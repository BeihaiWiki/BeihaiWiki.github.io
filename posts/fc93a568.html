<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>金砖国家机器学习比赛 | 北海`Blog</title><meta name="keywords" content="博客,我的大学生活,Java,算法,北海wiki"><meta name="author" content="北海🌊"><meta name="copyright" content="北海🌊"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="🐱‍👓金砖国家华东区域竞赛">
<meta property="og:type" content="article">
<meta property="og:title" content="金砖国家机器学习比赛">
<meta property="og:url" content="https://www.beihai.wiki/posts/fc93a568.html">
<meta property="og:site_name" content="北海&#96;Blog">
<meta property="og:description" content="🐱‍👓金砖国家华东区域竞赛">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://tuchuang.voooe.cn/images/2024/06/28/bc18.webp">
<meta property="article:published_time" content="2023-08-10T01:57:03.000Z">
<meta property="article:modified_time" content="2023-08-10T14:00:00.000Z">
<meta property="article:author" content="北海🌊">
<meta property="article:tag" content="博客,我的大学生活,Java,算法,北海wiki">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://tuchuang.voooe.cn/images/2024/06/28/bc18.webp"><link rel="shortcut icon" href="/assets/img/%E9%BB%84%E6%B3%89.webp"><link rel="canonical" href="https://www.beihai.wiki/posts/fc93a568"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/6.0.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.staticfile.org/fancyapps-ui/4.0.31/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 北海🌊","link":"链接: ","source":"来源: 北海`Blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.js',
      css: 'https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '金砖国家机器学习比赛',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-08-10 22:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><script src="https://npm.elemecdn.com/echarts@4.9.0/dist/echarts.min.js"></script><link rel="stylesheet" href="https://cdn1.tianli0.top/npm/element-ui@2.15.6/packages/theme-chalk/lib/index.css"><style id="themeColor"></style><style id="rightSide"></style><style id="transPercent"></style><style id="blurNum"></style><style id="settingStyle"></style><span id="fps"></span><style id="defineBg"></style><style id="menu_shadow"></style><svg aria-hidden="true" style="position:absolute; overflow:hidden; width:0; height:0"><symbol id="icon-sun" viewBox="0 0 1024 1024"><path d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z" fill="#FFD878" p-id="8420"></path><path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z" fill="#FFE4A9" p-id="8421"></path><path d="M512 109.248L626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z" fill="#4D5152" p-id="8422"></path><path d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z" fill="#4D5152" p-id="8423"></path></symbol><symbol id="icon-moon" viewBox="0 0 1024 1024"><path d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z" fill="#FFB531" p-id="11345"></path><path d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z" fill="#030835" p-id="11346"></path></symbol></svg><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="北海`Blog" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/assets/img/%E5%A4%B4%E5%83%8F.gif" onerror="onerror=null;src='/assets/r1.jpg'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">4</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-home"></use></svg><span class="menu_word" style="font-size:17px"> 首页</span></a></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-article"></use></svg><span class="menu_word" style="font-size:17px"> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-guidang">                   </use></svg><span class="menu_word" style="font-size:17px"> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-sekuaibiaoqian">                   </use></svg><span class="menu_word" style="font-size:17px"> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-fenlei">                   </use></svg><span class="menu_word" style="font-size:17px"> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-kafei"></use></svg><span class="menu_word" style="font-size:17px"> 休闲</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/life/music/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-music">                   </use></svg><span class="menu_word" style="font-size:17px"> 八音盒</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/movies/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-dianying">                   </use></svg><span class="menu_word" style="font-size:17px"> 影院</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/games/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-gamepad">                   </use></svg><span class="menu_word" style="font-size:17px"> 游戏</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-xiangzi"></use></svg><span class="menu_word" style="font-size:17px"> 八宝箱</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/box/gallery/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-tubiaozhizuomoban">                   </use></svg><span class="menu_word" style="font-size:17px"> 画廊</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/box/animation/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-Halloween-">                   </use></svg><span class="menu_word" style="font-size:17px"> 动画</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/box/nav/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-zhifengche">                   </use></svg><span class="menu_word" style="font-size:17px"> 网址导航</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shejiaoxinxi"></use></svg><span class="menu_word" style="font-size:17px"> 社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/social/fcircle/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-pengyouquan">                   </use></svg><span class="menu_word" style="font-size:17px"> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-liuyan">                   </use></svg><span class="menu_word" style="font-size:17px"> 留言板</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/social/link/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-lianjie1">                   </use></svg><span class="menu_word" style="font-size:17px"> 友人帐</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-wangye"></use></svg><span class="menu_word" style="font-size:17px"> 网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/site/census/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon--tongjibiao">                   </use></svg><span class="menu_word" style="font-size:17px"> 网站统计</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/site/echarts/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shujutongji1">                   </use></svg><span class="menu_word" style="font-size:17px"> 文章统计</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/site/time/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-xianxingshalou">                   </use></svg><span class="menu_word" style="font-size:17px"> 旧时光</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-mofashikatong"></use></svg><span class="menu_word" style="font-size:17px"> 个人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/personal/bb/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-go">                   </use></svg><span class="menu_word" style="font-size:17px"> 唠叨</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/love/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-aiqing">                   </use></svg><span class="menu_word" style="font-size:17px"> 恋爱小屋</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/about/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-paperplane">                   </use></svg><span class="menu_word" style="font-size:17px"> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">北海`Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-home"></use></svg><span class="menu_word" style="font-size:17px"> 首页</span></a></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-article"></use></svg><span class="menu_word" style="font-size:17px"> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-guidang">                   </use></svg><span class="menu_word" style="font-size:17px"> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-sekuaibiaoqian">                   </use></svg><span class="menu_word" style="font-size:17px"> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-fenlei">                   </use></svg><span class="menu_word" style="font-size:17px"> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-kafei"></use></svg><span class="menu_word" style="font-size:17px"> 休闲</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/life/music/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-music">                   </use></svg><span class="menu_word" style="font-size:17px"> 八音盒</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/movies/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-dianying">                   </use></svg><span class="menu_word" style="font-size:17px"> 影院</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/games/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-gamepad">                   </use></svg><span class="menu_word" style="font-size:17px"> 游戏</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-xiangzi"></use></svg><span class="menu_word" style="font-size:17px"> 八宝箱</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/box/gallery/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-tubiaozhizuomoban">                   </use></svg><span class="menu_word" style="font-size:17px"> 画廊</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/box/animation/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-Halloween-">                   </use></svg><span class="menu_word" style="font-size:17px"> 动画</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/box/nav/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-zhifengche">                   </use></svg><span class="menu_word" style="font-size:17px"> 网址导航</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shejiaoxinxi"></use></svg><span class="menu_word" style="font-size:17px"> 社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/social/fcircle/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-pengyouquan">                   </use></svg><span class="menu_word" style="font-size:17px"> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-liuyan">                   </use></svg><span class="menu_word" style="font-size:17px"> 留言板</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/social/link/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-lianjie1">                   </use></svg><span class="menu_word" style="font-size:17px"> 友人帐</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-wangye"></use></svg><span class="menu_word" style="font-size:17px"> 网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/site/census/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon--tongjibiao">                   </use></svg><span class="menu_word" style="font-size:17px"> 网站统计</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/site/echarts/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shujutongji1">                   </use></svg><span class="menu_word" style="font-size:17px"> 文章统计</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/site/time/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-xianxingshalou">                   </use></svg><span class="menu_word" style="font-size:17px"> 旧时光</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-mofashikatong"></use></svg><span class="menu_word" style="font-size:17px"> 个人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/personal/bb/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-go">                   </use></svg><span class="menu_word" style="font-size:17px"> 唠叨</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/love/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-aiqing">                   </use></svg><span class="menu_word" style="font-size:17px"> 恋爱小屋</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/about/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-paperplane">                   </use></svg><span class="menu_word" style="font-size:17px"> 关于</span></a></li></ul></div></div><center id="name-container"><a id="page-name" href="javascript:scrollToTop()">PAGE_NAME</a></center><div id="nav-right"><div id="search-button"><a class="search faa-parent animated-hover" title="检索站内任何你想要的信息"><svg class="faa-tada icon" style="height:24px;width:24px;fill:currentColor;position:relative;top:6px" aria-hidden="true"><use xlink:href="#icon-valentine_-search-love-find-heart"></use></svg><span> 搜索</span></a></div><a class="meihua faa-parent animated-hover" onclick="toggleWinbox()" title="美化设置-自定义你的风格" id="meihua-button"><svg class="faa-tada icon" style="height:26px;width:26px;fill:currentColor;position:relative;top:8px" aria-hidden="true"><use xlink:href="#icon-tupian1"></use></svg></a><a class="sun_moon faa-parent animated-hover" onclick="switchNightMode()" title="浅色和深色模式转换" id="nightmode-button"><svg class="faa-tada" style="height:25px;width:25px;fill:currentColor;position:relative;top:7px" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon">       </use></svg></a><div id="toggle-menu"><a><i class="fas fa-bars fa-fw"></i></a></div></div></div></nav><div id="post-info"><h1 class="post-title">金砖国家机器学习比赛</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><svg class="meta_icon post-meta-icon" style="width:30px;height:30px;position:relative;top:10px"><use xlink:href="#icon-rili"></use></svg><span class="post-meta-label">发表于 </span><time class="post-meta-date-created" datetime="2023-08-10T01:57:03.000Z" title="发表于 2023-08-10 09:57:03">2023-08-10</time><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-gengxin1"></use></svg><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-08-10T14:00:00.000Z" title="更新于 2023-08-10 22:00:00">2023-08-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-biaoqian"></use></svg><a class="post-meta-categories" href="/categories/%E5%B7%A5%E4%BD%9C%E5%AE%A4/">工作室</a><i class="fas fa-angle-right post-meta-separator"></i><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-biaoqian"></use></svg><a class="post-meta-categories" href="/categories/%E5%B7%A5%E4%BD%9C%E5%AE%A4/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><svg class="meta_icon post-meta-icon" style="width:25px;height:25px;position:relative;top:8px"><use xlink:href="#icon-charuword"></use></svg><span class="post-meta-label">字数总计:</span><span class="word-count">2.7w</span><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:20px;height:20px;position:relative;top:5px"><use xlink:href="#icon-shizhong"></use></svg><span class="post-meta-label">阅读时长:</span><span>113分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="金砖国家机器学习比赛"><svg class="meta_icon post-meta-icon" style="width:25px;height:25px;position:relative;top:5px"><use xlink:href="#icon-eye"></use></svg><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>机器学习与大数据赛项</h1>
<p>竞赛环境：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>技术规格</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hadoop</td>
<td>3.3.x</td>
</tr>
<tr>
<td>Sqoop</td>
<td>1.4.x</td>
</tr>
<tr>
<td>Hive</td>
<td>2.3.x</td>
</tr>
<tr>
<td>Zookeeper</td>
<td>3.6.x</td>
</tr>
<tr>
<td>Flume</td>
<td>1.10.x</td>
</tr>
<tr>
<td>Spark</td>
<td>3.3.x</td>
</tr>
<tr>
<td>Flink</td>
<td>1.15.x</td>
</tr>
<tr>
<td>JDK</td>
<td>11</td>
</tr>
<tr>
<td>Scala</td>
<td>2.13.x</td>
</tr>
<tr>
<td>Python</td>
<td>3.7.x</td>
</tr>
</tbody>
</table>
<p>比赛内容:</p>
<blockquote>
<p>Hadoop 平台搭建、HDFS 数据存储、Flume 数据采集、Sqoop 数据导入、MapReduce 批处理操作、Hive 数据查询、大数据 可视化、数据整合、数据读取、数据探查、数据处理、数据 建模、模型评价。</p>
</blockquote>
<h1>模块A：大数据运维与应用(30分)</h1>
<blockquote>
<p>三天把完全分布式自己搭建了一遍，中间mysql的安装是搞了好久，hive启动失败，多半是mysql有错误，mysql那里还是要多看看。剩下的时间就是背加练了，没什么好说的</p>
</blockquote>
<h2 id="Hadoop基础环境搭建">Hadoop基础环境搭建</h2>
<p>参考链接: <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_44715376/article/details/130843233?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22130843233%22%2C%22source%22%3A%22qq_44715376%22%7D&amp;fromshare=blogdetail">https://blog.csdn.net/qq_44715376/article/details/130843233?csdn_share_tail={&quot;type&quot;%3A&quot;blog&quot;%2C&quot;rType&quot;%3A&quot;article&quot;%2C&quot;rId&quot;%3A&quot;130843233&quot;%2C&quot;source&quot;%3A&quot;qq_44715376&quot;}&amp;fromshare=blogdetail</a></p>
<p>1、安装虚拟机和Linux操作系统，配置IP地址、主机名、防火墙、地址映射等</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">网卡</span><br><span class="line">vi /etc/sysconfig/network-scripts/ifcfg-ens33</span><br><span class="line"></span><br><span class="line">/ect/hosts        配置主机名和IP地址的对应，对本机提供解析</span><br><span class="line">/etc/resolv.conf      配置域名（在hosts内解析不到时此域名生效）</span><br><span class="line">/etc/sysconfig/network      配置主机名和网关</span><br><span class="line">/etc/sysconfig/network-scripts/ifcfg-eth0 配置IP、Mask等网络参数</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="C:%5CUsers%5Cbeihai%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20230704224936122.png" alt="image-20230704224936122"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">重启网卡</span><br><span class="line">systemctl restart netword</span><br><span class="line"></span><br><span class="line">查看网卡</span><br><span class="line">ip addr 或 ifconfig</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">主机名 ：/etc/hostname</span><br><span class="line">master</span><br><span class="line">映射：/etc/hosts</span><br><span class="line">192.168.43.10 master</span><br><span class="line">192.168.43.20 node01</span><br><span class="line">192.168.43.30 node02</span><br><span class="line">关闭防火墙</span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br><span class="line">关闭Linunx安全子系统</span><br><span class="line">vi /etc/selinux/config</span><br><span class="line">SELINUX=disabled</span><br><span class="line">重启系统</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure>
<p>2、安装 JDK 与 Hadoop</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">上传安装包</span><br><span class="line">解压</span><br><span class="line">tar -zxvf jdk-8u261-linux-x64.tar.gz -C /opt/softwore/</span><br><span class="line">tar -zxvf hadoop-2.7.7\ .tar.gz -C /opt/softwore</span><br><span class="line"></span><br><span class="line">修改配置文件</span><br><span class="line">vim + /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/usr/local/src/jdk</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/usr/local/src/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line">export HDFS_NAMENODE_USER=root</span><br><span class="line">export HDFS_DATANODE_USER=root</span><br><span class="line">export HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">export YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">export YARN_NODEMANAGER_USER=root</span><br><span class="line"></span><br><span class="line">重新加载配置文件，使配置生效</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<p>3、完全分布式部署（HDFS)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">配置文件路径：/usr/local/src/hadoop/etc/hadoop</span><br><span class="line">HDFS</span><br><span class="line">修改 hadoop-env.sh 设置 Hadoop 环境对应的 JDK</span><br><span class="line">export JAVA_HOME=/usr/local/src/jdk</span><br><span class="line"></span><br><span class="line">配置 MapReduce 与 YARN</span><br><span class="line">修改 yarn-env.sh、mapred-env.sh 添加 JAVA_HOME 配置</span><br><span class="line">export JAVA_HOME=/usr/local/src/jdk</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>修改 core-site.xml 配置文件，可以使用 NotePad++ 进行配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!--NameNode的访问URI，也可以写为IP，8020为默认端口--&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://192.168.201.10:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!--临时数据目录，用来存放数据，格式化时会自动生成--&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/src/hadoop/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>修改 hdfs-site.xml 配置文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!--Block的副本数，伪分布式要改为1--&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!--NameNode 元数据存放地址--&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/src/hadoop/data/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!--DataNode 副本存放地址--&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/src/hadoop/data/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!--HDFS 临时存放地址--&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/src/hadoop/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!--配置有secondarynamenode的主机--&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> 	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>master:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>mapred-site.xml ，把 mapred-sit.xml.template 复制一份，修改为 mapred-site.xml yarn-site.xml 添加相应 配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--mapred-site.xml--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!---计算框架的运行平台配置 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--yarn-site.xml--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!---YARN 的节点辅助服务配置 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!--默认是0.0.0.0 本地访问--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>在 slaves 配置文件中 添加 主机名，它指定了 DataNode 和 NodeManager所在的机器。(注意这里有可能自带workers需要修改workers)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">node01</span><br><span class="line">node02</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">关机</span><br><span class="line">poweroff</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>克隆</p>
</li>
<li>
<p>分发</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r /usr/local/hadoop-3.3.1 root@slave03:/usr/local</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>4、SSH免密登录</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">先在每一台节点生成公钥和私钥</span><br><span class="line">ssh-keygen</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">把每一个节点上的公钥文件发送到所有节点（包括自己），注意：每一条命令都需要在3个节点中执行</span><br><span class="line">ssh-copy-id master</span><br><span class="line">ssh-copy-id node01</span><br><span class="line">ssh-copy-id node02</span><br></pre></td></tr></table></figure>
<p>5、格式化HDFS</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#master</span><br><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>
<p>6、启动服务</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh /start-yarn.sh</span><br><span class="line"></span><br><span class="line">start-all.sh</span><br></pre></td></tr></table></figure>
<p>7、查看进程</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br><span class="line"></span><br><span class="line">#master</span><br><span class="line">[root@master hadoop]# jps</span><br><span class="line">6002 SecondaryNameNode</span><br><span class="line">6435 NodeManager</span><br><span class="line">6280 ResourceManager</span><br><span class="line">5594 NameNode</span><br><span class="line">7835 Jps</span><br><span class="line">5775 DataNode</span><br><span class="line"></span><br><span class="line">#node01</span><br><span class="line">[root@node01 hadoop]# jps</span><br><span class="line">2131 DataNode</span><br><span class="line">2532 Jps</span><br><span class="line">2271 NodeManager</span><br><span class="line"></span><br><span class="line">#node02</span><br><span class="line">[root@node02 hadoop]# jps</span><br><span class="line">2145 NodeManager</span><br><span class="line">2405 Jps</span><br><span class="line">2023 DataNode</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Hadoop常用端口说明：</span><br><span class="line">hadoop2.x</span><br><span class="line">HDFS Namenode内部通常端口:8020/9000</span><br><span class="line">HDFS Namenode对用户的查询端口:50070</span><br><span class="line">Yarn查看任务运行情况的:8088</span><br><span class="line">历史服务器:19888</span><br><span class="line"></span><br><span class="line">hadoop3.x</span><br><span class="line">HDFS Namenode内部通常端口:8020/9000/9820</span><br><span class="line">HDFS Namenode对用户的査询端口:9870</span><br><span class="line">Yarn查看任务运行情况的:8088</span><br><span class="line">历史服务器:19888</span><br></pre></td></tr></table></figure>
<h2 id="MySQL离线安装">MySQL离线安装</h2>
<p>安装包<code>mysql-5.7.20-linux-glibc2.12-x86_64.tar.gz</code> 拷贝到 离线生产环境<code>/usr/local</code>目录下。</p>
<p>==<strong>1、创建用户</strong>==</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加mysql用户组</span></span><br><span class="line">groupadd mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加mysql用户</span></span><br><span class="line">useradd -g mysql mysql -d /home/mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改mysql用户的登陆密码</span></span><br><span class="line">passwd mysql</span><br></pre></td></tr></table></figure>
<p><strong>==2、解压缩==</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/</span><br><span class="line"></span><br><span class="line">tar -xzvf mysql-<span class="number">5.7</span><span class="number">.13</span>-linux-glibc2<span class="number">.5</span>-x86_64 </span><br><span class="line"></span><br><span class="line"><span class="comment"># 改名为mysql</span></span><br><span class="line">mv mysql-<span class="number">5.7</span><span class="number">.13</span>-linux-glibc2<span class="number">.5</span>-x86_64 mysql</span><br><span class="line"></span><br><span class="line"><span class="comment">#赋予用户读写权限</span></span><br><span class="line">chown -R mysql:mysql mysql/</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 删除maridb</span></span><br><span class="line">rpm -qa | grep mariadb</span><br><span class="line">yum remove mariadb*</span><br></pre></td></tr></table></figure>
<p><strong>==3、创建配置文件==</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/my.cnf</span><br><span class="line"></span><br><span class="line"><span class="comment">#内容</span></span><br><span class="line"></span><br><span class="line">[client]</span><br><span class="line">port = <span class="number">3306</span></span><br><span class="line">socket = /tmp/mysql.sock</span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line">character_set_server=utf8</span><br><span class="line">init_connect=<span class="string">&#x27;SET NAMES utf8&#x27;</span></span><br><span class="line">basedir=/usr/local/src/mysql</span><br><span class="line">datadir=/usr/local/src/mysql/data</span><br><span class="line">socket=/tmp/mysql.sock</span><br><span class="line">log-error=/var/log/mysqld.log</span><br><span class="line">pid-file=/var/run/mysqld/mysqld.pid</span><br><span class="line"><span class="comment">#不区分大小写</span></span><br><span class="line">lower_case_table_names = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION</span><br><span class="line"></span><br><span class="line">max_connections=<span class="number">5000</span></span><br><span class="line"></span><br><span class="line">explicit_defaults_for_timestamp=true</span><br><span class="line"></span><br><span class="line">default-time_zone = <span class="string">&#x27;+8:00&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>==<strong>初始化文件</strong>==</p>
<p>1、初始化log文件，防止没有权限</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#手动编辑一下日志文件，什么也不用写，直接保存退出</span></span><br><span class="line">cd /var/log/</span><br><span class="line"></span><br><span class="line">vim mysqld.log</span><br><span class="line">：wq</span><br><span class="line"></span><br><span class="line">chmod <span class="number">777</span> mysqld.log</span><br><span class="line">chown mysql:mysql mysqld.log</span><br></pre></td></tr></table></figure>
<p>2、初始化pid文件，防止没有权限</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#手动编辑一下日志文件，什么也不用写，直接保存退出</span></span><br><span class="line">cd /var/run/				<span class="comment">#run的文件保存在内存中，重启会删除</span></span><br><span class="line">mkdir mysqld</span><br><span class="line">cd mysqld</span><br><span class="line">vi mysqld.pid</span><br><span class="line">：wq</span><br><span class="line"><span class="comment"># 给权限</span></span><br><span class="line">cd ..</span><br><span class="line">chmod <span class="number">777</span> mysqld</span><br><span class="line">chown -R mysql:mysql mysqld</span><br></pre></td></tr></table></figure>
<p>创建/opt/module/mysql/data</p>
<p>3、初始化数据库</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化数据库，并指定启动mysql的用户，否则就会在启动MySQL时出现权限不足的问题</span></span><br><span class="line">/usr/local/src/mysql/<span class="built_in">bin</span>/mysqld --initialize --user=mysql --basedir=/usr/local/src/mysql --datadir=/usr/local/src/mysql/data --lc_messages_dir=/usr/local/src/mysql/share --lc_messages=en_US</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看root的随机密码</span></span><br><span class="line">cat /var/log/mysqld.log</span><br><span class="line"></span><br><span class="line"><span class="comment">#root@local: XXXXX   XXXXX就是初始密码</span></span><br></pre></td></tr></table></figure>
<p>bash_profile 在 ~ /中</p>
<p>==<strong>启动数据库</strong>==</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#源目录启动：</span></span><br><span class="line">/usr/local/src/mysql/support-files/mysql.server start</span><br></pre></td></tr></table></figure>
<p>设置开机自动启动服务</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 复制启动脚本到资源目录</span></span><br><span class="line">cp /usr/local/src/mysql/support-files/mysql.server /etc/rc.d/init.d/mysqld</span><br><span class="line"></span><br><span class="line"><span class="comment"># 增加mysqld服务控制脚本执行权限</span></span><br><span class="line">chmod +x /etc/rc.d/init.d/mysqld</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将mysqld服务加入到系统服务</span></span><br><span class="line">chkconfig --add mysqld</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查mysqld服务是否已经生效</span></span><br><span class="line">chkconfig --<span class="built_in">list</span> mysqld</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换至mysql用户，启动mysql，或者稍后下一步再启动。</span></span><br><span class="line">su mysql</span><br><span class="line"></span><br><span class="line">service mysqld start </span><br></pre></td></tr></table></figure>
<p>==<strong>配置环境变量</strong>==</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换至mysql用户</span></span><br><span class="line">su mysql</span><br><span class="line"></span><br><span class="line">vi .bash_profile</span><br><span class="line"><span class="comment"># 修改配置文件，增加export PATH=$PATH:/usr/local/src/mysql/bin</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 立即生效</span></span><br><span class="line">source .bash_profile</span><br></pre></td></tr></table></figure>
<p>==<strong>登录，修改密码</strong>==</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 系统默认会查找/usr/bin下的命令;建立一个链接文件。</span></span><br><span class="line">ln -s /usr/local/usr/mysql/<span class="built_in">bin</span>/mysql /usr/<span class="built_in">bin</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 登陆mysql的root用户</span></span><br><span class="line">mysql -uroot -p</span><br><span class="line"><span class="comment"># 输入2.4生成的 随机密码</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改root用户密码为123456</span></span><br><span class="line"><span class="built_in">set</span> password <span class="keyword">for</span> root@localhost=password(<span class="string">&quot;123456&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">#给权限,使用户可以远程登录</span></span><br><span class="line">mysql&gt;grant <span class="built_in">all</span> privileges on *.* to <span class="string">&#x27;新用户名&#x27;</span>@<span class="string">&#x27;%&#x27;</span> identified by <span class="string">&#x27;新密码&#x27;</span>;</span><br><span class="line"></span><br><span class="line">mysql&gt;flush privileges;</span><br></pre></td></tr></table></figure>
<h2 id="Hive安装">Hive安装</h2>
<p>1）解压</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf /opt/softwares/apache-hive-3.1.2-bin.tar.gz  -C /opt/module</span><br></pre></td></tr></table></figure>
<p>2）配环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_HOME=/opt/module/hive</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br><span class="line">export HADOOP_CLASSPATH=&#x27;hadoop classpath&#x27;</span><br></pre></td></tr></table></figure>
<p>3）修改配置文件</p>
<p><a target="_blank" rel="noopener" href="http://hive-env.sh">hive-env.sh</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8</span><br><span class="line">export HIVE_HOME=/opt/module/hive</span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-3.1.3</span><br><span class="line">export HIVE_CONF_DIR=/opt/module/hive/conf</span><br></pre></td></tr></table></figure>
<p>hive-site.xml（可去hive/hcatalog/etc/hcatalog/目录下把proto-hive-site.xml复制到conf目录下并改名为hive-site.xml，删除第一个property之间的和除这四个以外的）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">           &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">           &lt;value&gt;jdbc:mysql://master:3306/hive_db?createDatabaseIfNotExist=true&amp;amp;useSSL=false&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">           &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">           &lt;value&gt;root(名字看题目要求)&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">           &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">           &lt;value&gt;000000(密码看题目要求)&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">           &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">           &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;!--cli 显示表头和列名--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;hive.cli.print.header&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;hive.cli.print.current.db&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<p>4）拷贝jar包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cp mysql-connector-java-5.1.37-bin.jar  /opt/module/hive/lib</span><br><span class="line">rm -rf /opt/module/hive/lib/guave-19.0.jar</span><br><span class="line">cp /opt/module/hadoop-3.1.3/share/hadoop/commond/lib/guava-27.0-jre.jar /opt/module/hive/lib</span><br></pre></td></tr></table></figure>
<p>5）初始化</p>
<p>在src下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">schematool -dbType mysql -initSchema</span><br></pre></td></tr></table></figure>
<p>6）查看</p>
<p>输入hive，出现hive&gt;</p>
<p>7）退出 exit；</p>
<ul>
<li>
<p>登录</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -p</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>更改密码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alter user &#x27;root&#x27;@&#x27;localhost&#x27; identified by &#x27;root&#x27;;</span><br><span class="line">set password for &#x27;root&#x27;@&#x27;localhost&#x27;=&#x27;123456&#x27;;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>开启远程登录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">grant all privileges on *.* to &#x27;root&#x27;@&#x27;%&#x27; identified by &#x27;root&#x27; with grant option;</span><br><span class="line"></span><br><span class="line">刷新</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>3、配置hive</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">配置 conf/hive-env.sh文件中的 HADOOP_HOME</span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop/</span><br></pre></td></tr></table></figure>
<p>4.导入jar包 和 移除jar包</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">将 mysql-connector-java-5.1.47.jar 添加到hive lib 下</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/hive/lib/</span><br><span class="line">/usr/local/hadoop/share/hadoop/common/lib/</span><br><span class="line">删除低版本的jar包，将高版本的jar包复制到原来低版本的位置即可</span><br></pre></td></tr></table></figure>
<p>5.修改hive-site.xml配置文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--需要登录MySQL数据库，创建一个 hive 数据库备用--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://mater:3306/hive?</span><br><span class="line">createDatabaseIfNotExist=true<span class="symbol">&amp;amp;</span>useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--安装MySQL数据库的驱动类--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--安装MySQL数据库的名称--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--安装MySQL数据库的密码--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Hive使用">Hive使用</h2>
<p>==1、<strong>外部表</strong>==</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> t1 (</span><br><span class="line">  cust_id STRING,</span><br><span class="line">  fname STRING,</span><br><span class="line">  lname STRING,</span><br><span class="line">  email STRING,</span><br><span class="line">  level STRING,</span><br><span class="line">  phone MAP<span class="operator">&lt;</span>STRING, STRING<span class="operator">&gt;</span>,</span><br><span class="line">  order_ids <span class="keyword">ARRAY</span><span class="operator">&lt;</span>STRING<span class="operator">&gt;</span>,</span><br><span class="line">  order_value STRUCT<span class="operator">&lt;</span>min: STRING, max: STRING, avg: STRING, total: STRING<span class="operator">&gt;</span></span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited</span><br><span class="line">fields terminated <span class="keyword">by</span> <span class="string">&#x27;|&#x27;</span></span><br><span class="line">collection items terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">map keys terminated <span class="keyword">by</span> <span class="string">&#x27;:&#x27;</span></span><br><span class="line">location <span class="string">&#x27;/yyh&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> t1 (</span><br><span class="line"> cust_id STRING,</span><br><span class="line"> fname STRING,</span><br><span class="line"> lname STRING,</span><br><span class="line"> email STRING,</span><br><span class="line"> level STRING,</span><br><span class="line"> phone MAP<span class="operator">&lt;</span>STRING, STRING<span class="operator">&gt;</span>,</span><br><span class="line"> order_ids <span class="keyword">ARRAY</span><span class="operator">&lt;</span>STRING<span class="operator">&gt;</span>,</span><br><span class="line"> order_value STRUCT<span class="operator">&lt;</span>min: <span class="keyword">DOUBLE</span>, max: <span class="keyword">DOUBLE</span>, avg: <span class="keyword">DOUBLE</span>, total: <span class="keyword">DOUBLE</span><span class="operator">&gt;</span>)</span><br><span class="line"><span class="type">row</span> format delimited</span><br><span class="line">fields terminated <span class="keyword">by</span> <span class="string">&#x27;|&#x27;</span></span><br><span class="line">collection items terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">map keys terminated <span class="keyword">by</span> <span class="string">&#x27;:&#x27;</span></span><br><span class="line">location <span class="string">&#x27;/yyh&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> t5 (</span><br><span class="line"> cust_id STRING,</span><br><span class="line"> fname STRING,</span><br><span class="line"> lname STRING,</span><br><span class="line"> email STRING,</span><br><span class="line"> level STRING,</span><br><span class="line"> phone MAP<span class="operator">&lt;</span>STRING, STRING<span class="operator">&gt;</span>,</span><br><span class="line"> order_ids <span class="keyword">ARRAY</span><span class="operator">&lt;</span>STRING<span class="operator">&gt;</span>,</span><br><span class="line"> order_value STRUCT<span class="operator">&lt;</span>min: <span class="keyword">DOUBLE</span>, max: <span class="keyword">DOUBLE</span>, avg: <span class="keyword">DOUBLE</span>, total: <span class="keyword">DOUBLE</span><span class="operator">&gt;</span>)</span><br><span class="line"><span class="type">row</span> format delimited</span><br><span class="line">fields terminated <span class="keyword">by</span> <span class="string">&#x27;|&#x27;</span></span><br><span class="line">collection items terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">map keys terminated <span class="keyword">by</span> <span class="string">&#x27;#&#x27;</span></span><br><span class="line">location <span class="string">&#x27;/yyh&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 对上步任务创建的新表loyalty_program实现以下要求的简单查询：</span></span><br><span class="line"><span class="comment">-- 运行查询以选择客户ID1200866的HOME电话号码。并记录结果到 master 节点上 ec2-user 用户下的~/results/task4-2.txt文件中。（1分）</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">LOCAL</span> DIRECTORY <span class="string">&#x27;/home/ec2-user/results&#x27;</span></span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED</span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line"><span class="keyword">SELECT</span> phone[<span class="string">&#x27;HOME&#x27;</span>] <span class="keyword">FROM</span> loyalty_program <span class="keyword">WHERE</span> cust_id <span class="operator">=</span> <span class="string">&#x27;1200866&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查询客户ID1200866的HOME电话号码</span></span><br><span class="line"><span class="keyword">SELECT</span> phone[<span class="string">&#x27;HOME&#x27;</span>] <span class="keyword">FROM</span> loyalty_program <span class="keyword">WHERE</span> cust_id <span class="operator">=</span> <span class="string">&#x27;1200866&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 从order_ids数组中为客户ID1200866选择第三个元素</span></span><br><span class="line"><span class="keyword">SELECT</span> order_ids[<span class="number">2</span>] <span class="keyword">FROM</span> loyalty_program <span class="keyword">WHERE</span> cust_id <span class="operator">=</span> <span class="string">&#x27;1200866&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 从order_value结构中为客户ID1200866选择total属性</span></span><br><span class="line"><span class="keyword">SELECT</span> order_value.total <span class="keyword">FROM</span> loyalty_program <span class="keyword">WHERE</span> cust_id <span class="operator">=</span> <span class="string">&#x27;1200866&#x27;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>==<strong>分析数值产品评分</strong>==</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 客户评价和反馈是客户和像 Dualcore 的零售商的重要信息来源。我们希望找到客户最喜欢的产品，但必须防止评级很少的产品误导。</span></span><br><span class="line"><span class="comment">-- 探查 Hive 中的ratings表中数据，查询所有具有至少50个评级的产品中评分平均值最高的产品？并记录prod_id(产品ID)结果到 master -- 节点上 ec2-user 用户下的~/results/task4-3.txt文件中。（2分）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> prod_id</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">  <span class="keyword">SELECT</span> prod_id, <span class="built_in">AVG</span>(rating) <span class="keyword">AS</span> avg_rating, <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">AS</span> rating_count</span><br><span class="line">  <span class="keyword">FROM</span> ratings</span><br><span class="line">  <span class="keyword">GROUP</span> <span class="keyword">BY</span> prod_id</span><br><span class="line">  <span class="keyword">HAVING</span> rating_count <span class="operator">&gt;=</span> <span class="number">50</span></span><br><span class="line">) t</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> avg_rating <span class="keyword">DESC</span></span><br><span class="line">LIMIT <span class="number">1</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Sqoop安装与使用">Sqoop安装与使用</h2>
<p>==1、<strong>上传安装包、解压</strong>==</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz</span><br><span class="line"></span><br><span class="line">mv sqoop-1.4.7.bin__hadoop-2.6.0 sqoop</span><br></pre></td></tr></table></figure>
<p>==2、<strong>拷贝jar包，MySQL，hive</strong>==</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp mysql-connector-java-5.1.46.jar hive-exec-2.3.3.jar /opt/softwore/sqoop/lib</span><br></pre></td></tr></table></figure>
<p>==3、<strong>配置环境变量</strong>==</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim <span class="operator">/</span>etc<span class="operator">/</span>profile</span><br><span class="line">## SQOOP_HOME</span><br><span class="line">export SQOOP_HOME<span class="operator">=</span><span class="operator">/</span>opt<span class="operator">/</span>softwore<span class="operator">/</span>sqoop</span><br><span class="line">export PATH<span class="operator">=</span>$PATH:$SQOOP_HOME<span class="operator">/</span>bin</span><br><span class="line">source <span class="operator">/</span>etc<span class="operator">/</span>profile</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>==4、<strong>修改配置 文件</strong>==</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cp sqoop-env-template.sh sqoop-env.sh</span><br><span class="line"></span><br><span class="line">修改以下内容</span><br><span class="line">export HADOOP_COMMON_HOME=/opt/softwore/hadoop</span><br><span class="line">export HADOOP_MAPRED_HOME=/opt/softwore/hadoop</span><br><span class="line">export HIVE_HOME=/opt/softwore/hive</span><br></pre></td></tr></table></figure>
<p>==5、<strong>测试环境</strong>==</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop <span class="built_in">version</span></span><br></pre></td></tr></table></figure>
<p>==6、<strong>列出数据库</strong>==</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sqoop list<span class="operator">-</span>databases \</span><br><span class="line"><span class="comment">--connect jdbc:mysql://master:3306/ \</span></span><br><span class="line"><span class="comment">--username root --password 123456</span></span><br></pre></td></tr></table></figure>
<p>==7、<strong>查询SQL</strong>==</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sqoop eval \</span><br><span class="line">--connect jdbc:mysql://master:3306/yyh \</span><br><span class="line">--username root --password 123456 \</span><br><span class="line">--query &#x27;select count(distinct(name)) from t1&#x27;</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">~/results/task3-1.txt</span></span><br></pre></td></tr></table></figure>
<p>==8、<strong>sqoop导入</strong>==</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">MYSQL导入到HDFS</span></span><br><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://master:3306/yyh \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table t1 \</span><br><span class="line">--fields-terminated-by &#x27;,&#x27; \</span><br><span class="line">--lines-terminated-by &#x27;\n&#x27; \</span><br><span class="line">--target-dir &#x27;/sqoop/t1&#x27; \</span><br><span class="line">-m 1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">MYSQL导入到Hive</span></span><br><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://master:3306/yyh \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table t1 \</span><br><span class="line">--fields-terminated-by &#x27;,&#x27; \</span><br><span class="line">--lines-terminated-by &#x27;\n&#x27; \</span><br><span class="line">--target-dir &#x27;/sqoop/t111&#x27; \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--hive-import \</span><br><span class="line">--hive-table &#x27;yyh.t111&#x27; \</span><br><span class="line">-m 1</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>==9、<strong>sqoop导出</strong>==</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">HDFS导出到MYSQL</span></span><br><span class="line">sqoop export \</span><br><span class="line">--connect jdbc:mysql://master:3306/yyh \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table t1 \</span><br><span class="line">--export-dir &#x27;/sqoop/t1/*&#x27; \</span><br><span class="line">--fields-terminated-by &#x27;,&#x27; \</span><br><span class="line">--lines-terminated-by &#x27;\n&#x27; \</span><br><span class="line">-m 1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Hive导出到MYSQL</span></span><br><span class="line">sqoop export \</span><br><span class="line">--connect jdbc:mysql://master:3306/yyh \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table t111 \</span><br><span class="line">--export-dir &#x27;/user/hive/warehouse/yyh.db/t11/*&#x27; \</span><br><span class="line">-m 1</span><br></pre></td></tr></table></figure>
<p>==<strong>报错</strong>==</p>
<ul>
<li>mapreduce启动失败</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master txt]# hadoop classpath</span><br><span class="line">/opt/softwore/hadoop/etc/hadoop:/opt/softwore/hadoop/share/hadoop/common/lib/*:/opt/softwore/hadoop/share/hadoop/common/*:/opt/softwore/hadoop/share/hadoop/hdfs:/opt/softwore/hadoop/share/hadoop/hdfs/lib/*:/opt/softwore/hadoop/share/hadoop/hdfs/*:/opt/softwore/hadoop/share/hadoop/mapreduce/*:/opt/softwore/hadoop/share/hadoop/yarn:/opt/softwore/hadoop/share/hadoop/yarn/lib/*:/opt/softwore/hadoop/share/hadoop/yarn/*</span><br></pre></td></tr></table></figure>
<p>修改yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span>	     			<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/softwore/hadoop/etc/hadoop:/opt/softwore/hadoop/share/hadoop/common/lib/*:/opt/softwore/hadoop/share/hadoop/common/*:/opt/softwore/hadoop/share/hadoop/hdfs:/opt/softwore/hadoop/share/hadoop/hdfs/lib/*:/opt/softwore/hadoop/share/hadoop/hdfs/*:/opt/softwore/hadoop/share/hadoop/mapreduce/*:/opt/softwore/hadoop/share/hadoop/yarn:/opt/softwore/hadoop/share/hadoop/yarn/lib/*:/opt/softwore/hadoop/share/hadoop/yarn/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="Spark安装">Spark安装</h2>
<p>安装和启动 Spark 组件包括以下步骤：</p>
<ol>
<li>解压 Spark 安装包： 在 master 节点上执行以下命令解压 Spark 安装包：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf ~/hadoop搭建相关安装包/spark-2.4.6-bin-hadoop2.7.tgz</span><br></pre></td></tr></table></figure>
<ol>
<li>配置 Spark 环境变量： 编辑 <code>~/.bashrc</code> 文件，并添加以下环境变量配置：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export SPARK_HOME=/path/to/spark-2.4.6-bin-hadoop2.7</span><br><span class="line">export PATH=$PATH:$SPARK_HOME/bin</span><br></pre></td></tr></table></figure>
<p>然后运行以下命令使环境变量生效：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>
<ol>
<li>配置 Spark 主节点： 在 Spark 安装目录中的 <code>conf</code> 文件夹中，复制 <code>spark-env.sh.template</code> 并将其重命名为 <code>spark-env.sh</code>：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /path/to/spark-2.4.6-bin-hadoop2.7/conf</span><br><span class="line">cp spark-env.sh.template spark-env.sh</span><br></pre></td></tr></table></figure>
<p>编辑 <code>spark-env.sh</code> 文件，添加以下内容来配置 Spark 主节点（master）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export SPARK_MASTER_HOST=master_node_hostname</span><br><span class="line">export SPARK_MASTER_PORT=7077</span><br><span class="line">export SPARK_MASTER_WEBUI_PORT=8080</span><br></pre></td></tr></table></figure>
<p>将 <code>master_node_hostname</code> 替换为 master 节点的主机名或 IP 地址。</p>
<ol>
<li>配置 Spark 工作节点： 在 Spark 安装目录中的 <code>conf</code> 文件夹中，复制 <code>slaves.template</code> 并将其重命名为 <code>slaves</code>：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /path/to/spark-2.4.6-bin-hadoop2.7/conf</span><br><span class="line">cp slaves.template slaves</span><br></pre></td></tr></table></figure>
<p>编辑 <code>slaves</code> 文件，添加以下内容来配置 Spark 工作节点（worker）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node1</span><br><span class="line">node2</span><br></pre></td></tr></table></figure>
<p>将 <code>node1</code> 和 <code>node2</code> 替换为实际的工作节点主机名或 IP 地址。</p>
<ol>
<li>启动 Spark 主节点和工作节点： 在 master 节点上执行以下命令启动 Spark 主节点（Master）：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/path/to/spark-2.4.6-bin-hadoop2.7/sbin/start-master.sh</span><br></pre></td></tr></table></figure>
<p>然后，在每个工作节点（node1 和 node2）上执行以下命令启动 Spark 工作节点（Worker）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/path/to/spark-2.4.6-bin-hadoop2.7/sbin/start-slave.sh spark://master_node_hostname:7077</span><br></pre></td></tr></table></figure>
<p>将 <code>master_node_hostname</code> 替换为实际的 master 节点主机名或 IP 地址。</p>
<ol>
<li>验证 Spark 启动： 在浏览器中访问 Spark 主节点的 Web UI，地址为 <code>http://master_node_hostname:8080</code>，确保 Spark 主节点和工作节点都已成功启动，并查看集群的状态。</li>
</ol>
<p>完成上述步骤后，Spark 组件将安装在 master 节点和两个工作节点上，并且 Spark 集群已经启动，包含一个主节点（Master）和两个工作节点（Worker）。你可以通过 Web UI 来监控和管理 Spark 集群，并在 Spark Shell 中执行 Spark 任务。</p>
<p>==1、<strong>修改Hadoop配置文件yarn-site.xml</strong>==</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>==2、<strong>解压安装包、配置</strong>==</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">解压spark，并重命名为spark-yarn</span><br><span class="line">tar -zxvf spark-2.4.7-bin-hadoop2.7.tgz</span><br><span class="line">mv spark-2.4.7-bin-hadoop2.7 spark-yarn</span><br><span class="line"></span><br><span class="line">修改spark-env.sh文件，添加java环境和yarn配置地址</span><br><span class="line">cp spark-env.sh.template spark-env.sh</span><br><span class="line">vim spark-env.sh</span><br><span class="line"></span><br><span class="line">添加内容</span><br><span class="line">export JAVA_HOME=/opt/softwore/jdk8</span><br><span class="line">export HADOOP_HOME=/opt/softwore/hadoop</span><br><span class="line">export HADOOP_CONF_DIR=/opt/softwore/hadoop/etc/hadoop</span><br><span class="line">export LD_LIBRARY_PATH=/opt/softwore/hadoop/lib/native</span><br><span class="line">export SPARK_MASTER_IP=master</span><br><span class="line">export SPARK_LOCAL_DIRS=/opt/softwore/src/spark/tmp</span><br><span class="line">export SPARK_LOG_DIR=/opt/softwore/spark/logs</span><br><span class="line">export SPARK_MASTER_PORT=7077</span><br><span class="line">export SPARK_DRIVER_MEMORY=512M</span><br><span class="line"></span><br><span class="line">修改slaves文件</span><br><span class="line">cp slaves.template slaves</span><br><span class="line">vim slaves</span><br><span class="line">node01</span><br><span class="line">node02</span><br><span class="line"></span><br><span class="line">修改环境变量</span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">## SPARK_ENV</span><br><span class="line">export SPARK_HOME=/usr/local/spark-yarn</span><br><span class="line">export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin</span><br><span class="line"></span><br><span class="line">刷新，生效</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<p>==3、<strong>导入jar包</strong>==</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">cp</span> mysql-connector-java-<span class="number">5</span>.<span class="number">1</span>.<span class="number">47</span>.jar /opt/softwore/spark/jars</span><br><span class="line"><span class="attribute">cp</span> hive-common-<span class="number">2</span>.<span class="number">3</span>.<span class="number">1</span>.jar /opt/softwore/spark/jars</span><br></pre></td></tr></table></figure>
<p>==4、<strong>使用Hive</strong>==</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">spark-shell</span><br><span class="line"></span><br><span class="line"><span class="comment">// 开启多行代码模式</span></span><br><span class="line">:paste</span><br><span class="line"></span><br><span class="line">saprk.sql(<span class="string">&quot;select * from yyh.t1&quot;</span>).show()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 关闭</span></span><br><span class="line">ctrl + <span class="type">D</span></span><br></pre></td></tr></table></figure>
<h2 id="Spark使用">Spark使用</h2>
<h4 id="省赛样卷一">省赛样卷一</h4>
<blockquote>
<p>任务6：Spark 分布式计算（5分）</p>
<p>6.1 计算不重复的电影数量</p>
<p>6.2 计算电影平均评分</p>
<p>6.3 计算用户在夜晚的评分总记录数</p>
</blockquote>
<p>==<strong>实例化对象</strong>==</p>
<h5 id="6-1-计算不重复的电影数量">6.1 计算不重复的电影数量</h5>
<blockquote>
<p>在master节点上操作，读取 hdfs 上/spark/movie_ratings.csv数据，启动 spark 计算不重复的电影（movieId）数量，并保存结果到~/results/task6-1.txt文件中。（1分）</p>
</blockquote>
<p><code>spark-shell</code>还是先开启多行代码编辑模式<code>:paste</code></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; :paste</span><br><span class="line"><span class="comment">// Entering paste mode (ctrl-D to finish)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> data = spark.read</span><br><span class="line">                .option(<span class="string">&quot;header&quot;</span>,<span class="string">&quot;true&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;inferSchema&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">                .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">                .load(<span class="string">&quot;hdfs:///spark/movie_ratings.csv&quot;</span>)</span><br><span class="line">                .createTempView(<span class="string">&quot;t1&quot;</span>)</span><br><span class="line">spark.sql(<span class="string">&quot;select count(distinct(movieId)) from t1&quot;</span>).show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> res1 = spark.sql(<span class="string">&quot;select count(distinct(movieId)) from t1&quot;</span>)</span><br><span class="line"><span class="type">Seq</span>(res1.first().toString()).toDF().write.mode(<span class="string">&quot;overwrite&quot;</span>).text(<span class="string">&quot;file:///root/results/task6-2.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// Exiting paste mode, now interpreting.</span></span><br><span class="line"></span><br><span class="line">+-----------------------+                                                       </span><br><span class="line">|count(<span class="type">DISTINCT</span> movieId)|</span><br><span class="line">+-----------------------+</span><br><span class="line">|                  <span class="number">14026</span>|</span><br><span class="line">+-----------------------+</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> data: <span class="type">Unit</span> = ()</span><br><span class="line"><span class="keyword">val</span> res1: org.apache.spark.sql.<span class="type">DataFrame</span> = [count(<span class="type">DISTINCT</span> movieId): bigint]</span><br></pre></td></tr></table></figure>
<p>保存文件的时候遇到了一些问题，因为前面我是设置了<code>.format(&quot;inferSchema&quot;, &quot;true&quot;)</code>spark自动识别字段类型，所以有的数据格式为<code>Bigint</code>,但是存文件时候spark不支持直接将<code>Bigint</code>类型转换为文本格式，这里想了想只是输出一个纯文本用不着这么麻烦我直接就强转了，但是这样是错的你强转的只是sql语句，所以还是需要麻烦一点获取<code>first()</code>其实更好的方式是将<code>Bigint</code>类型转成String，然后存到一个Seq中再转成<code>dataframe</code>格式</p>
<p>还有一点就是保存到本地是<code>file:///</code></p>
<p><code>Seq</code>提供了许多其他的操作方法，如<code>head</code>、<code>tail</code>、<code>isEmpty</code>、<code>distinct</code>等</p>
<p>需要注意的是，<code>Seq</code>是不可变的，这意味着它的元素是不可变的，一旦创建，就不能修改。如果你需要可变的序列，可以使用<code>mutable.Seq</code>。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> from_unixtime(<span class="number">1112484727</span>, <span class="string">&#x27;yyyy-MM-dd HH:mm:ss&#x27;</span>);</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data1_1 = spark.sql(<span class="string">&quot;select cast(count(distinct(movieId)) as string) as number from t1&quot;</span>) data1_1.write.option(<span class="string">&quot;header&quot;</span>,<span class="string">&quot;false&quot;</span>).format(<span class="string">&quot;text&quot;</span>).mode(<span class="string">&quot;overwrite&quot;</span>).save(<span class="string">&quot;file:///root/spark/s1.txt&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="6-2-计算电影平均评分">6.2  计算电影平均评分</h5>
<blockquote>
<p>在master节点上操作，读取 hdfs 上/spark/movie_ratings.csv数据，运用 spark 计算电影平均评分，保留两位小数，并保存结果到~/results/task6-2.txt文件中。(平均评分=总评分数/总评分记录数）（1分）</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> res2 = spark.sql(<span class="string">&quot;select round(avg(rating),2) as avg_rating from t1&quot;</span>)</span><br><span class="line"><span class="type">Seq</span>(res2.first().toString()).toDF().write.mode(<span class="string">&quot;overwrite&quot;</span>).text(<span class="string">&quot;file:///root/results/task6-2.txt&quot;</span>)</span><br></pre></td></tr></table></figure>
<h5 id="6-3-计算用户在夜晚的评分总记录数">6.3  计算用户在夜晚的评分总记录数</h5>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 6.3 计算用户在夜晚的评分总记录数</span></span><br><span class="line"><span class="comment">     * 在master节点上操作，读取 hdfs 上/spark/movie_ratings.csv数据，</span></span><br><span class="line"><span class="comment">     * 按照以下要求把每天的评分时间字段划分为 morning、lunch、afternoon、evening、night 五个时间段，</span></span><br><span class="line"><span class="comment">     * 并运用 spark 计算用户在夜晚（evening）的评分总记录数，并保存结果到~/results/task6-3.txt文件中。（3分）</span></span><br><span class="line"><span class="comment">     * 评分时间戳字段分类（以小时为单位）：</span></span><br><span class="line"><span class="comment">     * •	morning：7~12（包含7点，不含12点）</span></span><br><span class="line"><span class="comment">     * •	lunch：12~14（包含12点，不含14点）</span></span><br><span class="line"><span class="comment">     * •	afternoon：14~18（包含14点，不含18点）</span></span><br><span class="line"><span class="comment">     * •	evening：18~24（包含18点，不含24点）</span></span><br><span class="line"><span class="comment">     * •	night：0~7（包含0点，不含7点）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> data = spark.read</span><br><span class="line">      .option(<span class="string">&quot;header&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;inferSchema&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">      .csv(<span class="string">&quot;C:\\Users\\beihai\\Desktop\\competition\\movie_ratings.csv&quot;</span>)</span><br><span class="line">      .createTempView(<span class="string">&quot;view1&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark.sql(</span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        |with t1 as (</span></span><br><span class="line"><span class="string">        |select</span></span><br><span class="line"><span class="string">        |       userId,movieId,rating,hour(from_unixtime(timestamp, &#x27;yyyy-MM-dd HH:mm:ss&#x27;)) as hour_time</span></span><br><span class="line"><span class="string">        |from</span></span><br><span class="line"><span class="string">        |       view1</span></span><br><span class="line"><span class="string">        |),</span></span><br><span class="line"><span class="string">        |t2 as (</span></span><br><span class="line"><span class="string">        |select</span></span><br><span class="line"><span class="string">        |       userId,rating,</span></span><br><span class="line"><span class="string">        |case</span></span><br><span class="line"><span class="string">        |       when hour_time &gt;= 7 and hour_time &lt; 12 then &#x27;morning&#x27;</span></span><br><span class="line"><span class="string">        |       when hour_time &gt;= 12 and hour_time &lt; 14 then &#x27;lunch&#x27;</span></span><br><span class="line"><span class="string">        |       when hour_time &gt;= 14 and hour_time &lt; 18 then &#x27;afternoon&#x27;</span></span><br><span class="line"><span class="string">        |       when hour_time &gt;= 18 and hour_time &lt; 24 then &#x27;evening&#x27;</span></span><br><span class="line"><span class="string">        |       else &#x27;night&#x27;</span></span><br><span class="line"><span class="string">        |end as evening_rating</span></span><br><span class="line"><span class="string">        |from t1</span></span><br><span class="line"><span class="string">        |)</span></span><br><span class="line"><span class="string">        |select</span></span><br><span class="line"><span class="string">        |userId, sum(rating) as rating</span></span><br><span class="line"><span class="string">        |from t2</span></span><br><span class="line"><span class="string">        |where evening_rating = &#x27;evening&#x27;</span></span><br><span class="line"><span class="string">        |group by userId</span></span><br><span class="line"><span class="string">        |order by userId</span></span><br><span class="line"><span class="string">        |&quot;&quot;&quot;</span>.stripMargin).show()</span><br><span class="line"></span><br><span class="line">    spark.sql(</span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        |select</span></span><br><span class="line"><span class="string">        |       userId,sum(rating) as evening_ratings</span></span><br><span class="line"><span class="string">        |from view1</span></span><br><span class="line"><span class="string">        |where</span></span><br><span class="line"><span class="string">        |       hour(from_unixtime(timestamp,&#x27;yyyy-MM-dd HH:mm:ss&#x27;)) &gt;= 18 and hour(from_unixtime(timestamp,&#x27;yyyy-MM-dd HH:mm:ss&#x27;)) &lt; 24</span></span><br><span class="line"><span class="string">        |group by userId</span></span><br><span class="line"><span class="string">        |order by userId</span></span><br><span class="line"><span class="string">        |&quot;&quot;&quot;</span>.stripMargin).show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取 movie_ratings.csv 数据</span></span><br><span class="line"><span class="keyword">val</span> data = spark.read</span><br><span class="line">  .option(<span class="string">&quot;header&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;inferSchema&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">  .csv(<span class="string">&quot;hdfs:///spark/movie_ratings.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将时间戳字段转换为时间类型</span></span><br><span class="line"><span class="keyword">val</span> formattedData = data.withColumn(<span class="string">&quot;timestamp&quot;</span>, to_timestamp(col(<span class="string">&quot;timestamp&quot;</span>), <span class="string">&quot;yyyy-MM-dd HH:mm:ss&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 添加时间段列</span></span><br><span class="line"><span class="keyword">val</span> categorizedData = formattedData.withColumn(<span class="string">&quot;time_period&quot;</span>, when(hour(col(<span class="string">&quot;timestamp&quot;</span>)).between(<span class="number">7</span>, <span class="number">11</span>), <span class="string">&quot;morning&quot;</span>)</span><br><span class="line">  .when(hour(col(<span class="string">&quot;timestamp&quot;</span>)).between(<span class="number">12</span>, <span class="number">13</span>), <span class="string">&quot;lunch&quot;</span>)</span><br><span class="line">  .when(hour(col(<span class="string">&quot;timestamp&quot;</span>)).between(<span class="number">14</span>, <span class="number">17</span>), <span class="string">&quot;afternoon&quot;</span>)</span><br><span class="line">  .when(hour(col(<span class="string">&quot;timestamp&quot;</span>)).between(<span class="number">18</span>, <span class="number">23</span>), <span class="string">&quot;evening&quot;</span>)</span><br><span class="line">  .otherwise(<span class="string">&quot;night&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 过滤出夜晚时间段的数据并计算评分总记录数</span></span><br><span class="line"><span class="keyword">val</span> eveningCount = categorizedData.filter(col(<span class="string">&quot;time_period&quot;</span>) === <span class="string">&quot;evening&quot;</span>).count()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将结果保存到文件</span></span><br><span class="line"><span class="keyword">val</span> outputPath = <span class="string">&quot;/home/ec2-user/results/task6-3.txt&quot;</span></span><br><span class="line"><span class="keyword">val</span> result = <span class="string">s&quot;Evening rating count: <span class="subst">$eveningCount</span>&quot;</span></span><br><span class="line">spark.sparkContext.parallelize(<span class="type">Seq</span>(result)).saveAsTextFile(outputPath)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">scala&gt; spark.sql(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">     | select</span></span><br><span class="line"><span class="string">     |      userId,count(*) as countt</span></span><br><span class="line"><span class="string">     | from df1</span></span><br><span class="line"><span class="string">     | where hour(from_unixtime(timestamp,&#x27;yyyy-MM-dd HH:mm:ss&#x27;)) &gt;= 18 and</span></span><br><span class="line"><span class="string">     | hour(from_unixtime(timestamp,&#x27;yyyy-MM-dd HH:mm:ss&#x27;)) &lt; 24</span></span><br><span class="line"><span class="string">     | group by userId</span></span><br><span class="line"><span class="string">     | &quot;&quot;&quot;</span>).show()</span><br><span class="line">+------+------+                                                                 </span><br><span class="line">|userId|countt|</span><br><span class="line">+------+------+</span><br><span class="line">|   <span class="number">148</span>|   <span class="number">128</span>|</span><br><span class="line">|   <span class="number">463</span>|    <span class="number">79</span>|</span><br><span class="line">|   <span class="number">471</span>|    <span class="number">31</span>|</span><br><span class="line">|   <span class="number">833</span>|     <span class="number">3</span>|</span><br><span class="line">|  <span class="number">1088</span>|    <span class="number">60</span>|</span><br><span class="line">|  <span class="number">1342</span>|    <span class="number">25</span>|</span><br><span class="line">|  <span class="number">1591</span>|     <span class="number">4</span>|</span><br><span class="line">|  <span class="number">1959</span>|    <span class="number">74</span>|</span><br><span class="line">|  <span class="number">2122</span>|    <span class="number">46</span>|</span><br><span class="line">|   <span class="number">392</span>|    <span class="number">21</span>|</span><br><span class="line">|   <span class="number">540</span>|    <span class="number">10</span>|</span><br><span class="line">|   <span class="number">737</span>|    <span class="number">19</span>|</span><br><span class="line">|   <span class="number">858</span>|    <span class="number">62</span>|</span><br><span class="line">|  <span class="number">1084</span>|    <span class="number">94</span>|</span><br><span class="line">|  <span class="number">1127</span>|    <span class="number">82</span>|</span><br><span class="line">|  <span class="number">1896</span>|   <span class="number">116</span>|</span><br><span class="line">|  <span class="number">1143</span>|    <span class="number">70</span>|</span><br><span class="line">|  <span class="number">1270</span>|    <span class="number">78</span>|</span><br><span class="line">|  <span class="number">1322</span>|   <span class="number">208</span>|</span><br><span class="line">|  <span class="number">1339</span>|   <span class="number">385</span>|</span><br><span class="line">+------+------+</span><br><span class="line">only showing top <span class="number">20</span> rows</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Flume安装与使用">Flume安装与使用</h2>
<p>==1、<strong>上传安装包，解压配置</strong>==</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">tar <span class="operator">-</span>zxvf apache<span class="operator">-</span>flume<span class="number">-1.9</span><span class="number">.0</span><span class="operator">-</span>bin.tar.gz</span><br><span class="line">mv apache<span class="operator">-</span>flume<span class="number">-1.8</span><span class="number">.0</span><span class="operator">-</span>bin flume</span><br><span class="line">修改配置文件</span><br><span class="line">cp flume<span class="operator">-</span>env.sh.template flume<span class="operator">-</span>env.sh</span><br><span class="line">vim flume<span class="operator">-</span>env.sh</span><br><span class="line">export JAVA_HOME<span class="operator">=</span><span class="operator">/</span>usr<span class="operator">/</span><span class="keyword">local</span><span class="operator">/</span>src<span class="operator">/</span>jdk</span><br><span class="line">配置环境变量</span><br><span class="line">vim <span class="operator">/</span>etc<span class="operator">/</span>profile</span><br><span class="line"></span><br><span class="line">## FLUME_HOME</span><br><span class="line">export FLUME_HOME<span class="operator">=</span><span class="operator">/</span>usr<span class="operator">/</span><span class="keyword">local</span><span class="operator">/</span>flume</span><br><span class="line">export PATH<span class="operator">=</span>$PATH:$FLUME_HOME<span class="operator">/</span>bin</span><br><span class="line">测试 Flume 环境配置</span><br><span class="line">flume<span class="operator">-</span>ng version</span><br></pre></td></tr></table></figure>
<p>==2、<strong>Flume 入门案例</strong>==</p>
<ul>
<li>
<p>采集需求：监控本地指定端口（44444)，采集数据到控制台日志显示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># example.conf</span><br><span class="line"></span><br><span class="line"># 定义Agent的名称、Source、Channel、Sink的名称</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># 配置 Source 组件属性</span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"># 配置 Channel 组件属性</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line"># 内存最大存储的 event 数量</span><br><span class="line">a1.channels.c1.capacity = 10000</span><br><span class="line"># 每次最大从source中拿到sink中的event数量</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 配置 Sink 组件属性</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"># 将源和接收器绑定到通道</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">flume<span class="operator">-</span>ng agent <span class="comment">--name a1 --conf $FLUME_HOME/conf --conf-file $FLUME_HOME/conf/example.conf</span></span><br><span class="line"><span class="operator">-</span>Dflume.root.logger<span class="operator">=</span>INFO,console</span><br><span class="line"></span><br><span class="line"><span class="operator">-</span>n <span class="operator">-</span>c <span class="operator">-</span>f </span><br></pre></td></tr></table></figure>
<p>本地监控需要安装</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nc localhost <span class="number">44444</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>监控指定目录采集数据保存到HDFS</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">a1表示代理名称</span></span><br><span class="line">a1.sources=s1</span><br><span class="line">a1.sinks=k1</span><br><span class="line">a1.channels=c1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置source1  监控目录是否有文件数据生成</span></span><br><span class="line">a1.sources.s1.type=spooldir</span><br><span class="line">a1.sources.s1.spoolDir=/opt/datas/flume/TestDir</span><br><span class="line">a1.sources.s1.channels=c1</span><br><span class="line">a1.sources.s1.fileHeader = false</span><br><span class="line">a1.sources.s1.interceptors = i1</span><br><span class="line">a1.sources.s1.interceptors.i1.type = timestamp</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置sink1  将检测到的数据sink到hdfs上</span></span><br><span class="line">a1.sinks.k1.type=hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path=hdfs://bigdata.ibeifeng.com:8020/flume</span><br><span class="line">a1.sinks.k1.hdfs.fileType=DataStream</span><br><span class="line">a1.sinks.k1.hdfs.writeFormat=TEXT</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">600s后hdfs上文件才没有tmp，否则有，有tmp则不能看</span></span><br><span class="line">a1.sinks.k1.hdfs.rollInterval=60</span><br><span class="line">a1.sinks.k1.channel=c1</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix=%Y-%m-%d</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">通道是以内存方式存储</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置channel1</span></span><br><span class="line">a1.channels.c1.type=memory</span><br><span class="line">a1.channels.c1.capacity=10000</span><br><span class="line">a1.channels.c1.transactionCapacity=100</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels=c1</span><br><span class="line">a1.sinks.k1.channel=c1</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>监控指定文件采集数据保存到HDFS</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a1<span class="selector-class">.sources</span><span class="selector-class">.r1</span>.type=exec</span><br><span class="line">a1<span class="selector-class">.sources</span><span class="selector-class">.r1</span>.command=tail -F /opt/data/t1<span class="selector-class">.txt</span></span><br><span class="line"></span><br><span class="line">a1<span class="selector-class">.sinks</span><span class="selector-class">.k1</span><span class="selector-class">.hdfs</span>.path= hdfs:<span class="comment">//master:8020/flume/%Y-%m-%d/%H</span></span><br><span class="line">a1<span class="selector-class">.sinks</span><span class="selector-class">.k1</span><span class="selector-class">.hdfs</span><span class="selector-class">.roundUnit</span> = hour</span><br><span class="line">a1<span class="selector-class">.sinks</span><span class="selector-class">.k1</span><span class="selector-class">.hdfs</span><span class="selector-class">.useLocalTimeStamp</span> = true</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Namenode 端口:</span><br><span class="line"><span class="number">2.</span>x端口	<span class="number">3.</span>x端口	name	<span class="keyword">desc</span></span><br><span class="line"><span class="number">50470</span>	<span class="number">9871</span>	dfs.namenode.https<span class="operator">-</span>address	The namenode secure http server address <span class="keyword">and</span> port.</span><br><span class="line"><span class="number">50070</span>	<span class="number">9870</span>	dfs.namenode.http<span class="operator">-</span>address	The address <span class="keyword">and</span> the base port <span class="keyword">where</span> the dfs namenode web ui will listen on.</span><br><span class="line"><span class="number">8020</span>	<span class="number">9820</span>	fs.defaultFS	指定HDFS运行时nameNode地址</span><br><span class="line">Secondary NN 端口:</span><br><span class="line"><span class="number">2.</span>x端口	<span class="number">3.</span>x端口	name	<span class="keyword">desc</span></span><br><span class="line"><span class="number">50091</span>	<span class="number">9869</span>	dfs.namenode.secondary.https<span class="operator">-</span>address	The secondary namenode HTTPS server address <span class="keyword">and</span> port</span><br><span class="line"><span class="number">50090</span>	<span class="number">9868</span>	dfs.namenode.secondary.http<span class="operator">-</span>address	The secondary namenode HTTPS server address <span class="keyword">and</span> port</span><br><span class="line">Datanode 端口:</span><br><span class="line"><span class="number">2.</span>x端口	<span class="number">3.</span>x端口	name	<span class="keyword">desc</span></span><br><span class="line"><span class="number">50020</span>	<span class="number">9867</span>	dfs.datanode.ipc.address	The datanode ipc server address <span class="keyword">and</span> port.</span><br><span class="line"><span class="number">50010</span>	<span class="number">9866</span>	dfs.datanode.address	The datanode server address <span class="keyword">and</span> port <span class="keyword">for</span> data transfer.</span><br><span class="line"><span class="number">50475</span>	<span class="number">9865</span>	dfs.datanode.https.address	The datanode secure http server address <span class="keyword">and</span> port</span><br><span class="line"><span class="number">50075</span>	<span class="number">9864</span>	dfs.datanode.http.address	The datanode http server address <span class="keyword">and</span> por</span><br><span class="line">Yarn 端口</span><br><span class="line"><span class="number">2.</span>x端口	<span class="number">3.</span>x端口	name	<span class="keyword">desc</span></span><br><span class="line"><span class="number">8088</span>	<span class="number">8088</span>	yarn.resourcemanager.webapp.address	http服务端口</span><br></pre></td></tr></table></figure>
<h2 id="Linux权限">Linux权限</h2>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_63992711/article/details/127042653">https://blog.csdn.net/qq_63992711/article/details/127042653</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rwx rw- r-- 这就是 111 110 100 最终即 764 权限。</span><br><span class="line"></span><br><span class="line">修改file.txt文件的权限分配设置为 rwx rw- r-- 就可以操作为 chmod 764 file.txt</span><br></pre></td></tr></table></figure>
<h4 id=""></h4>
<h1>模块B：数据分析(30分)</h1>
<blockquote>
<p>花了两天把省赛样题一做了一遍，感觉还不错，难点就是在前期的数据的处理上，对于所处数据的格式要有分辨，是对列处理，还是对表处理。另外对数据异常值和空值的处理时候会出现问题，就可以用替换的方式,fillna处理的时候要注意替换成数值类型的时候，需要将源数据的格式astype为数值类型。对于画图这里，其实还是对数据进行处理，难点就是对于轴处理和值处理，对于x,y最好还是zip一下或者enumerate。这一模块练的就是对数据的敏感性，还是得多刷点算法题练思维</p>
</blockquote>
<h2 id="省赛样卷一：模块B">省赛样卷一：模块B</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用来正常显示中文标签，SimHei是黑体的英文名称</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line"><span class="comment"># 解决符号显示为方块的问题</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h3 id="任务1：数据读取（1分）">任务1：数据读取（1分）</h3>
<blockquote>
<p>这里任务书说着是只读取一个文件，到比赛很可能就是读取两张表进行合并</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">任务1：数据读取（1分）</span></span><br><span class="line"><span class="string">• 载入 movies.csv 文件，数据路径为 ../data/movies.csv • 结果以变量data保存</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">data1 = pd.read_csv(<span class="string">&#x27;tmdb_5000_movies.csv&#x27;</span>)</span><br><span class="line">data2 = pd.read_csv(<span class="string">&#x27;tmdb_5000_credits.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># 合并表</span></span><br><span class="line">data = data1.merge(data2,how=<span class="string">&#x27;left&#x27;</span>, left_on=<span class="string">&#x27;id&#x27;</span>, right_on=<span class="string">&#x27;movie_id&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这里合并完成之后可能会有重复的列，python会自动识别然后添加_x,_y这种的字段，比赛的时候要看清楚，这里可以自定义删除和重命名</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data.rename(&#123;<span class="string">&#x27;title_x&#x27;</span>:t1,<span class="string">&#x27;title_y&#x27;</span>:t2&#125;,inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 删除有多种方式</span></span><br><span class="line"><span class="keyword">del</span> data[<span class="string">&#x27;title_x&#x27;</span>]</span><br><span class="line">data.drop(columns=[<span class="string">&#x27;title_x&#x27;</span>,<span class="string">&#x27;title_y&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>合并完表之后可以重置索引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = data.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#data.index += 1</span></span><br></pre></td></tr></table></figure>
<p>做完这一部分之后可以保存一些防止后期用到</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.to_csv(<span class="string">&#x27;movie.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="任务2：数据处理（9分）">任务2：数据处理（9分）</h3>
<h4 id="任务2-1（1分）">任务2-1（1分）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">删除指定字段，具体要求如下：</span></span><br><span class="line"><span class="string">•	删除homepage, original_title, overview, spoken_languages, status, tagline, movie_id字段</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">data.drop(columns=[<span class="string">&#x27;homepage&#x27;</span>, <span class="string">&#x27;original_title&#x27;</span>, <span class="string">&#x27;overview&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;spoken_languages&#x27;</span>, <span class="string">&#x27;status&#x27;</span>, <span class="string">&#x27;tagline&#x27;</span>, <span class="string">&#x27;movie_id&#x27;</span>],inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h4 id="任务2-2（1分）">任务2-2（1分）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">增加profit字段，该字段为每部电影的收益，具体要求如下：</span></span><br><span class="line"><span class="string">•	计算每部电影的收益，收益=电影票房-电影预算</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">data.loc[:,<span class="string">&#x27;profit&#x27;</span>] = data[<span class="string">&#x27;revenue&#x27;</span>] - data[<span class="string">&#x27;budget&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h4 id="任务2-4（1分）">任务2-4（1分）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">处理runtime字段的缺失值，该字段有两个缺失值，具体要求如下：</span></span><br><span class="line"><span class="string">•	将id为370980的缺失值填充为98</span></span><br><span class="line"><span class="string">•	将id为459488的缺失值填充为81</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 先查看数据类型</span></span><br><span class="line">data[<span class="string">&#x27;runtime&#x27;</span>].dtype</span><br><span class="line"><span class="comment"># 如果不是数值类型就改成数值类型</span></span><br><span class="line">data[<span class="string">&#x27;runtime&#x27;</span>] = data[<span class="string">&#x27;runtime&#x27;</span>].astype(<span class="built_in">float</span>)</span><br><span class="line"><span class="comment"># 查看空值</span></span><br><span class="line">data[data[<span class="string">&#x27;runtime&#x27;</span>].isnull()]</span><br><span class="line"><span class="comment"># 查看非空值</span></span><br><span class="line">data[~data[<span class="string">&#x27;runtime&#x27;</span>].isnull()]</span><br><span class="line"><span class="comment">#填充</span></span><br><span class="line">data.loc[(data[<span class="string">&#x27;runtime&#x27;</span>].isnull()) &amp; (data[<span class="string">&#x27;id&#x27;</span>] == <span class="number">370980</span>),<span class="string">&#x27;runtime&#x27;</span>] = <span class="number">98</span></span><br><span class="line">data.loc[(data[<span class="string">&#x27;runtime&#x27;</span>].isnull()) &amp; (data[<span class="string">&#x27;id&#x27;</span>] == <span class="number">459488</span>),<span class="string">&#x27;runtime&#x27;</span>] = <span class="number">81</span></span><br></pre></td></tr></table></figure>
<p>这里遇到些问题还没解决，就是对于缺失值处理我是用<code>fillna</code>函数，并且在格式正确的情况下，inplace=True不生效，查了查百度是因为链式原因，多次调用了指定的id，那就麻烦点直接对原始数据进行替换。</p>
<p>如果填充的时候报错可能是索引的问题去重新搞一下索引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h4 id="任务2-5（2分）">任务2-5（2分）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">分别对genres, keywords, production_companies, production_countries字段进行处理，具体要求如下：</span></span><br><span class="line"><span class="string">•	每个字段只保留该字段内容中name键值对应的value值，并以|分隔</span></span><br><span class="line"><span class="string">提示：例如[&#123;&quot;id&quot;: 28, &quot;name&quot;: &quot;Action&quot;&#125;, &#123;&quot;id&quot;: 12, &quot;name&quot;: &quot;Adventure&quot;&#125;, &#123;&quot;id&quot;: 14, &quot;name&quot;: &quot;Fantasy&quot;&#125;, &#123;&quot;id&quot;: 878, &quot;name&quot;: &quot;Science Fiction&quot;&#125;]，处理后变为Action|Adventure|Fantasy|Science Fiction</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 这里需要导入json</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将字符串装成字典列表类型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">task2_5</span>(<span class="params">datas</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(datas, <span class="built_in">str</span>):</span><br><span class="line">        datas = json.loads(datas)</span><br><span class="line">    names = [i[<span class="string">&#x27;name&#x27;</span>] <span class="keyword">for</span> i <span class="keyword">in</span> datas]</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;|&#x27;</span>.join(names)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用</span></span><br><span class="line">data[<span class="string">&#x27;genres&#x27;</span>] = data[<span class="string">&#x27;genres&#x27;</span>].apply(task2_5)</span><br><span class="line">data[<span class="string">&#x27;keywords&#x27;</span>] = data[<span class="string">&#x27;keywords&#x27;</span>].apply(task2_5)</span><br><span class="line">data[<span class="string">&#x27;production_companies&#x27;</span>] = data[<span class="string">&#x27;production_companies&#x27;</span>].apply(task2_5)</span><br><span class="line">data[<span class="string">&#x27;production_countries&#x27;</span>] = data[<span class="string">&#x27;production_countries&#x27;</span>].apply(task2_5)</span><br></pre></td></tr></table></figure>
<h4 id="任务2-6（2分）">任务2-6（2分）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">对crew字段进行处理，具体要求如下：</span></span><br><span class="line"><span class="string">•	只保留导演的名字，并以|分隔</span></span><br><span class="line"><span class="string">•	将crew字段列名改为director</span></span><br><span class="line"><span class="string">提示：导演的job为Director</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">task2_6</span>(<span class="params">datas</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(datas, <span class="built_in">str</span>):</span><br><span class="line">        datas = json.loads(datas)</span><br><span class="line">    names = [i[<span class="string">&#x27;name&#x27;</span>] <span class="keyword">for</span> i <span class="keyword">in</span> datas <span class="keyword">if</span> i[<span class="string">&#x27;job&#x27;</span>] == <span class="string">&#x27;Director&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;|&#x27;</span>.join(names)</span><br><span class="line">data[<span class="string">&#x27;crew&#x27;</span>] = data[<span class="string">&#x27;crew&#x27;</span>].apply(task2_6)</span><br><span class="line">data.rename(columns=&#123;<span class="string">&#x27;crew&#x27;</span>:<span class="string">&#x27;director&#x27;</span>&#125;,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>最后保存</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.to_csv(<span class="string">&#x27;movie2.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="任务3：数据可视化（20分）">任务3：数据可视化（20分）</h3>
<h4 id="任务3-1（2分）">任务3-1（2分）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">对电影的关键词制作词云图</span></span><br><span class="line"><span class="string">•	成功制作词云图（1分）</span></span><br><span class="line"><span class="string">•	词云图图形为video（1分）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 这里可以导入jieba进行分词,PIL进行img获取</span></span><br><span class="line"><span class="comment"># import jieba</span></span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> colors</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">keywords_res = keywords.<span class="built_in">str</span>.split(<span class="string">&#x27;|&#x27;</span>).explode().unique()</span><br><span class="line">key_res = <span class="string">&#x27; &#x27;</span>.join(keywords_res)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置版图口罩</span></span><br><span class="line">video_mask = np.array(Image.<span class="built_in">open</span>(<span class="string">&#x27;./img/map.jpg&#x27;</span>))</span><br><span class="line">color_list = [<span class="string">&#x27;black&#x27;</span>,<span class="string">&#x27;red&#x27;</span>,<span class="string">&#x27;orange&#x27;</span>]</span><br><span class="line">colormap = colors.ListedColormap(color_list)</span><br><span class="line"></span><br><span class="line">wordclound = WordCloud(</span><br><span class="line">    mask = video_mask,</span><br><span class="line">    background_color=<span class="string">&#x27;white&#x27;</span>,</span><br><span class="line">    colormap=colormap</span><br><span class="line">).generate(key_res)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line">plt.imshow(wordclound, interpolation=<span class="string">&#x27;bilinear&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(<span class="string">&#x27;wordcloud_map.png&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>词云图绘制要注意几个问题，最终genreate_from_text一定是以空格隔开的文本文字，如果比赛的时候提供了jieba包就可以</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">这里text是一维的列表格式</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">cut = jieba.cut(text)</span><br><span class="line">string = <span class="string">&#x27; &#x27;</span>.join(cut)</span><br></pre></td></tr></table></figure>
<p>如果需要自动化保存n张图片可以使用随机数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ranInt = random.randint(<span class="number">1</span>,<span class="number">1000000</span>)</span><br><span class="line"></span><br><span class="line">plt.savefig(<span class="string">f&#x27;./static/cloud/<span class="subst">&#123;ranInt&#125;</span>.png&#x27;</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="string">f&#x27;./static/cloud/<span class="subst">&#123;ranInt&#125;</span>.png&#x27;</span></span><br></pre></td></tr></table></figure>
<h4 id="任务3-2（2分）">任务3-2（2分）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">制作电影的时长频率分布直方图</span></span><br><span class="line"><span class="string">•	直方图图形类型正确（0.5分）</span></span><br><span class="line"><span class="string">•	直方图颜色为蓝色，透明度为 0.5，框线为黑色（0.5分）</span></span><br><span class="line"><span class="string">•	概率密度曲线以虚线表示（0.5分）</span></span><br><span class="line"><span class="string">•	X轴和Y轴标签正确，左轴为直方图Y轴，右侧为概率密度曲线轴（0.5分）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># 绘制直方图</span></span><br><span class="line"><span class="string">n, bins, patches = plt.hist(runtimes, bins=20, color=&#x27;skyblue&#x27;, alpha=0.5, edgecolor=&#x27;black&#x27;, density=True)			# 这里的density=True是显示频率，False是频数</span></span><br><span class="line"><span class="string"># 计算组距</span></span><br><span class="line"><span class="string">bin_width = bins[1] - bins[0]</span></span><br><span class="line"><span class="string"># 计算频率/组距</span></span><br><span class="line"><span class="string">frequency = n / bin_width</span></span><br><span class="line"><span class="string"># 计算频率密度</span></span><br><span class="line"><span class="string">total_count = len(runtimes)</span></span><br><span class="line"><span class="string">density = frequency / total_count</span></span><br><span class="line"><span class="string"># 计算频率密度</span></span><br><span class="line"><span class="string"># freq_density = n / (len(runtimes) * bin_width)</span></span><br><span class="line"><span class="string"># 打印频率/组距和频率密度</span></span><br><span class="line"><span class="string">print(&quot;频率/组距:&quot;, frequency)</span></span><br><span class="line"><span class="string">print(&quot;频率密度1:&quot;, density)</span></span><br><span class="line"><span class="string">print(&quot;频率密度2:&quot;, freq_density)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">runtimes = data[<span class="string">&#x27;runtime&#x27;</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>), dpi=<span class="number">120</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;电影时长频率分布直方图&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;电影时长&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;频率/组距&#x27;</span>)</span><br><span class="line"></span><br><span class="line">n,  bins, p = plt.hist(runtime,bins=<span class="number">32</span>, color=<span class="string">&#x27;skyblue&#x27;</span>, alpha=<span class="number">0.5</span>, density=<span class="literal">True</span>, edgecolor=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax2 = plt.twinx()</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;频率密度&#x27;</span>)</span><br><span class="line">ax2.plot(bins[:-<span class="number">1</span>],n, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">ax2.legend([<span class="string">&#x27;频率密度&#x27;</span>], loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>分化子图：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">n, bins, patches = plt.hist(runtimes, bins=<span class="number">20</span>, color=<span class="string">&#x27;blue&#x27;</span>, alpha=<span class="number">0.5</span>, edgecolor=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">bin_width = bins[<span class="number">1</span>] - bins[<span class="number">0</span>]</span><br><span class="line">freq_density = n / (<span class="built_in">len</span>(runtimes) * bin_width)</span><br><span class="line">fig, ax1 = plt.subplots()</span><br><span class="line">ax2 = ax1.twinx()</span><br><span class="line">ax2.plot(bins[:-<span class="number">1</span>], freq_density, linestyle=<span class="string">&#x27;--&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;电影时长（分钟）&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;频率/组距&#x27;</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;频率密度&#x27;</span>)</span><br><span class="line">ax2.legend([<span class="string">&#x27;频率密度&#x27;</span>], loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务3-3（2分）">任务3-3（2分）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">制作电影产地分布玫瑰图</span></span><br><span class="line"><span class="string">•	统计不同产地的电影数量，电影数量低于前五的产地，全部归为others</span></span><br><span class="line"><span class="string">•	成功制作玫瑰图（0.5分）</span></span><br><span class="line"><span class="string">•	标题为电影产地分布（0.5分）</span></span><br><span class="line"><span class="string">•	标签数值正确（0.5分）</span></span><br><span class="line"><span class="string">•	标签为国家：百分比，百分比保留两位小数，例如：Canada: 2.53%（0.5分）</span></span><br><span class="line"><span class="string">Canada: 2.53%，此数据为虚构的，真实数值需要自行计算</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">task3_3 = data[<span class="string">&#x27;production_countries&#x27;</span>].<span class="built_in">str</span>.split(<span class="string">&#x27;|&#x27;</span>).apply(np.unique).explode()</span><br><span class="line">task3_3 = task3_3.value_counts()</span><br><span class="line">top5 = task3_3.head(<span class="number">5</span>)</span><br><span class="line">other = task3_3[~task3_3.index.isin(top5.index)]</span><br><span class="line">other = pd.Series(other.<span class="built_in">sum</span>(), index=[<span class="string">&#x27;other&#x27;</span>])</span><br><span class="line">task3_3_1 = top5.append(other)</span><br><span class="line"></span><br><span class="line">x = task3_3_1.index</span><br><span class="line">y = (task3_3_1 / task3_3_1.<span class="built_in">sum</span>() * <span class="number">100</span>).<span class="built_in">round</span>(<span class="number">2</span>).values</span><br><span class="line"></span><br><span class="line">res = [[a,<span class="built_in">float</span>(b)] <span class="keyword">for</span> a,b <span class="keyword">in</span> <span class="built_in">zip</span>(x,y)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Pie</span><br><span class="line"></span><br><span class="line">c = (</span><br><span class="line">    Pie()</span><br><span class="line">    .add(</span><br><span class="line">        series_name=<span class="string">&quot;&quot;</span>,</span><br><span class="line">        data_pair=res,</span><br><span class="line">        radius=[<span class="string">&#x27;30%&#x27;</span>,<span class="string">&#x27;50%&#x27;</span>],</span><br><span class="line">        start_angle=<span class="number">21</span>,</span><br><span class="line">        rosetype=<span class="literal">True</span>,</span><br><span class="line">        label_opts=options.LabelOpts(is_show=<span class="literal">True</span>,formatter=<span class="string">&#x27;&#123;b&#125;:&#123;d&#125;%&#x27;</span>)</span><br><span class="line">    )</span><br><span class="line">    .set_global_opts(</span><br><span class="line">        title_opts=options.TitleOpts(is_show=<span class="literal">True</span>, title=<span class="string">&#x27;电影产地分布&#x27;</span>)</span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">c.render_notebook()</span><br></pre></td></tr></table></figure>
<p>isin的反函数是<code>~</code> ，isin是一个非常好用的判断存在与否的函数，多用反正思维来做，比正向节省许多代码量</p>
<h4 id="任务3-4（2分）">任务3-4（2分）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">统计票房均值Top10的导演，并以条形图展示</span></span><br><span class="line"><span class="string">•	票房均值以整数表示，四舍五入</span></span><br><span class="line"><span class="string">•	标题为票房排名Top10的导演（0.5分）</span></span><br><span class="line"><span class="string">•	标签数值正确（0.5分）</span></span><br><span class="line"><span class="string">•	标签位置放置右侧（0.5分）</span></span><br><span class="line"><span class="string">•	纵坐标导演名字显示完全（0.5分）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">task3_4 = data[[<span class="string">&#x27;director&#x27;</span>,<span class="string">&#x27;revenue&#x27;</span>]].groupby(<span class="string">&#x27;director&#x27;</span>).agg(&#123;<span class="string">&#x27;revenue&#x27;</span>:<span class="string">&#x27;mean&#x27;</span>&#125;).astype(<span class="string">&#x27;int64&#x27;</span>).sort_values(by=<span class="string">&#x27;revenue&#x27;</span>).tail(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">x = task3_4.index</span><br><span class="line">y = task3_4.values.flatten()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>), dpi=<span class="number">120</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;票房排名Top10的导演&#x27;</span>, loc=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim(<span class="number">0</span>, <span class="number">1500000000</span>)</span><br><span class="line">plt.xticks(np.arange(<span class="number">0</span>, <span class="number">1700000000</span>, <span class="number">300000000</span>))</span><br><span class="line"></span><br><span class="line">plt.gca().spines[<span class="string">&#x27;right&#x27;</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">plt.gca().spines[<span class="string">&#x27;top&#x27;</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">plt.barh(x, y, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="任务3-5（2分）">任务3-5（2分）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">分析原创电影与改编电影在收益、票房、预算方面的表现，以旋风图展示：</span></span><br><span class="line"><span class="string">•	成功制作旋风图（0.5分）</span></span><br><span class="line"><span class="string">•	旋风图标签数值正确，以万为单位，取整数（四舍五入）（0.5分）</span></span><br><span class="line"><span class="string">•	标题为原创电影与改编电影对比图（万）（0.5分）</span></span><br><span class="line"><span class="string">•	添加图例（0.5分）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">x1 = np.array([<span class="number">47</span>, <span class="number">23</span>, <span class="number">21</span>, <span class="number">19</span>,  <span class="number">7</span>])</span><br><span class="line">x2 = np.array([<span class="number">17</span>, <span class="number">33</span>, <span class="number">11</span>, <span class="number">2</span>,  <span class="number">17</span>])</span><br><span class="line">y = np.arange(<span class="number">5</span>)</span><br><span class="line">labels=[<span class="string">&#x27;&#x27;</span>,<span class="string">&#x27;特征1&#x27;</span>,<span class="string">&#x27;特征2&#x27;</span>,<span class="string">&#x27;特征三&#x27;</span>,<span class="string">&#x27;特征四&#x27;</span>,<span class="string">&#x27;特征五&#x27;</span>]</span><br><span class="line"><span class="comment"># fig, ax1 = plt.subplots()</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">ax1 = fig.add_subplot()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ax2 = ax1.twinx()</span></span><br><span class="line"><span class="comment">#plot</span></span><br><span class="line">ax1.barh(y, x1,<span class="number">0.8</span>,color =<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;改变&#x27;</span>)</span><br><span class="line">ax1.barh(y, -x2,<span class="number">0.8</span>,color =<span class="string">&#x27;k&#x27;</span>, label=<span class="string">&#x27;远程&#x27;</span>)</span><br><span class="line">ax1.set_yticklabels(labels,fontsize=<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line">ax1.set_xlim(-<span class="number">60</span>,<span class="number">60</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#setting</span></span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;竞品分析&#x27;</span>,color=<span class="string">&#x27;k&#x27;</span>,fontsize=<span class="number">16</span>)</span><br><span class="line"><span class="comment"># ax1.set_ylabel(&#x27;竞品分析&#x27;, color=&#x27;k&#x27;,fontsize=16)</span></span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> a,b <span class="keyword">in</span> <span class="built_in">zip</span>(x1,y):</span><br><span class="line">    plt.text(a+<span class="number">5</span>, b, <span class="string">&#x27;%0.00f&#x27;</span> % a, ha=<span class="string">&#x27;center&#x27;</span>, va= <span class="string">&#x27;center&#x27;</span>,fontsize=<span class="number">16</span>,color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> a,b <span class="keyword">in</span> <span class="built_in">zip</span>(x2,y):</span><br><span class="line">    plt.text(-a-<span class="number">5</span>, b, <span class="string">&#x27;%0.00f&#x27;</span> % a, ha=<span class="string">&#x27;center&#x27;</span>, va= <span class="string">&#x27;center&#x27;</span>,fontsize=<span class="number">16</span>,color=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="任务3-6（2分）">任务3-6（2分）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">统计各种电影类型所占的比例，以饼图展示</span></span><br><span class="line"><span class="string">•	设置other类，当电影类型所占比例小于%1时，全部归到other类中（0.5分）</span></span><br><span class="line"><span class="string">•	所占比例小于或等于%2时，对应的饼状图往外突出一截（0.5分）</span></span><br><span class="line"><span class="string">•	数值正确，百分比保留一位小数（0.5分）</span></span><br><span class="line"><span class="string">•	标题为各种电影类型所占的比例（0.5分）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">task3_6 = data[<span class="string">&#x27;genres&#x27;</span>].<span class="built_in">str</span>.split(<span class="string">&#x27;|&#x27;</span>).apply(np.unique).explode()</span><br><span class="line">task3_6 = task3_6[task3_6.apply(<span class="keyword">lambda</span> x : <span class="built_in">len</span>(x) &gt; <span class="number">0</span>)].reset_index(drop=<span class="literal">True</span>).value_counts()</span><br><span class="line"></span><br><span class="line">task3_6_1 = (task3_6 / task3_6.<span class="built_in">sum</span>() * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">other = task3_6_1[task3_6_1 &lt; <span class="number">1</span>].<span class="built_in">sum</span>().<span class="built_in">round</span>(<span class="number">1</span>)</span><br><span class="line">other = pd.Series(other, index=[<span class="string">&#x27;other&#x27;</span>])</span><br><span class="line"></span><br><span class="line">res = task3_6_1[task3_6_1 &gt; <span class="number">1</span>].<span class="built_in">round</span>(<span class="number">1</span>).append(other)</span><br><span class="line">x = res.index</span><br><span class="line">y = res.values</span><br><span class="line">explode = [<span class="number">0.1</span> <span class="keyword">if</span> i &lt;= <span class="number">2</span> <span class="keyword">else</span> <span class="number">0.02</span> <span class="keyword">for</span> i <span class="keyword">in</span> y]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>),dpi=<span class="number">120</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;各种电影类型所占的比例&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.pie(y,labels=x,explode=explode, autopct=<span class="string">&#x27;%.1f%%&#x27;</span>, startangle=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="任务3-7（2分）">任务3-7（2分）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">任务3-7（2分）</span></span><br><span class="line"><span class="string">统计电影风格（类型）Top5随时间（1980年至今）的变化趋势，以折线图展示</span></span><br><span class="line"><span class="string">•	折线图设置为顺滑模式（0.5分）</span></span><br><span class="line"><span class="string">•	标题和图例不能重叠（0.5分）</span></span><br><span class="line"><span class="string">•	数据起点和纵坐标没有间隙（0.5分）</span></span><br><span class="line"><span class="string">•	为最大值做标记（0.5分）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">task3_7 = data[[<span class="string">&#x27;genres&#x27;</span>,<span class="string">&#x27;year&#x27;</span>]]</span><br><span class="line">task3_7 = task3_7[task3_7[<span class="string">&#x27;genres&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="built_in">len</span>(x) &gt; <span class="number">0</span>)].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">task3_7[<span class="string">&#x27;genres&#x27;</span>] = task3_7[<span class="string">&#x27;genres&#x27;</span>].<span class="built_in">str</span>.split(<span class="string">&#x27;|&#x27;</span>).apply(np.unique)</span><br><span class="line"></span><br><span class="line">top5_index= task3_7[<span class="string">&#x27;genres&#x27;</span>].explode().value_counts().nlargest(<span class="number">5</span>).index</span><br><span class="line"></span><br><span class="line">task3_7_1 = task3_7.explode(column=[<span class="string">&#x27;genres&#x27;</span>])</span><br><span class="line">task3_7_1[<span class="string">&#x27;number&#x27;</span>] = <span class="number">1</span></span><br><span class="line">task3_7_1 = task3_7_1[task3_7_1[<span class="string">&#x27;genres&#x27;</span>].isin(top5_index)]</span><br><span class="line"></span><br><span class="line">task3_7_2 = task3_7_1.pivot_table(index=[<span class="string">&#x27;year&#x27;</span>], columns=[<span class="string">&#x27;genres&#x27;</span>],values=[<span class="string">&#x27;number&#x27;</span>],aggfunc=<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line"></span><br><span class="line">x = task3_7_2.index</span><br><span class="line"></span><br><span class="line">y1 = task3_7_2[<span class="string">&#x27;number&#x27;</span>][<span class="string">&#x27;Action&#x27;</span>]</span><br><span class="line">y2 = task3_7_2[<span class="string">&#x27;number&#x27;</span>][<span class="string">&#x27;Comedy&#x27;</span>]</span><br><span class="line">y3 = task3_7_2[<span class="string">&#x27;number&#x27;</span>][<span class="string">&#x27;Drama&#x27;</span>]</span><br><span class="line">y4 = task3_7_2[<span class="string">&#x27;number&#x27;</span>][<span class="string">&#x27;Romance&#x27;</span>]</span><br><span class="line">y5 = task3_7_2[<span class="string">&#x27;number&#x27;</span>][<span class="string">&#x27;Thriller&#x27;</span>]</span><br><span class="line"></span><br><span class="line">y1.fillna(<span class="number">0</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">y2.fillna(<span class="number">0</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">y3.fillna(<span class="number">0</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">y4.fillna(<span class="number">0</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">y5.fillna(<span class="number">0</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">max_id = y3.idxmax()</span><br><span class="line">max_value = <span class="built_in">int</span>(y3.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> make_interp_spline</span><br><span class="line"></span><br><span class="line">x_smooth = np.linspace(<span class="built_in">int</span>(x.<span class="built_in">min</span>()), <span class="built_in">int</span>(x.<span class="built_in">max</span>()), <span class="number">400</span>)</span><br><span class="line">y1_smooth = make_interp_spline(x,y1)(x_smooth)</span><br><span class="line">y2_smooth = make_interp_spline(x,y2)(x_smooth)</span><br><span class="line">y3_smooth = make_interp_spline(x,y3)(x_smooth)</span><br><span class="line">y4_smooth = make_interp_spline(x,y4)(x_smooth)</span><br><span class="line">y5_smooth = make_interp_spline(x,y5)(x_smooth)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>),dpi=<span class="number">120</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;电影风格（类型）Top5随时间（1980年至今）的变化趋势&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.ylim(<span class="number">0</span>,<span class="number">150</span>)</span><br><span class="line">plt.yticks(np.arange(<span class="number">0</span>,<span class="number">180</span>,<span class="number">30</span>))</span><br><span class="line">plt.xlim(<span class="number">1980</span>,<span class="number">2017</span>)</span><br><span class="line">plt.xticks(np.arange(<span class="number">1980</span>,<span class="number">2018</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">plt.plot(x_smooth,y1_smooth)</span><br><span class="line">plt.plot(x_smooth,y2_smooth)</span><br><span class="line">plt.plot(x_smooth,y3_smooth)</span><br><span class="line">plt.plot(x_smooth,y4_smooth)</span><br><span class="line">plt.plot(x_smooth,y5_smooth)</span><br><span class="line"></span><br><span class="line">plt.text(max_id,max_value+<span class="number">5</span>,max_value, va=<span class="string">&#x27;bottom&#x27;</span>, ha=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="任务3-8（2分）">任务3-8（2分）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">统计不同风格（类型）电影的收益能力，以条形图和折线图混合展示</span></span><br><span class="line"><span class="string">•	条形图为不同电影类型的收益总和，以千亿为单位，保留两位小数（0.5分）</span></span><br><span class="line"><span class="string">•	折线图为不同电影类型的收益率，收益率=收益/预算（0.5分）</span></span><br><span class="line"><span class="string">•	条形图标签数值正确（0.5分）</span></span><br><span class="line"><span class="string">•	折线图不显示标签数值（0.5分）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">task3_8 = data[[<span class="string">&#x27;genres&#x27;</span>,<span class="string">&#x27;profit&#x27;</span>,<span class="string">&#x27;budget&#x27;</span>]]</span><br><span class="line">task3_8 = task3_8[task3_8[<span class="string">&#x27;genres&#x27;</span>].apply(<span class="keyword">lambda</span> x : <span class="built_in">len</span>(x) &gt; <span class="number">0</span>)].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">task3_8[<span class="string">&#x27;genres&#x27;</span>] = task3_8[<span class="string">&#x27;genres&#x27;</span>].<span class="built_in">str</span>.split(<span class="string">&#x27;|&#x27;</span>)</span><br><span class="line"></span><br><span class="line">task3_8_1 = task3_8.explode(column=<span class="string">&#x27;genres&#x27;</span>).groupby(<span class="string">&#x27;genres&#x27;</span>).agg(<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line">task3_8_1[<span class="string">&#x27;pre&#x27;</span>] = (task3_8_1[<span class="string">&#x27;profit&#x27;</span>] / task3_8_1[<span class="string">&#x27;budget&#x27;</span>] * <span class="number">100</span>)</span><br><span class="line">task3_8_1[<span class="string">&#x27;profit&#x27;</span>] = (task3_8_1[<span class="string">&#x27;profit&#x27;</span>] / <span class="number">100000000000</span>).<span class="built_in">round</span>(<span class="number">2</span>)</span><br><span class="line">task3_8_1 = task3_8_1.sort_values(by=<span class="string">&#x27;profit&#x27;</span>,ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">task3_8_1[<span class="string">&#x27;profit&#x27;</span>] = task3_8_1[<span class="string">&#x27;profit&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="number">0</span> <span class="keyword">if</span>(x == -<span class="number">0.00</span>) <span class="keyword">else</span> x)</span><br><span class="line"></span><br><span class="line">x = task3_8_1.index</span><br><span class="line">y1 = task3_8_1[<span class="string">&#x27;profit&#x27;</span>].values</span><br><span class="line">y2 = task3_8_1[<span class="string">&#x27;pre&#x27;</span>].values</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>),dpi=<span class="number">120</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(rotation=-<span class="number">45</span>, ha=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.ylim(<span class="number">0</span>,<span class="number">1.2</span>)</span><br><span class="line">plt.yticks(np.arange(<span class="number">0</span>,<span class="number">1.4</span>,<span class="number">0.2</span>))</span><br><span class="line">plt.bar(x,y1, color=<span class="string">&#x27;red&#x27;</span>,label=<span class="string">&#x27;收益&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> a,b <span class="keyword">in</span> <span class="built_in">zip</span>(x,y1):</span><br><span class="line">    plt.text(a,b+<span class="number">0.02</span>,b,ha=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">ax2 = plt.twinx()</span><br><span class="line">ax2.set_ylim(-<span class="number">100</span>, <span class="number">300</span>)</span><br><span class="line">ax2.set_yticks(np.arange(-<span class="number">100</span>, <span class="number">350</span>, <span class="number">50</span>))</span><br><span class="line">ax2.set_yticklabels([(<span class="built_in">str</span>(i)+<span class="string">&quot;%&quot;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(-<span class="number">100</span>, <span class="number">350</span>, <span class="number">50</span>)])</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;收益率&#x27;</span>)</span><br><span class="line">ax2.plot(x, y2, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;收益率&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax2.legend(loc=<span class="string">&#x27;upper right&#x27;</span>, bbox_to_anchor=(<span class="number">1</span>, <span class="number">0.95</span>))</span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.gca().spines[<span class="string">&#x27;top&#x27;</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="任务3-9（4分）">任务3-9（4分）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">统计电影类型Top5，以条形图展示</span></span><br><span class="line"><span class="string">•	条形图颜色依次为#BCEE68, #EBBDBF, #D6A5DD, #A020F0, #76CBE8 （0.5分）</span></span><br><span class="line"><span class="string">•	条形图右端添加象形图片，symbols已提前给出，象形图框线为灰色grey （2分）</span></span><br><span class="line"><span class="string">•	标签数值正确（0.5分）</span></span><br><span class="line"><span class="string">•	标签放置条形图右侧，显示完全，不能被遮挡（1分）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">data2 = pd.read_csv(<span class="string">&#x27;movie2.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">data2[<span class="string">&#x27;genres&#x27;</span>] = data2[<span class="string">&#x27;genres&#x27;</span>].<span class="built_in">str</span>.split(<span class="string">&#x27;|&#x27;</span>)</span><br><span class="line">top5_genres = data2.explode(<span class="string">&#x27;genres&#x27;</span>).groupby(<span class="string">&#x27;genres&#x27;</span>).size().reset_index(name=<span class="string">&#x27;number&#x27;</span>)</span><br><span class="line"></span><br><span class="line">top5_res = top5_genres.nlargest(<span class="number">5</span>,columns=<span class="string">&#x27;number&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">genres	number</span></span><br><span class="line"><span class="string">6	Drama	2297</span></span><br><span class="line"><span class="string">3	Comedy	1722</span></span><br><span class="line"><span class="string">17	Thriller	1274</span></span><br><span class="line"><span class="string">0	Action	1154</span></span><br><span class="line"><span class="string">14	Romance	894</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">genres = top5_res[<span class="string">&#x27;genres&#x27;</span>]</span><br><span class="line">number = top5_res[<span class="string">&#x27;number&#x27;</span>]</span><br><span class="line"></span><br><span class="line">colors = [<span class="string">&#x27;#BCEE68&#x27;</span>, <span class="string">&#x27;#EBBDBF&#x27;</span>, <span class="string">&#x27;#D6A5DD&#x27;</span>, <span class="string">&#x27;#A020F0&#x27;</span>, <span class="string">&#x27;#76CBE8&#x27;</span>]</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制条形图</span></span><br><span class="line">ax.barh(genres, number, color=colors, edgecolor=<span class="string">&#x27;grey&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加Unicode字符作为象形图片</span></span><br><span class="line">symbols = [<span class="string">&#x27;⚔️&#x27;</span>, <span class="string">&#x27;🌍&#x27;</span>, <span class="string">&#x27;🧙‍♂️&#x27;</span>, <span class="string">&#x27;🚀&#x27;</span>, <span class="string">&#x27;🐰&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> a,b <span class="keyword">in</span> <span class="built_in">zip</span>(genres,number):</span><br><span class="line">    ax.text(b, a, symbols[i], va=<span class="string">&#x27;center&#x27;</span>, ha=<span class="string">&#x27;left&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;数量&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;电影类型&#x27;</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;电影类型Top5&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">ax.yaxis.set_ticks_position(<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">ax.xaxis.set_ticks_position(<span class="string">&#x27;bottom&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h1>模块C：机器学习</h1>
<blockquote>
<p>四天把机器学习的几种算法过了一遍，难点在特征工程，对于模型的选择只需要明白是回归，分类还是聚类就好了，另外就是对于特征值和目标值的提取需要注意，由于没有数据练，只能找b站的几个数据练了</p>
</blockquote>
<h2 id="特征工程">特征工程</h2>
<h3 id="特征提取">特征提取</h3>
<p>API</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_extraction</span><br></pre></td></tr></table></figure>
<h4 id="1、字典特征提取">1、字典特征提取</h4>
<p>需要先将数据转换成字典类型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转换成字典</span></span><br><span class="line">x = x.to_dict(orient=<span class="string">&quot;recorda&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>需要注意的是调用转换器之后返回的是稀疏矩阵，这里sparse需要设置成false才不会返回sparse</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> feature_extraction <span class="keyword">as</span> fe</span><br><span class="line"></span><br><span class="line">data = [&#123;<span class="string">&#x27;city&#x27;</span>:<span class="string">&#x27;bj&#x27;</span>, <span class="string">&#x27;tem&#x27;</span>:<span class="number">100</span>&#125;,</span><br><span class="line">       &#123;<span class="string">&#x27;city&#x27;</span>:<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;tem&#x27;</span>:<span class="number">300</span>&#125;,</span><br><span class="line">       &#123;<span class="string">&#x27;city&#x27;</span>:<span class="string">&#x27;sd&#x27;</span>, <span class="string">&#x27;tem&#x27;</span>:<span class="number">50</span>&#125;]</span><br><span class="line">transfer = fe.DictVectorizer(sparse=<span class="literal">False</span>)		<span class="comment"># 需要设置成False</span></span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line">data_new</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([[  1.,   0.,   0., 100.],</span></span><br><span class="line"><span class="string">       [  0.,   0.,   1., 300.],</span></span><br><span class="line"><span class="string">       [  0.,   1.,   0.,  50.]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="2、文本特征提取">2、文本特征提取</h4>
<ul>
<li>
<p>英文文本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> feature_extraction <span class="keyword">as</span> fe</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文本特征提取</span></span><br><span class="line">data = [<span class="string">&quot;Lift is short, i like python&quot;</span>,</span><br><span class="line">       <span class="string">&quot;Lift is too long, i dislike sleep&quot;</span>]</span><br><span class="line">transfer = fe.text.CountVectorizer()</span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(data_new.toarray())</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">[[0 1 1 1 0 1 1 0 0]</span></span><br><span class="line"><span class="string"> [1 1 1 0 1 0 0 1 1]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>中文文本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 中文文本提取</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">data = [<span class="string">&#x27;我爱北京天安门&#x27;</span>, <span class="string">&#x27;天安门上太阳升&#x27;</span>]</span><br><span class="line">data_new = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">    data_new.append(<span class="string">&quot; &quot;</span>.join(<span class="built_in">list</span>(jieba.cut(i))))</span><br><span class="line">data_new</span><br><span class="line">transfer = fe.text.CountVectorizer()</span><br><span class="line">data_final = transfer.fit_transform(data_new)</span><br><span class="line">data_final.toarray()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([[1, 1, 0],</span></span><br><span class="line"><span class="string">       [0, 1, 1]], dtype=int64)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>3、TF-IDF</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TFidf文本提取</span></span><br><span class="line">fe.text.TfidfVectorizer().fit_transform(data_new).toarray()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([[0.81480247, 0.57973867, 0.        ],</span></span><br><span class="line"><span class="string">       [0.        , 0.57973867, 0.81480247]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="特征降维">特征降维</h3>
<p>降维是指在某些限定条件下，降低随机变量(特征)的个数，得到一组&quot;不想关&quot;主变量的过程大致就是我如果有三个特征，但是这三个特征之中有两个相关系数非常大，就选择这两者之一</p>
<p>降维之前要注意我所有的列是类似ont-hot一样的编码格式，不能出现英文或者中文</p>
<p>==<strong>降维方式</strong>==</p>
<ul>
<li>特征选择</li>
<li>主成分分析（可以理解一种特征提取的方式）</li>
</ul>
<h4 id="1、特征选择">1、特征选择</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Filter过滤式</span><br><span class="line">- 方差选择法：地方查特征过滤</span><br><span class="line">- 相关系数</span><br><span class="line">  - 衡量特征与特征之间的相关性</span><br><span class="line"></span><br><span class="line">Embeded嵌入式</span><br><span class="line">- 决策树</span><br><span class="line">- 正则化</span><br><span class="line">- 深度学习</span><br></pre></td></tr></table></figure>
<p>==<strong>过滤式</strong>==</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">variance_demo</span>():</span><br><span class="line">    data = pd.read_csv(<span class="string">r&quot;E:\Code\Pywork\Machine\data\factor_returns.csv&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;data:\n&quot;</span>,data)</span><br><span class="line">    data = data.iloc[:, <span class="number">1</span>:-<span class="number">2</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;data:\n&quot;</span>,data)</span><br><span class="line">    <span class="comment"># 这里的threshold是阈值大于它的就会被删去</span></span><br><span class="line">    transfer = VarianceThreshold(threshold=<span class="number">5</span>)</span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;data_new:\n&quot;</span>, data_new, data_new.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    variance_demo()</span><br></pre></td></tr></table></figure>
<p>==<strong>相关系数</strong>==</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">variance_demo</span>():</span><br><span class="line">    data = pd.read_csv(<span class="string">r&quot;E:\Code\Pywork\Machine\data\factor_returns.csv&quot;</span>)</span><br><span class="line">    data = data.iloc[:, <span class="number">1</span>:-<span class="number">2</span>]</span><br><span class="line">    r = pearsonr(data[<span class="string">&#x27;pe_ratio&#x27;</span>],data[<span class="string">&#x27;pb_ratio&#x27;</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;相关系数:&quot;</span>,r)</span><br><span class="line"><span class="comment">#     相关系数: PearsonRResult(statistic=-0.004389322779936274, pvalue=0.8327205496564927)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    variance_demo()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="2、主成分分析-PCA">2、主成分分析(PCA)</h4>
<p>高维转低维</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.decomposition.<span class="keyword">PCA</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>交叉表使用: table = pd.crosstab(data[‘user_id’],data[‘aisle’])</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;array([[0.81480247, 0.57973867, 0.        ],</span></span><br><span class="line"><span class="string">       [0.        , 0.57973867, 0.81480247]])&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> decomposition <span class="keyword">as</span> sd</span><br><span class="line">transfer = sd.PCA(n_components=<span class="number">0.95</span>)	<span class="comment">#小数表示保留多少原始信息，整数表示获取到几维数据</span></span><br><span class="line">data_new = transfer.fit_transform(data2)</span><br><span class="line"><span class="built_in">print</span>(data_new)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">[[ 0.57615236]</span></span><br><span class="line"><span class="string"> [-0.57615236]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="调优">调优</h3>
<h4 id="网格搜索和交叉验证">网格搜索和交叉验证</h4>
<p>API</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection <span class="keyword">as</span> ms</span><br><span class="line">ms.GridSearchCV(model,param_grid=xxx,cv=xxx)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets <span class="keyword">as</span> sd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors <span class="keyword">as</span> sn</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">iris = sd.load_iris()</span><br><span class="line">transfer = PCA(n_components=<span class="number">0.95</span>)</span><br><span class="line"></span><br><span class="line">x = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line">x = transfer.fit_transform(x)</span><br><span class="line"></span><br><span class="line">train_x, test_x, train_y, test_y = ms.train_test_split(x, y, shuffle=<span class="literal">True</span>, random_state=<span class="number">5</span>, train_size=<span class="number">0.75</span>)</span><br><span class="line"></span><br><span class="line">transfer = sp.StandardScaler()</span><br><span class="line">train_x = transfer.fit_transform(train_x)</span><br><span class="line">test_x = transfer.transform(test_x</span><br><span class="line">                            </span><br><span class="line">model = sn.KNeighborsClassifier()</span><br><span class="line">                            </span><br><span class="line">ms.GridSearchCV(model,param_grid=&#123;<span class="string">&quot;n_neighbors&quot;</span>:&#123;<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">11</span>&#125;&#125;,cv=<span class="number">20</span>)</span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line">pred_y = model.predict(test_x)</span><br><span class="line">                            </span><br><span class="line">sm.f1_score(test_y, pred_y, average=<span class="string">&#x27;micro&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="数据预处理">数据预处理</h3>
<h4 id="1、均值移除-标准差标准化">1、<strong>均值移除 (标准差标准化)</strong></h4>
<blockquote>
<p>由于一个样本的不同特征值差异较大，不利于使用现有机器学习算法进行样本处理。<br>
标准差标准化也叫零均值标准化或分数标准化，是当前使用最广泛的数据标准化方法。经过该方法处理的数据均值移除可以让样本矩阵中的每一列的平均值为0，标准差为1。<br>
如何使样本矩阵中的每一列的平均值为0呢？</p>
</blockquote>
<p>$$<br>
X* = （X-mean）/ std<br>
$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn.preprocessing <span class="keyword">as</span> sp</span><br><span class="line"></span><br><span class="line">arr01 = np.array([</span><br><span class="line">    [<span class="number">17</span>, <span class="number">100</span>, <span class="number">4000</span>],</span><br><span class="line">    [<span class="number">20</span>, <span class="number">80</span>, <span class="number">5000</span>],</span><br><span class="line">    [<span class="number">23</span>, <span class="number">75</span>, <span class="number">5500</span>]</span><br><span class="line">])</span><br><span class="line">arr01</span><br><span class="line"><span class="comment"># 调用类，生成实例化对象</span></span><br><span class="line">scaler = sp.StandardScaler()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 先调用fit, 再调用transform()</span></span><br><span class="line">scaler.fit(arr01).transform(arr01)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用fit_transform()</span></span><br><span class="line">std_samples = scaler.fit_transform(arr01)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([[-1.22474487,  1.38873015, -1.33630621],</span></span><br><span class="line"><span class="string">       [ 0.        , -0.46291005,  0.26726124],</span></span><br><span class="line"><span class="string">       [ 1.22474487, -0.9258201 ,  1.06904497]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 逆转</span></span><br><span class="line">scaler.inverse_transform(std_samples)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用方法</span></span><br><span class="line">sp.scale(arr01)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义算法</span></span><br><span class="line">array01_mean = arr01.mean(axis=<span class="number">0</span>)</span><br><span class="line">arr01_new = (arr01-array01_mean)/arr01.std(axis=<span class="number">0</span>)</span><br><span class="line">arr01_new.mean(axis=<span class="number">0</span>)</span><br><span class="line">arr01_new.std(axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">sklearn</span>.preprocessing.StandardScaler(*, copy=<span class="literal">True</span>, with_mean=<span class="literal">True</span>, with_std=<span class="literal">True</span>)</span><br><span class="line">参数：</span><br><span class="line">with_mean：<span class="built_in">bool</span>, default=<span class="literal">True</span>：如果为<span class="literal">True</span>，则在缩放之前将数据居中。这在操作稀疏矩阵时不起作用（并且会引发一个异常），因为将它们居中需要构建一个密集矩阵，在常见的用例中，密集矩阵可能太大而无法容纳在内存中。</span><br><span class="line">with_std：<span class="built_in">bool</span>, default=<span class="literal">True</span>：如果为<span class="literal">True</span>，则将数据缩放为单位方差（或等效的单位标准差）。</span><br><span class="line">属性：</span><br><span class="line">scale_ ：ndarray of shape (n_features,) <span class="keyword">or</span> <span class="literal">None</span>：数据的每个特征相对缩放，以实现零均值和单位方差。通常使用np.sqrt（var）计算。如果方差为零，我们无法实现单位方差，数据保持原样，给出缩放因子<span class="number">1</span>。当with_std=<span class="literal">False</span>时，scale_等于<span class="literal">None</span>。</span><br><span class="line">mean_ ：ndarray of shape (n_features,) <span class="keyword">or</span> <span class="literal">None</span> ：训练集中每个特征的平均值。当_mean=<span class="literal">False</span>时，等于<span class="literal">None</span>。</span><br><span class="line">var_ ：ndarray of shape (n_features,) <span class="keyword">or</span> <span class="literal">None</span>：训练集中每个特征的方差。用于计算scale_ 。当std=<span class="literal">False</span>时，等于<span class="literal">None</span>。</span><br><span class="line">示例：</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler = StandardScaler()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(scaler.fit(data))</span><br><span class="line">StandardScaler()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(scaler.mean_)</span><br><span class="line">[<span class="number">0.5</span> <span class="number">0.5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(scaler.transform(data))</span><br><span class="line">[[-<span class="number">1.</span> -<span class="number">1.</span>]</span><br><span class="line"> [-<span class="number">1.</span> -<span class="number">1.</span>]</span><br><span class="line"> [ <span class="number">1.</span>  <span class="number">1.</span>]</span><br><span class="line"> [ <span class="number">1.</span>  <span class="number">1.</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(scaler.transform([[<span class="number">2</span>, <span class="number">2</span>]]))</span><br><span class="line">[[<span class="number">3.</span> <span class="number">3.</span>]]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="2、范围缩放（离差标准化）">2、<strong>范围缩放（离差标准化）</strong></h4>
<blockquote>
<p>另一种标准化方法是将特征缩放到给定的最小值和最大值之间，通常介于0和1之间，或者将每个特征的最大绝对值缩放到单位大小。这可以分别使用MinMaxScaler或MaxAbsScaler实现。使用这种缩放的动机包括对非常小的特征标准差的鲁棒性，以及在稀疏数据中保持零条目。</p>
<p>将样本矩阵中的每一列的最小值和最大值设定为相同的区间，统一各列特征值的范围。一般情况下会把特征值缩放至[0, 1]区间。</p>
<p>离差标准化是对原始数据的一种线性变换，结果是将原始数据的数值映射到[0,1]区间之间。<br>
$$<br>
X^*=(X-min)/(max-min)<br>
$$<br>
其中max为样本数据的最大值，min 为样本数据的最小值，max-min为极差。离差标准化保留了原始数据值之间的联系，是消除量纲和数据取值范围影响最简单的方法。</p>
<p>离差标准化的特点：</p>
<p>数据的整体分布情况并不会随离差标准化而发生改变，原先取值较大的数据，在做完离差标准化后的值依旧较大。</p>
<p>当数据和最小值相等的时候，通过离差标准化可以发现数据变为0。</p>
<p>同时，还可以看出离差标准化的缺点：若数据集中某个数值很大，则离差标准化的值就会接近于0，并且相互之间差别不大。若将来遇到超过目前属性[min,max]取值范围的时候，会引起系统出错，这时便需要重新确定min和max。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scaler = sp.MinMaxScaler()</span><br><span class="line"><span class="comment"># 调用fit_transform</span></span><br><span class="line">scaler.fit_transform(arr01)</span><br><span class="line"><span class="comment"># 手写</span></span><br><span class="line">max_ = arr01.<span class="built_in">max</span>(axis=<span class="number">0</span>)</span><br><span class="line">min_ = arr01.<span class="built_in">min</span>(axis=<span class="number">0</span>)</span><br><span class="line">(arr01 - min_) / (max_ - min_)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([[0.        , 1.        , 0.        ],</span></span><br><span class="line"><span class="string">       [0.5       , 0.2       , 0.66666667],</span></span><br><span class="line"><span class="string">       [1.        , 0.        , 1.        ]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="3、异常值缩放数据">3、<strong>异常值缩放数据</strong></h4>
<blockquote>
<p>如果数据中包含了许多异常值，那么使用数据的均值和方差进行缩放可能不会很好地工作。在这些情况下，您可以使用RobustScaler作为替代品。它对数据的中心和范围使用了更可靠的估计。</p>
<p>使用对异常值具有鲁棒性的统计数据来缩放特征。</p>
<p>此缩放器删除中值，并根据分位数范围（默认为IQR：四分位数范围）缩放数据。IQR是第一个四分位数（第25分位数）和第三个四分位（第75分位数）之间的范围。通过计算训练集中样本的相关统计信息，对每个特征进行居中和缩放。然后存储中值和四分位间距，以便使用转换方法用于后续数据。</p>
<p>数据集的标准化是许多机器学习估计器的共同要求。通常，这是通过去除平均值并缩放到单位方差来实现的。然而，异常值通常会以负面方式影响样本均值/方差。在这种情况下，中值和四分位数范围通常会给出更好的结果。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scaler = sp.RobustScaler()</span><br><span class="line">scaler.fit_transform(arr01)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([[-1.        ,  1.6       , -1.33333333],</span></span><br><span class="line"><span class="string">       [ 0.        ,  0.        ,  0.        ],</span></span><br><span class="line"><span class="string">       [ 1.        , -0.4       ,  0.66666667]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="4、归一化">4、<strong>归一化</strong></h4>
<blockquote>
<p>归一化/标准化可以去除数据单位对计算带来的影响，也就是所谓的去量纲行为，归一化/标准化实质是一种线性变换，线性变换有很多良好的性质，这些性质决定了对数据改变后不会造成“失效”，反而能提高数据的表现，这些性质是归一化/标准化的前提。</p>
<p>归一化/标准化的去量纲作用能够带来以下两个好处：</p>
<p>1）提升模型的精度。一些分类器需要计算样本之间的距离（如欧氏距离），例如KNN。如果一个特征值域范围非常大，那么距离计算就主要取决于这个特征，从而与实际情况相悖（比如这时实际情况是值域范围小的特征更重要）。</p>
<p>2）提高收敛速度。对于线性模型来说，数据归一化/标准化后，最优解的寻优过程明显会变得平缓，更容易正确的收敛到最优解。</p>
<p>有些情况每个样本的每个特征值具体的值并不重要，但是每个样本特征值的占比更加重要。</p>
<table>
<thead>
<tr>
<th></th>
<th>动作</th>
<th>爱情</th>
<th>科幻</th>
</tr>
</thead>
<tbody>
<tr>
<td>小明</td>
<td>20</td>
<td>10</td>
<td>5</td>
</tr>
<tr>
<td>小王</td>
<td>4</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>小李</td>
<td>15</td>
<td>11</td>
<td>13</td>
</tr>
</tbody>
</table>
<p>所以归一化即是用每个样本的每个特征值除以该样本各个特征值绝对值的总和。变换后的样本矩阵，每个样本的特征值绝对值之和为1。</p>
<p>将样本单独归一化为单位范数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">API：</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">sklearn</span>.preprocessing.Normalizer(norm=<span class="string">&#x27;l2&#x27;</span>, *, copy=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">参数：</span><br><span class="line"></span><br><span class="line">norm：&#123;‘l1’, ‘l2’, ‘<span class="built_in">max</span>’&#125;, default=’l2’：用于标准化每个非零样本的范数。如果使用norm=<span class="string">&#x27;max&#x27;</span>，则值将按绝对值的最大值重新缩放。</span><br><span class="line"></span><br><span class="line">这里： l1 是曼哈顿距离		l2 是欧几里得距离</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">copy：<span class="built_in">bool</span>, default=<span class="literal">True</span>：设置为<span class="literal">False</span>以执行在位行规范化并避免复制（如果输入已经是numpy数组或scipy.sparse CSR矩阵）。</span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">scaler = sp.Normalizer(norm=<span class="string">&#x27;l2&#x27;</span>)</span><br><span class="line">scaler.fit_transform(arr01)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([[0.00424863, 0.02499197, 0.99967862],</span></span><br><span class="line"><span class="string">       [0.00399946, 0.01599782, 0.99986403],</span></span><br><span class="line"><span class="string">       [0.00418139, 0.01363498, 0.9998983 ]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">scaler1 = sp.Normalizer(norm=<span class="string">&#x27;l1&#x27;</span>)</span><br><span class="line">scaler1.fit_transform(arr01)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([[0.00412922, 0.02428953, 0.97158125],</span></span><br><span class="line"><span class="string">       [0.00392157, 0.01568627, 0.98039216],</span></span><br><span class="line"><span class="string">       [0.00410861, 0.01339764, 0.98249375]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="5、二值化">5、二值化</h4>
<blockquote>
<p>有些业务并不需要分析矩阵的详细完整数据（比如图像边缘识别只需要分析出图像边缘即可），可以根据一个事先给定的阈值，用0和1表示特征值不高于或高于阈值。二值化后的数组中每个元素非0即1，达到简化数学模型的目的。大于阈值的值映射到1，而小于或等于阈值的值则映射到0。默认阈值为0时，只有正值映射到1。</p>
<p>二值化是对文本计数数据的一种常见操作，分析人员可以决定只考虑特征的存在或不存在，而不是量化的出现次数。它还可以用作考虑布尔随机变量的估计器的预处理步骤（例如，在贝叶斯设置中使用伯努利分布建模）。</p>
<p>API：</p>
<p>class sklearn.preprocessing.Binarizer(*, threshold=0.0, copy=True)</p>
<p>参数：</p>
<p><code>threshold：float</code>, default=0.0：低于或等于此的特征值由0替换，高于此值由1替换。对于稀疏矩阵上的操作，阈值不能小于0。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scaler = sp.Binarizer(threshold=<span class="number">80</span>)</span><br><span class="line">scaler.fit_transform(arr01)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([[0, 1, 1],</span></span><br><span class="line"><span class="string">       [0, 0, 1],</span></span><br><span class="line"><span class="string">       [0, 0, 1]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="6、独热编码（onehot）">6、独热编码（<code>onehot</code>）</h4>
<blockquote>
<p>将分类特征编码为一个热点数字数组。为样本特征的每个值建立一个由一个1和若干个0组成的序列，用该序列对所有的特征值进行编码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">两个数	三个数	四个数</span><br><span class="line"><span class="number">1</span>	<span class="number">3</span>	<span class="number">2</span></span><br><span class="line"><span class="number">7</span>	<span class="number">5</span>	<span class="number">4</span></span><br><span class="line"><span class="number">1</span>	<span class="number">8</span>	<span class="number">6</span></span><br><span class="line"><span class="number">7</span>	<span class="number">3</span>	<span class="number">9</span></span><br><span class="line">为每一个数字进行独热编码：</span><br><span class="line"><span class="number">1</span>-&gt;<span class="number">10</span>    <span class="number">3</span>-&gt;<span class="number">100</span>	  <span class="number">2</span>-&gt;<span class="number">1000</span></span><br><span class="line"><span class="number">7</span>-&gt;01    <span class="number">5</span>-&gt;<span class="number">0</span>10   <span class="number">4</span>-&gt;<span class="number">0</span>100</span><br><span class="line"><span class="number">8</span>-&gt;001   <span class="number">6</span>-&gt;<span class="number">00</span>10  <span class="number">9</span>-&gt;0001</span><br><span class="line">编码完毕后得到最终经过独热编码后的样本矩阵：</span><br><span class="line"><span class="number">101001000</span></span><br><span class="line"><span class="number">0</span>10100100</span><br><span class="line"><span class="number">100010010</span></span><br><span class="line">011000001</span><br><span class="line">API：</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">sklearn</span>.preprocessing.OneHotEncoder(*, categories=<span class="string">&#x27;auto&#x27;</span>, drop=<span class="literal">None</span>, sparse=<span class="literal">True</span>, dtype=&lt;<span class="keyword">class</span> <span class="string">&#x27;numpy.float64&#x27;</span>&gt;, handle_unknown=<span class="string">&#x27;error&#x27;</span>, min_frequency=<span class="literal">None</span>, max_categories=<span class="literal">None</span>)</span><br><span class="line">参数:</span><br><span class="line">categories：‘auto’ <span class="keyword">or</span> a <span class="built_in">list</span> of array-like, default=’auto’：</span><br><span class="line">“auto”：根据培训数据自动确定类别。</span><br><span class="line"><span class="built_in">list</span>:categories[i]包含第i列中预期的类别。传递的类别不应在单个功能中混合字符串和数值，并且应在数值的情况下进行排序。</span><br><span class="line">sparse：<span class="built_in">bool</span>, default=<span class="literal">True</span>：如果设置为<span class="literal">True</span>，将返回稀疏矩阵，否则将返回数组。</span><br><span class="line">min_frequency：<span class="built_in">int</span> <span class="keyword">or</span> <span class="built_in">float</span>, default=<span class="literal">None</span>：指定最低频率，低于该频率类别将被视为不常见。</span><br><span class="line">max_categories：<span class="built_in">int</span>, default=<span class="literal">None</span>：在考虑不常用类别时，为每个输入要素指定输出要素数量的上限。如果存在不常见的类别，max_categories将包括表示不常见类别的类别以及常见类别。如果无，则输出特征的数量没有限制。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enc = OneHotEncoder(handle_unknown=<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = [[<span class="string">&#x27;Male&#x27;</span>, <span class="number">1</span>], [<span class="string">&#x27;Female&#x27;</span>, <span class="number">3</span>], [<span class="string">&#x27;Female&#x27;</span>, <span class="number">2</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enc.fit(X)</span><br><span class="line">OneHotEncoder(handle_unknown=<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enc.categories_ <span class="comment"># 每个特征的类别</span></span><br><span class="line">[array([<span class="string">&#x27;Female&#x27;</span>, <span class="string">&#x27;Male&#x27;</span>], dtype=<span class="built_in">object</span>), array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=<span class="built_in">object</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enc.transform([[<span class="string">&#x27;Female&#x27;</span>, <span class="number">1</span>], [<span class="string">&#x27;Male&#x27;</span>, <span class="number">4</span>]]).toarray() <span class="comment"># 将结果转为数组</span></span><br><span class="line">array([[<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将编码反转为原来的形式</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enc.inverse_transform([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]]) </span><br><span class="line">array([[<span class="string">&#x27;Male&#x27;</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="literal">None</span>, <span class="number">2</span>]], dtype=<span class="built_in">object</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enc.get_feature_names_out([<span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;group&#x27;</span>])</span><br><span class="line">array([<span class="string">&#x27;gender_Female&#x27;</span>, <span class="string">&#x27;gender_Male&#x27;</span>, <span class="string">&#x27;group_1&#x27;</span>, <span class="string">&#x27;group_2&#x27;</span>, <span class="string">&#x27;group_3&#x27;</span>], ...)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="7、标签编码">7、标签编码</h4>
<blockquote>
<p>对值介于0和n_classes-1之间的目标标签进行编码。根据字符串形式的特征值在特征序列中的位置，为其指定一个数字标签，用于提供给基于数值算法的学习模型。该转换器应用于编码目标值，即y，而不是输入X。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">API：</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">sklearn</span>.preprocessing.LabelEncoder()</span><br><span class="line">无参数</span><br><span class="line">属性：</span><br><span class="line">classes_：ndarray of shape (n_classes,)：保存每个类的标签。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> sklearn.preprocessing <span class="keyword">as</span> sp</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>raw_samples = np.array([</span><br><span class="line"><span class="meta">... </span>   <span class="string">&#x27;audi&#x27;</span>, <span class="string">&#x27;ford&#x27;</span>, <span class="string">&#x27;audi&#x27;</span>, <span class="string">&#x27;toyota&#x27;</span>,</span><br><span class="line"><span class="meta">... </span>   <span class="string">&#x27;ford&#x27;</span>, <span class="string">&#x27;bmw&#x27;</span>, <span class="string">&#x27;toyota&#x27;</span>, <span class="string">&#x27;ford&#x27;</span>,</span><br><span class="line"><span class="meta">... </span>   <span class="string">&#x27;audi&#x27;</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(raw_samples)</span><br><span class="line">lbe = sp.LabelEncoder()</span><br><span class="line">lbe_samples = lbe.fit_transform(raw_samples)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(lbe_samples)</span><br><span class="line">inv_samples = lbe.inverse_transform(lbe_samples)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(inv_samples)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="8、常用">8、常用</h4>
<table>
<thead>
<tr>
<th>类名</th>
<th>方法名</th>
</tr>
</thead>
<tbody>
<tr>
<td>sklearn.preprocessing.Binarizer()</td>
<td>sklearn.preprocessing.binarize()</td>
</tr>
<tr>
<td>sklearn.preprocessing.LabelBinarizer()</td>
<td>sklearn.preprocessing.label_binarize()</td>
</tr>
<tr>
<td>sklearn.preprocessing.MaxAbsScaler()</td>
<td>sklearn.preprocessing.maxabs_scale()</td>
</tr>
<tr>
<td>sklearn.preprocessing.MinMaxScaler()</td>
<td>sklearn.preprocessing.minmax_scale()</td>
</tr>
<tr>
<td>sklearn.preprocessing.Normalizer()</td>
<td>sklearn.preprocessing.normalize()</td>
</tr>
<tr>
<td>sklearn.preprocessing.StandardScaler()</td>
<td>sklearn.preprocessing.scale()</td>
</tr>
<tr>
<td>sklearn.preprocessing.RobustScaler()</td>
<td>sklearn.preprocessing.robust_scale()</td>
</tr>
</tbody>
</table>
<h2 id="回归问题">回归问题</h2>
<blockquote>
<p>回归问题是一种常见的监督机器学习任务，在很多领域均有广泛应用。其典型应用包括销量预测、库存预测、股票价格预测、天气预测等</p>
<p>大纲：</p>
<p>线性回归模型的目标函数（损失函数和正则函数）、线性回归模型的优化求解、回归任务的性能指标、线性回归模型的超参数调优以及使用sklearn实现线性回归模型的应用案例。</p>
</blockquote>
<h3 id="1、线性回归简介">1、线性回归简介</h3>
<blockquote>
<p>回归分析：回归分析法指利用数据统计原理，对大量统计数据进行数学处理，并确定因变量y与某些自变量x的相关关系，建立一个相关性较好的回归方程（函数表达式），并加以外推，用于预测今后的因变量的变化分析方法。回归的目标是学习一个输入x到输出y的映射f，并根据该模型预测新的测试数据x对应的响应y=f(x)'公式：</p>
</blockquote>
<p>$$<br>
f(x,w)=w^T+b<br>
$$</p>
<h3 id="2、一元线性回归">2、一元线性回归</h3>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picco.eu.org//img/bizhi20230710153626.png" alt=""></p>
<p>可以看出来最后求的就是损失函数，获取最小值min	即距离线距离和最短</p>
<p>可以理解我每一段都需要获取最小值，</p>
<h5 id="损失函数">损失函数</h5>
<blockquote>
<p>损失函数就是总样本误差关于模型参数的函数，该函数属于三维数学模型，即需要找到一组<code>w0</code>，<code>w1</code>使得loss取极小值。</p>
<p>核心：找到w0和w1的值，使得预测值和真实值之间的平均差异最小。</p>
<p>损失：机器学习模型关于单个样本的预测值与真实值的差，损失越小，模型越好；如果预测值与真实值相等，就是没有损失。</p>
<p>损失函数：用于计算损失的函数模型每一次预测的好坏用损失函数来度量。</p>
<p>常见的损失函数：</p>
<p>l 平均平方误差（Mean Squared Error （<code>MSE</code>））：也称为 <code>L2</code> Loss，是机器学习、深度学习回归任务中最常用的一种损失函数，对离群点敏感。</p>
<p>l 平均绝对误差（ Mean Absolute Error（MAE））：也称为<code>L1</code> Loss，使用绝对值，<code>L1</code>损失对离群点不敏感。</p>
<p>l 胡伯损失（Huber）：综合了<code>L2</code>损失和<code>L1</code>损失的优点。</p>
</blockquote>
<h5 id="线性回归模型的优化求解">线性回归模型的优化求解</h5>
<blockquote>
<p>模型的目标函数确定后，我们就可以采用合适的优化方法寻找最佳的模型参数。在线性回归模型中，模型参数包括线性回归系数<code>w1</code>，和截距<code>w0</code>。当训练数据集不大时，最小二乘线性回归可采用解析求解法求解，解析求解法涉及到大量公式推导，此处暂不做讲解。除此以外还可以使用梯度下降法求解。</p>
</blockquote>
<h5 id="正规方程">正规方程</h5>
<p>直接求解W</p>
<p>举例：</p>
<figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">y <span class="operator">=</span> ax^<span class="number">2</span> + bx +<span class="keyword">c</span></span><br><span class="line">y&#x27; <span class="operator">=</span> <span class="number">2</span>ax + b <span class="operator">=</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">x</span> <span class="operator">=</span> - b / <span class="number">2</span>a</span><br><span class="line"></span><br><span class="line">同理是矩阵求导<span class="operator">=</span><span class="number">0</span></span><br></pre></td></tr></table></figure>
<h5 id="梯度下降（Gradient-Descent）">梯度下降（Gradient Descent）</h5>
<blockquote>
<p>梯度下降法是求解无约束优化问题最常用的方法之一，亦被称为最速下降法。最小二乘回归和岭回归均可采用梯度下降法求解，Lasso回归由于目标函数中有L1正则函数而不可导，因此不能采用梯度下降法求解。梯度下降法是一种基于搜索的最优化方法，在机器学习中，熟练的使用梯度法（下降法或上升法）求取目标函数的最优解是非常重要的。线性回归算法模型的本质就是最小化一个损失函数，然后求出损失函数的参数的数学解； 梯度下降法是在机器学习领域中最小化损失函数的最为常用的方法。</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picco.eu.org//img/bizhi/20230710205448.png" alt=""></p>
<blockquote>
<p>假如你迷失在山上的浓雾之中，完全看不见下山的方向，你能感觉到的只有脚下的路面坡度。快速到达山脚的一个策略就是沿着最陡的方向下坡。这就是梯度下降的做法：通过测量参数向量θ相关的损失函数的局部梯度，并不断沿着降低梯度的方向调整，直到梯度将为0，达到最小值！ 每下降一步都去选择最陡峭的方向，然后踏出一步。因此没迭代一次需要考虑两个变量，一个是方向（朝哪边走），一个是步长（走多少）。方向就是向量θ的斜率，步长是一个超参数叫做学习率（learning_rate）。</p>
</blockquote>
<p>==<strong>学习速率（learning_rate）</strong>==</p>
<blockquote>
<p>学习率是一个超参数，学习率的取值会影响获得最优解的速度; 太小，算法需要经过大量迭代才能收敛，这将耗费很长时间；反过来学习率太大，可能会越过最小值直接到达另一边，甚至有可能比之前的起点还要高，这会导致算法发散，值越来越大，无法找到最优解。学习率是超参数需要手动调节，取值范围一般在[0, 1]之间。下图展示了不同学习率对梯度下降的影响。</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picco.eu.org//img/bizhi/20230710205526.png" alt=""></p>
<h3 id="3、回归相关API">3、回归相关<code>API</code></h3>
<blockquote>
<p><code>sklearn.linear_model</code>模块下提供了线性分类器（Linear classifiers）和经典线性回归（Classical linear regressors）两种问题的实现类。其中Linear classifiers中的类是用线性回归的思想解决分类问题的，其中包含了逻辑回归分类器（<code>LogisticRegression</code>），岭回归分类器（<code>RidgeClassifier</code>），交叉验证逻辑回归分类器（<code>RidgeClassifierCV</code>），线性感知器分类器（<code>Perceptron</code>），<code>SGD</code>训练的线性分类器（<code>SGDClassifier</code>）等多种分类器。Classical linear regressors模块中提供了线性回归（<code>LinearRegression</code>），岭回归（Ridge），交叉验证岭回归（<code>RidgeCV</code>），随机梯度下降回归（<code>SGDRegressor</code>）。除此以外还有带有变量选择的回归器（Regressors with variable selection）；贝叶斯回归（Bayesian regressors）；具有变量选择的多任务线性回归器（Multi-task linear regressors with variable selection）；离群稳健回归（<code>Outlier-robust regressors</code>）；回归的广义线性模型（Generalized linear models (<code>GLM</code>) for regression）；混合模型（Miscellaneous）等。</p>
</blockquote>
<p>==1.<strong><code>LinearRegression()</code></strong>==</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">普通最小二乘线性回归。线性回归拟合系数w=（w1，…，wp）的线性模型，以最小化数据集中观察到的目标与线性近似预测的目标之间的残差平方和。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">sklearn.linear_model.LinearRegression(*, fit_intercept=<span class="literal">True</span>, normalize=<span class="literal">False</span>, copy_X=<span class="literal">True</span>, n_jobs=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>fit_intercept</td>
<td>是否计算此模型的截距。如果设置为False，则不会在计算中使用截距（即，预计数据将居中）。</td>
</tr>
<tr>
<td>normalize</td>
<td>当fit_intercept设置为False时，将忽略此参数。如果为True，则回归前将通过减去平均值并除以l2范数对回归X进行归一化。如果您希望标准化，请在对normalize=False的估计器调用fit之前使用StandardScaler。</td>
</tr>
<tr>
<td>copy_X</td>
<td>如果为True，将复制X；否则，可能会被覆盖。</td>
</tr>
<tr>
<td>n_jobs</td>
<td>用于计算的作业数</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>属性</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>coef_</td>
<td>系数。形状为（n_features，）或（n_targets，n_features）的数组</td>
</tr>
<tr>
<td>rank_</td>
<td>矩阵的等级X</td>
</tr>
<tr>
<td>intercept_</td>
<td>截距</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>fit(X, y)</td>
<td>拟合线性模型</td>
</tr>
<tr>
<td>get_params([deep])</td>
<td>获取此估计器的参数。</td>
</tr>
<tr>
<td>predict(X)</td>
<td>使用线性模型进行预测。</td>
</tr>
<tr>
<td>score(X, y)</td>
<td>返回预测的确定系数。</td>
</tr>
<tr>
<td>set_params()</td>
<td>设置此估计器的参数。</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">示例代码：</span><br><span class="line"><span class="keyword">import</span> sklearn.linear_model <span class="keyword">as</span> lm</span><br><span class="line"><span class="comment"># 创建模型</span></span><br><span class="line">model = lm.LinearRegression()</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="comment"># 输入为一个二维数组表示的样本矩阵</span></span><br><span class="line"><span class="comment"># 输出为每个样本最终的结果</span></span><br><span class="line">model.fit(输入, 输出) <span class="comment"># 通过梯度下降法计算模型参数</span></span><br><span class="line"><span class="comment"># 预测输出  </span></span><br><span class="line"><span class="comment"># 输入array是一个二维数组，每一行是一个样本，每一列是一个特征。</span></span><br><span class="line">result = model.predict(array)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>==2.<strong><code>SGDRegressor()</code></strong>==</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">通过SGD最小化正则化经验损失拟合的线性模型。SGD代表随机梯度下降：一次估计每个样本的损失梯度，并以递减的强度计划（即学习率）更新模型。正则化器是添加到损失函数的惩罚，其使用平方欧几里德范数L2或绝对范数L1或两者的组合（弹性网）将模型参数收缩到零向量。如果参数更新由于正则化器而与0.0值交叉，则更新将被截断为0.0，以允许学习稀疏模型并实现在线特征选择。此实现可以处理表示为特征浮点值密集numpy数组的数据。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">sklearn</span>.linear_model.SGDRegressor(loss=<span class="string">&#x27;squared_error&#x27;</span>, *, penalty=<span class="string">&#x27;l2&#x27;</span>, alpha=<span class="number">0.0001</span>, l1_ratio=<span class="number">0.15</span>, fit_intercept=<span class="literal">True</span>, max_iter=<span class="number">1000</span>, tol=<span class="number">0.001</span>, shuffle=<span class="literal">True</span>, verbose=<span class="number">0</span>, epsilon=<span class="number">0.1</span>, random_state=<span class="literal">None</span>, learning_rate=<span class="string">&#x27;invscaling&#x27;</span>, eta0=<span class="number">0.01</span>, power_t=<span class="number">0.25</span>, early_stopping=<span class="literal">False</span>, validation_fraction=<span class="number">0.1</span>, n_iter_no_change=<span class="number">5</span>, warm_start=<span class="literal">False</span>, average=<span class="literal">False</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>loss</td>
<td>损失函数，str，默认值为：squared_error，可选：‘squared_error’,  ‘huber’, ‘epsilon_insensitive’, or ‘squared_epsilon_insensitive’</td>
</tr>
<tr>
<td>penalty</td>
<td>正则项，可选：{‘l2’,  ‘l1’, ‘elasticnet’}, 默认值为’l2’</td>
</tr>
<tr>
<td>alpha</td>
<td>正则强度，浮点型，默认值为：0.0001。值越大，正则化越强。</td>
</tr>
<tr>
<td>fit_intercept</td>
<td>是否计算截距，布尔型，默认值为：True。是否应估计截距。如果为False，则假定数据已居中。</td>
</tr>
<tr>
<td>learning_rate</td>
<td>学习率，字符串，默认值为：invscaling，不按比例缩放。</td>
</tr>
<tr>
<td>eta0</td>
<td>学习率的初始值，浮点型，  ‘constant’, ‘invscaling’ or ‘adaptive’初始学习率，默认为0.01</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>coef_</td>
<td>指定要素的权重斜率。</td>
</tr>
<tr>
<td>intercept_</td>
<td>截距项。</td>
</tr>
<tr>
<td>n_iter_</td>
<td>达到停止标准之前的实际迭代次数。</td>
</tr>
<tr>
<td>t_</td>
<td>训练期间执行的体重更新次数</td>
</tr>
<tr>
<td>n_features_in_</td>
<td>装配过程中看到的特征数量。</td>
</tr>
<tr>
<td>feature_names_in_</td>
<td>装配过程中看到的特征名称。仅当X具有全部字符串的要素名称时才定义。</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>fit(X, y)</td>
<td>用随机梯度下降拟合线性模型。</td>
</tr>
<tr>
<td>predict(X)</td>
<td>使用模型预测</td>
</tr>
<tr>
<td>get_params(deep=True)</td>
<td>获取此估计器的参数。</td>
</tr>
<tr>
<td>sparsify()</td>
<td>将系数矩阵转换为稀疏格式。</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>n_samples, n_features = <span class="number">10</span>, <span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rng = np.random.RandomState(<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = rng.randn(n_samples)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = rng.randn(n_samples, n_features)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Always scale the input. The most convenient way is to use a pipeline.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reg = make_pipeline(StandardScaler(),</span><br><span class="line"><span class="meta">... </span>                    SGDRegressor(max_iter=<span class="number">1000</span>, tol=<span class="number">1e-3</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reg.fit(X, y)</span><br><span class="line">Pipeline(steps=[(<span class="string">&#x27;standardscaler&#x27;</span>, StandardScaler()),</span><br><span class="line">                (<span class="string">&#x27;sgdregressor&#x27;</span>, SGDRegressor())])</span><br></pre></td></tr></table></figure>
<h3 id="4、案例实战：加利福尼亚房屋价格回归分析">4、案例实战：加利福尼亚房屋价格回归分析</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets <span class="keyword">as</span> sd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model <span class="keyword">as</span> sl</span><br><span class="line"></span><br><span class="line">data = sd.fetch_california_housing()</span><br><span class="line">x = data[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">y = data[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">查看形状</span></span><br><span class="line"><span class="string">x.shape</span></span><br><span class="line"><span class="string">y.shape</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">数据介绍</span></span><br><span class="line"><span class="string">print(data[&#x27;DESCR&#x27;])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 数据已经处理好了不需要进行特征工程</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集划分：训练集和测试集</span></span><br><span class="line">train_x, test_x, train_y, test_y = sm.train_test_split(x, y, train_size=<span class="number">0.75</span>, test_size=<span class="number">0.25</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">145</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">这里:</span></span><br><span class="line"><span class="string">train_size + test_size = 1</span></span><br><span class="line"><span class="string">shuffle = True 	混洗</span></span><br><span class="line"><span class="string">random_state = 145	随机数种子</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择模型</span></span><br><span class="line">model = sl.LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">pred_y = model.predict(test_x)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">预测这里主要看的就是看预测值与测试值之间的区别</span></span><br><span class="line"><span class="string">预测值:</span></span><br><span class="line"><span class="string">array([0.0696445 , 0.61678432, 2.02419006, ..., 1.9095006 , 2.67847098,</span></span><br><span class="line"><span class="string">       2.07215543])</span></span><br><span class="line"><span class="string">      </span></span><br><span class="line"><span class="string">测试值:</span></span><br><span class="line"><span class="string">array([0.988, 1.572, 1.609, ..., 1.361, 2.727, 3.167])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line">sm.mean_squared_error(test_y, pred_y)	<span class="comment">#0.5406765977332207</span></span><br></pre></td></tr></table></figure>
<p>从上面可以看出来随机数种子的选择和对测试集和训练集的划分对最后模型的评估有着很重要的作用</p>
<h3 id="5、回归模型评价指标">5、回归模型评价指标</h3>
<p>sklearn度量模块实现了几个损失、分数和效用函数来度量回归性能。其中一些已被增强以处理多输出情况：mean_squared_error、mean_absolute_error，r2_score，explained_variance_score、mean_pinball_loss、d2_pinball_score和d2_absolute _error_score。</p>
<table>
<thead>
<tr>
<th>方法名称</th>
<th>最优值</th>
<th>sklearn函数</th>
</tr>
</thead>
<tbody>
<tr>
<td>平均绝对误差</td>
<td>0.0</td>
<td>metrics. mean_absolute_error(y_true, y_pred)</td>
</tr>
<tr>
<td>平均均方误差</td>
<td>0.0</td>
<td>metrics. mean_squared_error(y_true, y_pred)</td>
</tr>
<tr>
<td>均方对数误差</td>
<td>0.0</td>
<td>metrics.mean_squared_log_error(y_true, y_pred)</td>
</tr>
<tr>
<td>中位绝对误差</td>
<td>0.0</td>
<td>metrics. median_absolute_error(y_true, y_pred)</td>
</tr>
<tr>
<td>最大误差</td>
<td>0.0</td>
<td>metrics.max_error(y_true, y_pred)</td>
</tr>
<tr>
<td>可解释方差值</td>
<td>1.0</td>
<td>metrics. explained_variance_score(y_true,  y_pred)</td>
</tr>
<tr>
<td>R方值</td>
<td>1.0</td>
<td>metrics. r2_score(y_true, y_pred)</td>
</tr>
</tbody>
</table>
<p>示例：</p>
<p>线性回归模型训练完毕后，可以利用测试集评估训练结果误差。sklearn.metrics提供了计算模型误差的几个常用算法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.metrics <span class="keyword">as</span> sm</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 平均绝对值误差：1/m∑|实际输出-预测输出|</span></span><br><span class="line"> sm.mean_absolute_error(test_y, pred_y)</span><br><span class="line"><span class="comment"># 平均平方误差：SQRT(1/mΣ(实际输出-预测输出)^2)</span></span><br><span class="line"> sm.mean_squared_error(test_y, pred_y)</span><br><span class="line"><span class="comment"># 中位绝对值误差：MEDIAN(|实际输出-预测输出|)</span></span><br><span class="line"> sm.median_absolute_error(test_y, pred_y)</span><br><span class="line"><span class="comment"># 解释方差回归评分：最好分数是 1.0，越低模型越不好</span></span><br><span class="line"> sm.explained_variance_score(test_y, y_pred)</span><br><span class="line"><span class="comment"># R2得分，(0,1]区间的分值,分数越高，误差越小。</span></span><br><span class="line"> sm.r2_score(test_y, pred_y)</span><br></pre></td></tr></table></figure>
<h3 id="6、过拟合和欠拟合">6、过拟合和欠拟合</h3>
<p>欠拟合</p>
<ul>
<li>原因: 学习导数据的特征过少</li>
<li>解决办法: 增加数据的特征数量</li>
</ul>
<p>过于简单的模型，无论对于训练数据还是测试数据都无法给出足够高的预测精度，这种现象叫做欠拟合。</p>
<p>过拟合</p>
<ul>
<li>原因: 原始特征过多，存在一些嘈杂特征，模型过于复杂是因为模型查实去兼顾各个测试数据点</li>
<li>解决办法: 正则化</li>
</ul>
<p>过于复杂的模型，对于训练数据可以得到较高的预测精度，但对于测试数据通常精度较低，这种现象叫做过拟合。</p>
<p>一个性能可以接受的学习模型应该对训练数据和测试数据都有接近的预测精度，而且精度不能太低。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">训练集R2  测试集R2</span><br><span class="line"> <span class="number">0.3</span>    <span class="number">0.4</span>    欠拟合：过于简单，无法反映数据的规则</span><br><span class="line"> <span class="number">0.9</span>    <span class="number">0.2</span>    过拟合：过于复杂，太特殊，缺乏一般性</span><br><span class="line"> <span class="number">0.7</span>    <span class="number">0.6</span>    可接受：复杂度适中，既反映数据的规则，同时又不失一般性</span><br></pre></td></tr></table></figure>
<h3 id="7、多元线性回归">7、多元线性回归</h3>
<p>在回归分析中，如果有两个或两个以上的自变量，就称为多元回归。</p>
<p>例如房屋价格预测，其中房屋价格会受到房屋面积，卧室数量，楼层，房屋年限等多种因素的影响，每个自变量对价格（因变量）的影响程度不一样</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picco.eu.org//img/bizhi/20230710205809.png" alt=""></p>
<h3 id="8、多项式回归">8、多项式回归</h3>
<blockquote>
<p>如果数据比直线更复杂怎么办？可以使用线性模型来拟合非线性数据。一个简单的方法就是将每个特征的幂次方添加为一个新特征，然后在此扩展特征集上训练一个线性模型。这种技术称为多项式回归。</p>
</blockquote>
<h3 id="9、正则化线性模型">9、正则化线性模型</h3>
<blockquote>
<p>减少过拟合的一个好方法是对模型进行正则化（即约束模型）：它拥有的自由度越少，则过拟合数据的难度就越大。</p>
<p>多项式模型正则化的一种简单方法是减少多项式的次数。</p>
<p>线性模型正则化通常是通过约束模型的权重来实现的。</p>
<p>岭回归、Lasso回归和弹性网络，它们实现了三种限制权重的方法</p>
</blockquote>
<p>我的理解就是数据种有脏数据，有异常值即过大或过小，而正则化就是排除这些异常</p>
<p>各个范式的理解：</p>
<p>​	<a target="_blank" rel="noopener" href="https://blog.csdn.net/vincent_duan/article/details/117305250">https://blog.csdn.net/vincent_duan/article/details/117305250</a></p>
<ul>
<li>
<p>==<strong>岭回归</strong>==</p>
<p>岭回归也称为Tikhonov正则化，是线性回归的正则化版本。普通线性回归模型使用基于梯度下降的最小二乘法，在最小化损失函数的前提下，寻找最优模型参数，于此过程中，包括<strong>少数异常样本</strong>在内的全部训练数据都会对最终模型参数造成程度相等的影响，异常值对模型所带来影响<strong>无法在训练过程中</strong>被识别出来。为此，岭回归在模型迭代过程所依据的损失函数中<strong>增加了正则项</strong>，以限制模型参数对异常样本的匹配程度，进而提高模型面对多数正常样本的拟合精度。</p>
<p>​	线性回归+L2正则项：Ridge 回归（岭回归）</p>
<ol>
<li>超参数γ控制要对模型进行正则化的程度。如果γ=0，则岭回归仅是线性回归。如果γ非常大，则所有权重最终都非常接近于零，结果是一条经过数据均值的平线。</li>
<li>在执行岭回归之前缩放数据（例如使用StandardScaler）很重要，因为它对输入特征的缩放敏感</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 岭回归API：</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">sklearn</span>.linear_model.Ridge(alpha=<span class="number">1.0</span>, *, fit_intercept=<span class="literal">True</span>, copy_X=<span class="literal">True</span>, max_iter=<span class="literal">None</span>, tol=<span class="number">0.0001</span>, solver=<span class="string">&#x27;auto&#x27;</span>, positive=<span class="literal">False</span>, random_state=<span class="literal">None</span>, normalize=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>normalize设置为True相当于先进行了一次标准化</li>
<li>alpha是正则化力度，取值: 0-1 1-10</li>
<li>solver:会根据数据自动选择优化方法
<ul>
<li>sag:如果数据集、特征都比较大，选择该随机梯度下降优化</li>
</ul>
</li>
</ul>
</li>
<li>
<p>==<strong>Lasso 回归</strong>==</p>
<p>线性回归+L1正则项：Lasso 回归（套索回归）</p>
<p>与岭回归一样，它也是向成本函数添加一个正则项，但是它增加的是权重向量的L1范数，而不是L2范数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rom sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line">linear_model.Lasso(alpha=<span class="number">1.0</span>, *, fit_intercept=<span class="literal">True</span>, normalize=<span class="literal">False</span>, precompute=<span class="literal">False</span>, copy_X=<span class="literal">True</span>, max_iter=<span class="number">1000</span>, tol=<span class="number">0.0001</span>, warm_start=<span class="literal">False</span>, positive=<span class="literal">False</span>, random_state=<span class="literal">None</span>, selection=<span class="string">&#x27;cyclic&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>==<strong>弹性网络</strong>==</p>
<p>弹性网络是介于岭回归和Lasso回归之间的中间地带。正则项是岭和Lasso正则项的简单混合，可以控制混合比ρ。</p>
<ul>
<li>
<p>当ρ=0时，弹性网络等效于岭回归；</p>
</li>
<li>
<p>当ρ=1时，弹性网络等于Lasso回归；</p>
</li>
</ul>
<blockquote>
<p>那么什么时候使用普通的线性回归岭、Lasso或弹性网络呢？通常，有正则化，哪怕很小，总比没有更可取一些，所以大部分情况下，应该避免使用纯线性回归。岭回归是个不错的默认选择，但是如果实际用到的特征只有少数几个，那就应该更倾向于Lasso回归或者弹性网络，因为它们会将无用特征的权重降为零。一般，弹性网络优于Lasso回归，因为当特征数量超过训练实例数量，又或者是几个特征强相关时，Lasso回归的表现可能非常不稳定。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet</span><br><span class="line"></span><br><span class="line">ElasticNet(alpha=<span class="number">1.0</span>, *, l1_ratio=<span class="number">0.5</span>, fit_intercept=<span class="literal">True</span>, normalize=<span class="literal">False</span>, precompute=<span class="literal">False</span>, max_iter=<span class="number">1000</span>, copy_X=<span class="literal">True</span>, tol=<span class="number">0.0001</span>, warm_start=<span class="literal">False</span>, positive=<span class="literal">False</span>, random_state=<span class="literal">None</span>, selection=<span class="string">&#x27;cyclic&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="逻辑回归">逻辑回归</h2>
<blockquote>
<p>逻辑回归分类模型是一种基于回归思想实现分类业务的分类模型。</p>
<p>逻辑回归的工作原理：与线性回归模型一样，逻辑回归模型也是计算输入特征的加权和（加上偏置项），但是不同于线性回归模型直接输出结果，它输出的是结果的数理逻辑。分类问题可以分为二元分类（OvO:one-versus-all）和多元分类(OvR:one-versus-all)。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="C:%5CUsers%5Cbeihai%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20230711084936733.png" alt="image-20230711084936733"></p>
<p>逻辑回归做二元分类时的核心思想为：</p>
<p>针对输出为{0, 1}的已知训练样本训练一个回归模型，使得训练样本的预测输出限制在(0, 1)的数值区间。该模型使原类别为0的样本的输出更接近于0，原类别为1的样本的输出更接近于1。这样就可以使用相同的回归模型来完成分类预测。</p>
</blockquote>
<h3 id="1、逻辑回归原理">1、逻辑回归原理</h3>
<p>逻辑回归目标函数：<br>
$$<br>
逻辑函数(sigmoid)：y=1/(1+e^(-z) ); z=w^T x+b<br>
$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 逻辑回归相关API：</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sklearn.linear_model <span class="keyword">as</span> lm		<span class="comment"># logist:逻辑</span></span><br><span class="line"><span class="comment"># 构建逻辑回归器 		</span></span><br><span class="line"><span class="comment"># solver：逻辑函数中指数的函数关系（liblinear为线型函数关系）</span></span><br><span class="line"><span class="comment"># C：参数代表正则强度，为了防止过拟合。正则越大拟合效果越小。</span></span><br><span class="line">model = lm.LogisticRegression(solver=<span class="string">&#x27;liblinear&#x27;</span>, C=正则强度)</span><br><span class="line">model.fit(训练输入集，训练输出集)</span><br><span class="line">result = model.predict(带预测输入集)</span><br></pre></td></tr></table></figure>
<h3 id="2、交叉验证">2、交叉验证</h3>
<blockquote>
<p>在机器学习中，因为训练集和测试集的数据划分是随机的，所以有时会重复地使用数据，以便更好地评估模型的有效性，并选出最好的模型，该做法称为交叉验证。具体而言就是对原始样本数据进行切分，然后组合成为多组不同的训练集和测试集，用训练集训练模型，用测试集评估模型。某次的训练集可能是下次的测试集，故而称为交叉验证。</p>
<p>交叉验证的方法有简单交叉验证、K折交叉验证和留一交叉验证3种。其中K折交叉验证应用较为广泛，它是指将数据集随机等分为K份，每次选取K-1份作为训练集，用剩下的1份作为测试集，得到K个模型后将这K个模型的平均测试效果作为最终的模型效果。</p>
<p>通常来说，如果训练集相对较小，则增大K值，这样在每次迭代过程中将会有更多数据用于模型训练，同时算法时间延长；如果训练集相对较大，则减小K值，这样可以降低模型在不同的数据块上进行重复拟合性能评估的计算成本，在平均性能的基础上获得模型的准确评估。</p>
<p>除了更精确地评估模型，交叉验证的另一个重要作用就是利用更精确的评估结果对模型进行参数调优，它经常与<code>GridSearch</code>网格搜索配合使用。</p>
</blockquote>
<p>就是把将训练集分为不同的折，然后将测试集交叉放进去与训练集拟合，好处就是可以学到训练集的细节</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="C:%5CUsers%5Cbeihai%5CDesktop%5Cgrid_search_cross_validation.png" alt="grid_search_cross_validation"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sklearn提供了交叉验证相关API：</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sklearn.model_selection <span class="keyword">as</span> ms</span><br><span class="line">指标值数组 = ms.cross_val_score(模型, 输入集, 输出集, cv=折叠数, scoring=指标名)</span><br></pre></td></tr></table></figure>
<h3 id="3、数据集划分">3、数据集划分</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">数据集划分相关API：</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sklearn.model_selection <span class="keyword">as</span> ms</span><br><span class="line"> </span><br><span class="line"> X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=测试集占比, random_state=随机种子)</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>*arrays</td>
<td>接收一个或多个数据集。代表需要划分的数据集，若为分类回归则分别传入数据和标签，若为聚类则传入数 据。无默认。</td>
</tr>
<tr>
<td>test_size</td>
<td>接收float，int，None类型的数据。代表测试集的大小。如果传入的为float类型的数据则需要限定在0-1之 间，代表测试集在总数中的占比；如果传入为int类型的数据，则表示测试集记录的绝对数目。该参数与  train_size可以只传入一个。在0.21版本前，若test_size和train_size均为默认则testsize为25%。</td>
</tr>
<tr>
<td>train_size</td>
<td>接收float，int，None类型的数据。代表训练集的大小。该参数与test_size可以只传入一个。</td>
</tr>
<tr>
<td>random_state</td>
<td>接收int。代表随机种子编号，相同随机种子编号产生相同的随机结果，不同的随机种子编号产生不同的随机结果。默认为None。random_state就是为了保证程序每次运行都分割一样的训练集合测试集。</td>
</tr>
<tr>
<td>shuffle</td>
<td>接收boolean。代表是否进行有放回抽样。若该参数取值为True则stratify参数必须不能为空。</td>
</tr>
<tr>
<td>stratify</td>
<td>接收array或者None。如果不为None，则使用传入的标签进行分层抽样。</td>
</tr>
</tbody>
</table>
<p>train_test_split是最常用的数据划分方法，在model_selection模块中还提供了其他数据集划分的函数，如<code>PredefinedSplit</code>，<code>ShuffleSplit</code>等。</p>
<p>划分训练集和测试集在某种程度上也是为了检查模型是否出现过拟合。过拟合指模型在训练样本中拟合程度过高，虽然它很好地契合了训练集数据，但是却丧失了泛化能力，因而不具有推广性，导致在测试集数据中的预测表现不佳。就好比每次模考都做同一份卷子，训练时得分很高，但是期末考试换了一套卷子就得分很低。而划分训练集和测试集可以用来对模型进行更好的检验。</p>
<h3 id="4、模型搭建">4、模型搭建</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#模型的搭建相对比较容易，逻辑回归相关API：</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sklearn.linear_model <span class="keyword">as</span> lm</span><br><span class="line"> <span class="comment"># 构建逻辑回归器 </span></span><br><span class="line"> <span class="comment"># solver：逻辑函数中指数的函数关系（liblinear为线型函数关系）</span></span><br><span class="line"> <span class="comment"># C：参数代表正则强度，反值，为了防止过拟合。正则越大拟合效果越小。</span></span><br><span class="line"></span><br><span class="line"> model = lm.LogisticRegression(solver=<span class="string">&#x27;liblinear&#x27;</span>, C=正则强度)</span><br><span class="line"> model.fit(X_train，y_train)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">如果这里solver不选择liblinear 会默认选择 lbfgs</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">官网这样说的：The ‘newton-cg’, ‘sag’, and ‘lbfgs’ solvers support only L2 regularization with primal formulation, or no regularization. The ‘liblinear’ solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty. The Elastic-Net regularization is only supported by the ‘saga’ solver.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="5、分类问题模型评估">5、分类问题模型评估</h3>
<ul>
<li>
<p>==<strong>一级指标</strong>==</p>
<blockquote>
<p>分类模型的评价指标：真假与正类负类</p>
<p>a. 真正例(TP) 是指模型将正类别样本正确地预测为正类别。</p>
<p>b. 真负例(TN) 是指模型将负类别样本正确地预测为负类别。</p>
<p>c. 假正例(FP) 是指模型将负类别样本错误地预测为正类别。</p>
<p>d. 假负例(FN) 是指将正类别样本错误地预测为负类别。</p>
</blockquote>
<p><strong>混淆矩阵</strong></p>
<p>混淆矩阵（也称误差矩阵，Confusion Matrix）就是分别统计分类模型归错类，归对类的观测值个数，然后把结果放在一个表里展示出来。这个表就是混淆矩阵。</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th>真实值</th>
<th>真实值</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td>Positive</td>
<td>Negative</td>
</tr>
<tr>
<td>预测值</td>
<td>Positive</td>
<td>真正例（TP)</td>
<td>假正例（FP)</td>
</tr>
<tr>
<td>预测值</td>
<td>Negative</td>
<td>假负例（FN)</td>
<td>真负例（TN)</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取模型分类结果的混淆矩阵的相关API：</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sklearn.metrics <span class="keyword">as</span> sm</span><br><span class="line">混淆矩阵 = sm.confusion_matrix(实际输出, 预测输出)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>==<strong>二级指标</strong>==</p>
<p>准确率(accuracy)：是指模型预测正确的样本数比上总样本数的比重。</p>
<p>计算公式：accuracy = (TP + TN) / (TP + TN + FP + FN)</p>
<p>精确率(precision_weighted)：针对每一个类别，预测正确的样本数比上预测出来的样本数。</p>
<p>计算公式：precision_weighted = TP / TP + FP</p>
<p>召回率(recall_weighted)：针对每一个类别，预测正确的样本数比上实际存在的样本数。</p>
<p>​       计算公式：recall_weighted = TP / TP + FN</p>
<p>某池塘有1400条鲤鱼，300只虾，300只鳖。现在以捕鲤鱼为目的。 撒一大网，逮着了700条鲤鱼，200只虾，100只鳖。那么，这些指标 分别如下：<br>
精确率 = 700 / (700 + 200 + 100) = 70%<br>
召回率 = 700 / 1400 = 50%<br>
F值 = 70% * 50% * 2 / (70% + 50%) = 58.3%</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># API</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 准确率</span></span><br><span class="line">sm.accuracy_score(test_y, pred_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 精确率</span></span><br><span class="line">sm.precision_score(test_y, pred_y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">这里会报错：</span></span><br><span class="line"><span class="string">		ValueError: Target is multiclass but average=&#x27;binary&#x27;. Please choose another average setting, one of [None, &#x27;micro&#x27;, &#x27;macro&#x27;, &#x27;weighted&#x27;].</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">只需要更改：</span></span><br><span class="line"><span class="string">sm.precision_score(test_y, pred_y, average=None)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 更改为；</span></span><br><span class="line">sm.precision_score(test_y, pred_y, average=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([0.8       , 0.94444444, 1.        ])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 精确率</span></span><br><span class="line">sm.precision_score(test_y, pred_y, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">0.9148148148148149</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 召回率</span></span><br><span class="line">sm.recall_score(test_y, pred_y, average=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([0.88888889, 0.89473684, 1.        ])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 召回率</span></span><br><span class="line">sm.recall_score(test_y, pred_y, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">0.9278752436647174</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>精确率和召回率有一定关系 -&gt;</p>
<ol>
<li>精确率是预测正确的比上预测出来的</li>
<li>召回率是预测正确的比上原来就有的</li>
<li>记住一个结论：精确率和召回率是此消彼长的关系</li>
<li>例如：抖音审核，精确率上升，召回率下降</li>
</ol>
</li>
<li>
<p>==<strong>三级指标</strong>==</p>
<blockquote>
<p>•      F1_Score(f1_weighted)：2x精确率x召回率/(精确率+召回率)</p>
<p>分类模型对测试集进行预测而得出的准确率(accuracy)并不能很好地反映模型的性能，为了有效判断一个预测模型的性能表现，需要结合真实值，计算出精确率(precision_weighted)、召回率(recall_weighted)、F1_Score和Cohen’s Kappa系数等指标来衡量。分值越高越好。</p>
<p>要全面评估模型的有效性，必须<strong>同时</strong>检查精确率(precision_weighted)和召回率(recall_weighted)。遗憾的是，精确率和召回率往往是此消彼长的情况。也就是说，提高精确率通常会降低召回率值，反之亦然。提高分类阈值，精确率可能会提高（因为FP可能会减小）；召回率会下降或保持不变（因为TP会减少或不变，且FN会增加或不变）。降低分类阈值，精确率可能会下降（因为FP可能会增加），而召回率（FN可能会减少）可能会有所提高。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># f1得分  -&gt; 召回率和精确率</span></span><br><span class="line">sm.f1_score(test_y, pred_y, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">0.9203413940256047</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分类报告</span></span><br><span class="line"><span class="built_in">print</span>(sm.classification_report(test_y, pred_y))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">			precision    recall  f1-score   support</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">           0       0.80      0.89      0.84         9</span></span><br><span class="line"><span class="string">           1       0.94      0.89      0.92        19</span></span><br><span class="line"><span class="string">           2       1.00      1.00      1.00        17</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    accuracy                           0.93        45</span></span><br><span class="line"><span class="string">   macro avg       0.91      0.93      0.92        45</span></span><br><span class="line"><span class="string">weighted avg       0.94      0.93      0.93        45</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="6、红酒分类">6、红酒分类</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets <span class="keyword">as</span> sd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model <span class="keyword">as</span> lm</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据</span></span><br><span class="line">data = sd.load_wine()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看一些数据详情</span></span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;DESCR&#x27;</span>])</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"> ============================= ==== ===== ======= =====</span></span><br><span class="line"><span class="string">                                   Min   Max   Mean     SD</span></span><br><span class="line"><span class="string">    ============================= ==== ===== ======= =====</span></span><br><span class="line"><span class="string">    Alcohol:                      11.0  14.8    13.0   0.8</span></span><br><span class="line"><span class="string">    Malic Acid:                   0.74  5.80    2.34  1.12</span></span><br><span class="line"><span class="string">    Ash:                          1.36  3.23    2.36  0.27</span></span><br><span class="line"><span class="string">    Alcalinity of Ash:            10.6  30.0    19.5   3.3</span></span><br><span class="line"><span class="string">    Magnesium:                    70.0 162.0    99.7  14.3</span></span><br><span class="line"><span class="string">    Total Phenols:                0.98  3.88    2.29  0.63</span></span><br><span class="line"><span class="string">    Flavanoids:                   0.34  5.08    2.03  1.00</span></span><br><span class="line"><span class="string">    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12</span></span><br><span class="line"><span class="string">    Proanthocyanins:              0.41  3.58    1.59  0.57</span></span><br><span class="line"><span class="string">    Colour Intensity:              1.3  13.0     5.1   2.3</span></span><br><span class="line"><span class="string">    Hue:                          0.48  1.71    0.96  0.23</span></span><br><span class="line"><span class="string">    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71</span></span><br><span class="line"><span class="string">    Proline:                       278  1680     746   315</span></span><br><span class="line"><span class="string">    ============================= ==== ===== ======= =====</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取特征值和目标值</span></span><br><span class="line">x = data[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">y = data[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分数据集</span></span><br><span class="line">train_x, test_x, train_y, test_y = ms.train_test_split(x, y, train_size=<span class="number">0.75</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择模型</span></span><br><span class="line">model = lm.LogisticRegression(solver=<span class="string">&#x27;liblinear&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">这里solver切记要切换模型 不然下面训练模型会出错</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测模型</span></span><br><span class="line">pred_y = model.predict(test_x)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([2, 0, 2, 2, 1, 2, 1, 0, 1, 2, 0, 1, 2, 1, 1, 1, 1, 2, 0, 0, 0, 1,</span></span><br><span class="line"><span class="string">       1, 1, 0, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 0, 2, 0, 0, 2, 2,</span></span><br><span class="line"><span class="string">       1])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对比真实值</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([2, 0, 2, 2, 1, 2, 1, 0, 1, 2, 0, 1, 2, 1, 1, 1, 1, 2, 0, 0, 1, 1,</span></span><br><span class="line"><span class="string">       1, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 1, 1, 1, 2, 2, 0, 2, 0, 1, 2, 2,</span></span><br><span class="line"><span class="string">       1])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 混淆矩阵</span></span><br><span class="line">sm.confusion_matrix(test_y, pred_y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([[ 8,  1,  0],</span></span><br><span class="line"><span class="string">       [ 2, 17,  0],</span></span><br><span class="line"><span class="string">       [ 0,  0, 17]], dtype=int64)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">这里横轴相加为真实值的各个类的总和</span></span><br><span class="line"><span class="string">纵轴相加为预测值的各个类的总和</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line"><span class="comment"># 准确率</span></span><br><span class="line">sm.accuracy_score(test_y, pred_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 精确率</span></span><br><span class="line">sm.precision_score(test_y, pred_y, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">0.9148148148148149</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 召回率</span></span><br><span class="line">sm.recall_score(test_y, pred_y, average=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([0.88888889, 0.89473684, 1.        ])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 召回率</span></span><br><span class="line">sm.recall_score(test_y, pred_y, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">0.9278752436647174</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># f1得分  -&gt; 召回率和精确率</span></span><br><span class="line">sm.f1_score(test_y, pred_y, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">0.9203413940256047</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分类报告</span></span><br><span class="line"><span class="built_in">print</span>(sm.classification_report(test_y, pred_y))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">			precision    recall  f1-score   support</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">           0       0.80      0.89      0.84         9</span></span><br><span class="line"><span class="string">           1       0.94      0.89      0.92        19</span></span><br><span class="line"><span class="string">           2       1.00      1.00      1.00        17</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    accuracy                           0.93        45</span></span><br><span class="line"><span class="string">   macro avg       0.91      0.93      0.92        45</span></span><br><span class="line"><span class="string">weighted avg       0.94      0.93      0.93        45</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="决策树">决策树</h2>
<p>**决策树模型的几个重要概念：**父节点和子节点、根节点和叶子节点。</p>
<p>父节点和子节点是相对的，子节点由父节点根据某一规则分裂而来，然后子节点作为新的父节点继续分裂，直至不能分裂为止。</p>
<p>根节点则和叶子节点是绝对的，根节点是没有父节点的节点，即初始节点，叶子节点则是没有子节点的节点，即最终节点。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="C:%5CUsers%5Cbeihai%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20230711104500841.png" alt="image-20230711104500841"></p>
<p>**决策树模型的关键：**就是如何选择合适的节点进行分裂。</p>
<h3 id="1、决策树回归器模型相关API">1、决策树回归器模型相关API</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.tree <span class="keyword">as</span> st</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 决策树分类模型接口</span></span><br><span class="line"> sklearn.tree.DecisionTreeClassifier(*, criterion=<span class="string">&#x27;gini&#x27;</span>, splitter=<span class="string">&#x27;best&#x27;</span>, max_depth=<span class="literal">None</span>, min_samples_split=<span class="number">2</span>, min_samples_leaf=<span class="number">1</span>, min_weight_fraction_leaf=<span class="number">0.0</span>, max_features=<span class="literal">None</span>, random_state=<span class="literal">None</span>, max_leaf_nodes=<span class="literal">None</span>, min_impurity_decrease=<span class="number">0.0</span>, min_impurity_split=<span class="literal">None</span>, class_weight=<span class="literal">None</span>, ccp_alpha=<span class="number">0.0</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 决策树回归模型接口</span></span><br><span class="line"> sklearn.tree.DecisionTreeRegressor(*, criterion=<span class="string">&#x27;mse&#x27;</span>, splitter=<span class="string">&#x27;best&#x27;</span>, max_depth=<span class="literal">None</span>, min_samples_split=<span class="number">2</span>, min_samples_leaf=<span class="number">1</span>, min_weight_fraction_leaf=<span class="number">0.0</span>, max_features=<span class="literal">None</span>, random_state=<span class="literal">None</span>, max_leaf_nodes=<span class="literal">None</span>, min_impurity_decrease=<span class="number">0.0</span>, min_impurity_split=<span class="literal">None</span>, ccp_alpha=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>criterion:{“gini”, “entropy”}, default=”gini”</td>
<td>衡量分类的质量“entropy”代表信息增益,&quot;gini&quot;代表基尼系数</td>
</tr>
<tr>
<td>max_depth</td>
<td>树的最大深度</td>
</tr>
<tr>
<td>min_samples_split</td>
<td>一个内部节点需要的最少的样本数</td>
</tr>
<tr>
<td>min_samples_leaf</td>
<td>一个叶节点所需要的最小样本数</td>
</tr>
<tr>
<td>max_leaf_nodes</td>
<td>最大叶子节点的值</td>
</tr>
<tr>
<td>class_weight</td>
<td>类的关联权值</td>
</tr>
</tbody>
</table>
<h3 id="2、鸢尾花回归决策树">2、鸢尾花回归决策树</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets <span class="keyword">as</span> sd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line">data = sd.load_iris()</span><br><span class="line">x = data.data</span><br><span class="line">y = data.target</span><br><span class="line">train_x, test_x, train_y, test_y = ms.train_test_split(x, y, train_size=<span class="number">0.75</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">7</span>)</span><br><span class="line"><span class="comment"># 选择模型</span></span><br><span class="line">model = st.DecisionTreeClassifier()</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 预测模型</span></span><br><span class="line">pred_y = model.predict(test_x)</span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line">sm.f1_score(test_y, pred_y, average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line"><span class="comment"># 绘画决策树</span></span><br><span class="line">st.plot_tree(model,feature_names=[<span class="string">&#x27;sepal length&#x27;</span>, <span class="string">&#x27;sepal width&#x27;</span>, <span class="string">&#x27;petal length&#x27;</span>, <span class="string">&#x27;petal width&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看特征的重要性</span></span><br><span class="line">model.feature_importances_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([0.01786711, 0.        , 0.0329131 , 0.94921978])</span></span><br><span class="line"><span class="string">所以我们选择data的时候只需要后面两列就ok</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="C:%5CUsers%5Cbeihai%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20230711110745356.png" alt="image-20230711110745356"></p>
<h2 id="集合算法">集合算法</h2>
<blockquote>
<p>集合算法也叫集成学习模型，它是使用一系列弱学习器（也称为基础模型或基模型）进行学习，并将各个弱学习器的结果进行整合，从而获得比单个学习器更好的学习效果。集成学习模型的常见算法有Bagging算法和Boosting算法两种。Bagging算法的典型机器学习模型为随机森林模型，而Boosting算法的典型机器学习模型为：AdaBoost、GBDT、XGBoost和LightGBM模型。</p>
<p>Bagging算法</p>
<p>Bagging算法的原理类似投票，每个弱学习器都有一票，最终根据所有弱学习器的投票，按照“少数服从多数”的原则产生最终的预测结果。</p>
<p>假设原始数据共有10000条，从中随机有放回地抽取10000次数据构成一个新的训练集（因为是随机有放回抽样，所以可能出现某一条数据多次被抽中，也有可能某一条数据一次也没有被抽中），每次使用一个训练集训练一个弱学习器。这样有放回地随机抽取n次后，训练结束时就能获得由不同的训练集训练出的n个弱学习器，根据这n个弱学习器的预测结果，按照“少数服从多数”的原则，获得一个更加准确、合理的最终预测结果。具体来说，在分类问题中是用n个弱学习器投票的方式获取最终结果，在回归问题中则是取n个弱学习器的平均值作为最终结果。</p>
<p>Boosting算法</p>
<p>Boosting算法的本质是将弱学习器提升为强学习器，它和Bagging算法的区别在于：Bagging算法对待所有的弱学习器一视同仁；而Boosting算法则会对弱学习器“区别对待”，通俗来讲就是注重“培养精英”和“重视错误”。</p>
<p>”培养精英”就是每一轮训练后对预测结果较准确的弱学习器给予较大的权重，对表现不好的弱学习器则降低其权重。这样在最终预测时，“优秀模型”的权重是大的，相当于它可以投出多票，而“一般模型”只能投出一票或不能投票。</p>
<p>“重视错误”就是在每一轮训练后改变训练集的权值或概率分布，通过提高在前一轮被弱学习器预测错误的样例的权值，降低前一轮被弱学习器预测正确的样例的权值，来提高弱学习器对预测错误的数据的重视程度，从而提升模型的整体预测效果。</p>
</blockquote>
<h3 id="1、随机森林">1、随机森林</h3>
<p>​				随机森林（Random Forest）是一种经典的Bagging模型，其弱学习器为决策树模型。随机森林模型会在原始数据集中随机抽样，构成n个不同的样本数据集，然后根据这些数据集搭建n个不同的决策树模型，最后根据这些决策树模型的平均值（针对回归模型）或者投票情况（针对分类模型）来获取最终结果。为了保证模型的泛化能力（或者说通用能力），随机森林模型在建立每棵树时，往往会遵循<strong>数据随机</strong>和<strong>特征随机</strong>这两个基本原则。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#随机森林相关API：</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sklearn.ensemble <span class="keyword">as</span> se</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机森林回归模型	（属于集合算法的一种）</span></span><br><span class="line"><span class="comment"># max_depth：决策树最大深度10</span></span><br><span class="line"><span class="comment"># n_estimators：构建1000棵决策树，训练模型</span></span><br><span class="line"><span class="comment"># min_samples_split: 子表中最小样本数 若小于这个数字，则不再继续向下拆分</span></span><br><span class="line">model = se.RandomForestRegressor(max_depth=<span class="number">10</span>, n_estimators=<span class="number">1000</span>,min_samples_split=<span class="number">2</span>,random_state=<span class="number">7</span>)</span><br><span class="line">model.fit(X,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随集森林分类模型</span></span><br><span class="line">model=RandomForestClassifier(max_depth=<span class="number">10</span>, n_estimators=<span class="number">1000</span>,min_samples_split=<span class="number">2</span>,random_state=<span class="number">7</span>)</span><br><span class="line">model.fit(X,y)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>==<strong>案例</strong>==</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets <span class="keyword">as</span> sd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> ensemble <span class="keyword">as</span> se</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line">data = sd.load_iris()</span><br><span class="line">x = data.data</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分数据集</span></span><br><span class="line">train_x, test_x, train_y, test_y = ms.train_test_split(x, y, train_size=<span class="number">0.75</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择模型</span></span><br><span class="line">model = se.RandomForestClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看权重</span></span><br><span class="line">model.feature_importances_</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([0.06178603, 0.0128437 , 0.47481514, 0.45055513])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测模型</span></span><br><span class="line">pred_y = model.predict(test_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 稀疏矩阵</span></span><br><span class="line">sm.confusion_matrix(test_y, pred_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line">sm.f1_score(test_y, pred_y, average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">0.8947368421052632</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(sm.classification_report(test_y, pred_y))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">              precision    recall  f1-score   support</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">           0       1.00      1.00      1.00        11</span></span><br><span class="line"><span class="string">           1       0.86      0.86      0.86        14</span></span><br><span class="line"><span class="string">           2       0.85      0.85      0.85        13</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    accuracy                           0.89        38</span></span><br><span class="line"><span class="string">   macro avg       0.90      0.90      0.90        38</span></span><br><span class="line"><span class="string">weighted avg       0.89      0.89      0.89        38</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="2、AdaBoost">2、AdaBoost</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets <span class="keyword">as</span> sd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model <span class="keyword">as</span> lm</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> ensemble <span class="keyword">as</span> se</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据</span></span><br><span class="line">data = sd.load_iris()</span><br><span class="line"></span><br><span class="line">x = data.data</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分数据集</span></span><br><span class="line">train_x, test_x, train_y, test_y = ms.train_test_split(x, y, train_size=<span class="number">0.8</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">21</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择模型</span></span><br><span class="line">sgd = lm.SGDClassifier()</span><br><span class="line">model = se.AdaBoostClassifier(estimator=sgd, algorithm=<span class="string">&#x27;SAMME&#x27;</span>, n_estimators=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">pred_y = model.predict(test_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line"><span class="built_in">print</span>(sm.classification_report(test_y, pred_y))</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">			  precision    recall  f1-score   support</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">           0       1.00      1.00      1.00        11</span></span><br><span class="line"><span class="string">           1       1.00      0.71      0.83        14</span></span><br><span class="line"><span class="string">           2       0.76      1.00      0.87        13</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    accuracy                           0.89        38</span></span><br><span class="line"><span class="string">   macro avg       0.92      0.90      0.90        38</span></span><br><span class="line"><span class="string">weighted avg       0.92      0.89      0.89        38</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="朴素贝叶斯">朴素贝叶斯</h2>
<blockquote>
<p>贝叶斯分类是机器学习中应用极为广泛的分类算法之一，其产生自英国数学家贝叶斯对于逆概问题的思考。朴素贝叶斯是贝叶斯模型当中最简单的一种。</p>
<p><strong>贝叶斯公式</strong> **: **<br>
$$<br>
P(A|B) = P(B|A)P(A) / P(B)<br>
$$<br>
其中P（A）为事件A发生的概率，P（B）为事件B发生的概率，P（A|B）表示在事件B发生的条件下事件A发生的概率，同理P（B|A）则表示在事件A发生的条件下事件B发生的概率。</p>
<p><strong>朴素贝叶斯分类是贝叶斯分类中最简单，也是常见的一种分类方法</strong>。<br>
$$<br>
P( Y|X1,X2,…,Xn ) = p( X1,X2,…Xn|Y) P(Y) / P(X1,X2,…Xn)<br>
$$<br>
朴素贝叶斯模型假设给定目标值后各个特征之间相互独立，分子的计算公式可以写成如下形式:<br>
$$<br>
P( X1,X2,…Xn|Y)P(Y) = P(X1|Y)P(X2|Y)P(X3|Y)…P(Xn|Y)P(Y)<br>
$$<br>
。其中<code>P（X1|Y）、P（X2|Y）、P（Y）</code>等数据都是已知的，由此可以计算在n个特征变量取不同的值的条件下，目标变量取某个值的概率，并且选择概率更高者对样本进行分类。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#朴素贝叶斯模型相关API:</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sklearn.naive_bayes <span class="keyword">as</span> nb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建高斯分布朴素贝叶斯分类器,它适用于任何连续数值型的数据集。</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets <span class="keyword">as</span> sd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> feature_extraction <span class="keyword">as</span> fe</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> naive_bayes <span class="keyword">as</span> nb</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line">data = sd.fetch_20newsgroups()</span><br><span class="line">x = data.data</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line">train_x, test_x, train_y, test_y = ms.train_test_split(x, y, train_size=<span class="number">0.75</span>, random_state=<span class="number">6</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">transfer = fe.text.TfidfVectorizer()</span><br><span class="line">train_x = transfer.fit_transform(train_x)</span><br><span class="line">test_x = transfer.transform(test_x)</span><br><span class="line"></span><br><span class="line">model = nb.MultinomialNB()</span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line">pred_y = model.predict(test_x)</span><br><span class="line"></span><br><span class="line">sm.f1_score(test_y, pred_y, average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">0.8462354188759279</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="支持向量机-SVM">支持向量机(SVM)</h2>
<p><strong>支持向量机</strong>(<strong>SVM</strong>)是一组用于分类、回归和异常值检测的监督学习方法。</p>
<p>支持向量机的优点是：</p>
<ul>
<li>
<p>在高维空间中有效。</p>
</li>
<li>
<p>在维数大于样本数的情况下仍然有效。</p>
</li>
<li>
<p>在决策函数中使用训练点的子集（称为支持向量），因此它也是内存高效的。</p>
</li>
<li>
<p>通用性：可以为决策函数指定不同的内核函数。提供了通用内核，但也可以指定自定义内核。</p>
</li>
</ul>
<p>支持向量机的缺点包括：</p>
<ul>
<li>
<p>​     如果特征数量远大于样本数量，在选择核函数时避免过度拟合，正则化项至关重要。</p>
</li>
<li>
<p>​      SVM不直接提供概率估计，这些是使用昂贵的五折交叉验证计算的。</p>
</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="C:%5CUsers%5Cbeihai%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20230711150419453.png" alt="image-20230711150419453"></p>
<h3 id="分类（SVC）">分类（SVC）</h3>
<p>SVC，NuSVC、LinearSVC是能够对数据集执行二进制和多类分类的类。</p>
<p>SVC和NuSVC是类似的方法，但接受的参数集略有不同，并具有不同的数学公式。另一方面，LinearSVC对于线性核的情况，是支持向量分类的另一种（更快）实现。请注意， LinearSVC不接受参数kernel，因为它被假定为线性的。</p>
<p>作为其他分类器，SVC、NuSVC和 LinearSVC将两个数组作为输入：一个包含训练样本X的形状数组，以及一个形状类标签（字符串或整数）数组：(n_samples, n_features) y(n_samples)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sklearn.svm.LinearSVC(penalty=<span class="string">&#x27;l2&#x27;</span>, loss=<span class="string">&#x27;squared_hinge&#x27;</span>, *, dual=<span class="literal">True</span>, tol=<span class="number">0.0001</span>, C=<span class="number">1.0</span>, multi_class=<span class="string">&#x27;ovr&#x27;</span>, fit_intercept=<span class="literal">True</span>, intercept_scaling=<span class="number">1</span>, class_weight=<span class="literal">None</span>, verbose=<span class="number">0</span>, random_state=<span class="literal">None</span>, max_iter=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">sklearn.svm.NuSVC(*, nu=<span class="number">0.5</span>, kernel=<span class="string">&#x27;rbf&#x27;</span>, degree=<span class="number">3</span>, gamma=<span class="string">&#x27;scale&#x27;</span>, coef0=<span class="number">0.0</span>, shrinking=<span class="literal">True</span>, probability=<span class="literal">False</span>, tol=<span class="number">0.001</span>, cache_size=<span class="number">200</span>, class_weight=<span class="literal">None</span>, verbose=<span class="literal">False</span>, max_iter=-<span class="number">1</span>, decision_function_shape=<span class="string">&#x27;ovr&#x27;</span>, break_ties=<span class="literal">False</span>, random_state=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">sklearn.svm.SVC(*, C=<span class="number">1.0</span>, kernel=<span class="string">&#x27;rbf&#x27;</span>, degree=<span class="number">3</span>, gamma=<span class="string">&#x27;scale&#x27;</span>, coef0=<span class="number">0.0</span>, shrinking=<span class="literal">True</span>, probability=<span class="literal">False</span>, tol=<span class="number">0.001</span>, cache_size=<span class="number">200</span>, class_weight=<span class="literal">None</span>, verbose=<span class="literal">False</span>, max_iter=-<span class="number">1</span>, decision_function_shape=<span class="string">&#x27;ovr&#x27;</span>, break_ties=<span class="literal">False</span>, random_state=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h3 id="回归（SVR）">回归（SVR）</h3>
<p>支持向量分类的方法可以扩展到解决回归问题。这种方法称为支持向量回归。</p>
<p>SVM算法非常全面，它不仅支持线性和非线性分类，而且还支持线性和非线性回归。SVM回归要做的就是让尽可能多的实例位于街道上，同时限制间隔违例（也就是不在街道上的实例）。街道的宽度由超参数ε控制，ε值越大，间隔越大；ε值越小，间隔越小。在间隔内添加更多的实例不会影响模型的预测，所以这个模型被称为ε不敏感。</p>
<p>支持向量分类生成的模型（如上所述）仅依赖于训练数据的一个子集，因为构建模型的成本函数不关心超出边界的训练点。类似地，支持向量回归生成的模型仅依赖于训练数据的一个子集，因为成本函数忽略了预测接近其目标的样本。</p>
<p>支持向量回归有 3 种不同的实现：<code> SVR、NuSVR和LinearSVR</code>。</p>
<p><code>LinearSVR</code>提供比<code>SVR</code>(仅考虑线性内核)更快的实现，同时<code>NuSVR</code>实现与<code>SVR</code>略有不同的公式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># API</span></span><br><span class="line"></span><br><span class="line">sklearn.svm.LinearSVR(*, epsilon=<span class="number">0.0</span>, tol=<span class="number">0.0001</span>, C=<span class="number">1.0</span>, loss=<span class="string">&#x27;epsilon_insensitive&#x27;</span>, fit_intercept=<span class="literal">True</span>, intercept_scaling=<span class="number">1.0</span>, dual=<span class="literal">True</span>, verbose=<span class="number">0</span>, random_state=<span class="literal">None</span>, max_iter=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">sklearn.svm.NuSVR(*, nu=<span class="number">0.5</span>, C=<span class="number">1.0</span>, kernel=<span class="string">&#x27;rbf&#x27;</span>, degree=<span class="number">3</span>, gamma=<span class="string">&#x27;scale&#x27;</span>, coef0=<span class="number">0.0</span>, shrinking=<span class="literal">True</span>, tol=<span class="number">0.001</span>, cache_size=<span class="number">200</span>, verbose=<span class="literal">False</span>, max_iter=- <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">sklearn.svm.NuSVR(*, nu=<span class="number">0.5</span>, C=<span class="number">1.0</span>, kernel=<span class="string">&#x27;rbf&#x27;</span>, degree=<span class="number">3</span>, gamma=<span class="string">&#x27;scale&#x27;</span>, coef0=<span class="number">0.0</span>, shrinking=<span class="literal">True</span>, tol=<span class="number">0.001</span>, cache_size=<span class="number">200</span>, verbose=<span class="literal">False</span>, max_iter=- <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="案例">案例</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets <span class="keyword">as</span> sd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line">data = sd.load_iris()</span><br><span class="line">x = data.data</span><br><span class="line">y = data.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分数据集</span></span><br><span class="line">train_x, test_x, train_y, test_y = ms.train_test_split(x, y, train_size=<span class="number">0.75</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择分类模型</span></span><br><span class="line">model = svm.SVC()</span><br><span class="line"><span class="comment"># 训练分类模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 预测分类模型</span></span><br><span class="line">pred_y = model.predict(test_x)</span><br><span class="line"><span class="comment"># 分离模型评估</span></span><br><span class="line"><span class="built_in">print</span>(sm.classification_report(test_y, pred_y))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;*****************************************&quot;</span>)</span><br><span class="line">sm.f1_score(test_y, pred_y, average=<span class="literal">None</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">              precision    recall  f1-score   support</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">           0       1.00      1.00      1.00        11</span></span><br><span class="line"><span class="string">           1       0.76      0.93      0.84        14</span></span><br><span class="line"><span class="string">           2       0.90      0.69      0.78        13</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    accuracy                           0.87        38</span></span><br><span class="line"><span class="string">   macro avg       0.89      0.87      0.87        38</span></span><br><span class="line"><span class="string">weighted avg       0.88      0.87      0.87        38</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">*****************************************</span></span><br><span class="line"><span class="string">array([1.        , 0.83870968, 0.7826087 ])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 回归模型构建</span></span><br><span class="line">model2 = svm.SVR()</span><br><span class="line"><span class="comment"># 训练回归模型</span></span><br><span class="line">model2.fit(train_x, train_y)</span><br><span class="line">sm.r2_score(test_y, pred_y)</span><br></pre></td></tr></table></figure>
<h2 id="ROC曲线与AUC指标">ROC曲线与AUC指标</h2>
<ul>
<li>
<p>AUC只能用来评价二分类</p>
</li>
<li>
<p>AUC非常适合评价样本不平衡中的分类器性能</p>
</li>
</ul>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br></pre></td></tr></table></figure>
<h2 id="模型保存和加载">模型保存和加载</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">joblib.dump(model, <span class="string">&quot;titanic.pkl&quot;</span>)</span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">model2 = joblib.load(<span class="string">&quot;titanic.pkl&quot;</span>)</span><br><span class="line">model2.predict(test_x)</span><br></pre></td></tr></table></figure>
<h2 id="无监督学习">无监督学习</h2>
<h3 id="K-means聚类">K-means聚类</h3>
<p>就是设置K值，在特征空间中随机找K个特征作为聚类中心，然后去找和中心点最近的并标为同一类，全部标为同一颜色后重新寻找这些聚类后的K个中心点，然后重复，当最后聚类的点和初始点一样时候就停止</p>
<p>API</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.cluster.KMeans(n_clusters=<span class="number">8</span>,init=<span class="string">&#x27;k-means++&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="评估">评估</h3>
<p>外部距离最大化，内部距离最小化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 轮廓系数</span></span><br><span class="line">sklearn.metrics.slihouette_score(特征, 预测值)</span><br></pre></td></tr></table></figure>
<h2 id="信用卡诈骗检测">信用卡诈骗检测</h2>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="C:%5CUsers%5Cbeihai%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20230714155343300.png" alt="image-20230714155343300"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">f&quot;C:\\Users\\beihai\\workpace\\金砖\\模块C\\数据\\creditcard.csv&quot;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="comment"># 获取目标值和特征值</span></span><br><span class="line">x = data.iloc[:,<span class="number">1</span>:<span class="number">30</span>]</span><br><span class="line">y = data.iloc[:,-<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">train_x, test_x, train_y, test_y = ms.train_test_split(x, y, train_size=<span class="number">0.8</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">21</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">print(train_x.shape)</span></span><br><span class="line"><span class="string">print(test_x.shape)</span></span><br><span class="line"><span class="string">(227845, 29)</span></span><br><span class="line"><span class="string">(56962, 29)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择模型</span></span><br><span class="line">model = svm.SVC()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看模型</span></span><br><span class="line">model.feature_names_in_</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([&#x27;V1&#x27;, &#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V5&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;, &#x27;V10&#x27;, &#x27;V11&#x27;,</span></span><br><span class="line"><span class="string">       &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;, &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;, &#x27;V19&#x27;, &#x27;V20&#x27;,</span></span><br><span class="line"><span class="string">       &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;, &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;, &#x27;V28&#x27;, &#x27;Amount&#x27;],</span></span><br><span class="line"><span class="string">      dtype=object)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测模型</span></span><br><span class="line">pred_y = model.predict(test_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line"><span class="built_in">print</span>(sm.classification_report(test_y, pred_y))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">              precision    recall  f1-score   support</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">           0       1.00      1.00      1.00     56853</span></span><br><span class="line"><span class="string">           1       0.91      0.29      0.44       109</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    accuracy                           1.00     56962</span></span><br><span class="line"><span class="string">   macro avg       0.96      0.65      0.72     56962</span></span><br><span class="line"><span class="string">weighted avg       1.00      1.00      1.00     56962</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># f1_score评分</span></span><br><span class="line">sm.f1_score(test_y, pred_y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">0.4444444444444445</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">f&quot;C:\\Users\\beihai\\workpace\\金砖\\模块C\\数据\\creditcard.csv&quot;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">count_classes = pd.value_counts(data[<span class="string">&#x27;Class&#x27;</span>], sort = <span class="literal">True</span>).sort_index()</span><br><span class="line"><span class="built_in">print</span>(count_classes)</span><br><span class="line">count_classes.plot(kind=<span class="string">&#x27;bar&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Fraud class histograam&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Class&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Frequency&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="comment"># 数据处理</span></span><br><span class="line">data[<span class="string">&#x27;normAmount&#x27;</span>] = StandardScaler().fit_transform(data[<span class="string">&#x27;Amount&#x27;</span>].to_numpy().reshape(-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">data = data.drop([<span class="string">&#x27;Time&#x27;</span>, <span class="string">&#x27;Amount&#x27;</span>], axis = <span class="number">1</span>)</span><br><span class="line">data.head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下采样：使得0 和 1 所占数据一样多</span></span><br><span class="line">x = data.loc[:, data.columns != <span class="string">&#x27;Class&#x27;</span>]</span><br><span class="line">y = data.loc[:, data.columns == <span class="string">&#x27;Class&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="built_in">print</span>(y.shape)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(284807, 29)</span></span><br><span class="line"><span class="string">(284807, 1)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">number_recored_fraud = <span class="built_in">len</span>(data[data.Class == <span class="number">1</span>])</span><br><span class="line">fraud_indicies = np.array(data[data.Class == <span class="number">1</span>].index)</span><br><span class="line"><span class="built_in">print</span>(number_recored_fraud)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(fraud_indicies))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">492</span></span><br><span class="line"><span class="string">492</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">normal_indices = data[data.Class == <span class="number">0</span>].index</span><br><span class="line">random_normal_indices = np.random.choice(normal_indices, number_recored_fraud, replace=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(random_normal_indices)</span><br><span class="line">random_normal_indices = np.array(random_normal_indices)</span><br><span class="line"><span class="built_in">print</span>(random_normal_indices)</span><br><span class="line"></span><br><span class="line">under_sample_indices = np.concatenate([fraud_indicies, random_normal_indices])</span><br><span class="line">under_sample_data = data.iloc[under_sample_indices,:]</span><br><span class="line">x_undersample = under_sample_data.iloc[:,under_sample_data.columns != <span class="string">&#x27;Class&#x27;</span>]</span><br><span class="line">y_undersample = under_sample_data.iloc[:,under_sample_data.columns == <span class="string">&#x27;Class&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(x_undersample),<span class="built_in">len</span>(y_undersample)) </span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">984 984</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line">model = svm.SVC()</span><br><span class="line">model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测模型</span></span><br><span class="line">pred_y = model.predict(test_x)</span><br><span class="line">pred_y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics <span class="keyword">as</span> sm</span><br><span class="line">sm.f1_score(test_y, pred_y)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">0.9236363636363637</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(sm.classification_report(test_y, pred_y))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">              precision    recall  f1-score   support</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">           0       0.88      0.99      0.93       149</span></span><br><span class="line"><span class="string">           1       0.99      0.86      0.92       147</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    accuracy                           0.93       296</span></span><br><span class="line"><span class="string">   macro avg       0.94      0.93      0.93       296</span></span><br><span class="line"><span class="string">weighted avg       0.94      0.93      0.93       296</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info"><h>金砖国家机器学习比赛</h></span></div><div class="post-copyright__type"><span class="post-copyright-info"><a href="https://www.beihai.wiki/posts/fc93a568.html">https://www.beihai.wiki/posts/fc93a568.html</a></span></div><div class="post-copyright-m"><div class="post-copyright-m-info"><div class="post-copyright-a"><h>作者</h><div class="post-copyright-cc-info"><h>北海🌊</h></div></div><div class="post-copyright-c"><h>发布于</h><div class="post-copyright-cc-info"><h>2023-08-10</h></div></div><div class="post-copyright-u"><h>更新于</h><div class="post-copyright-cc-info"><h>2023-08-10</h></div></div><div class="post-copyright-c"><h>许可协议</h><div class="post-copyright-cc-info"><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></div></div></div></div></div><div class="tag_share"><div class="post-meta__tag-list"></div></div><link rel="stylesheet" href="/css/coin.css" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">投喂作者</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://tuchuang.voooe.cn/images/2024/06/07/VXpay.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://tuchuang.voooe.cn/images/2024/06/07/VXpay.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://tuchuang.voooe.cn/images/2024/06/07/ZFpay.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://tuchuang.voooe.cn/images/2024/06/07/ZFpay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></button></div><audio id="coinAudio" src="https://npm.elemecdn.com/akilar-candyassets@1.0.36/audio/aowu.m4a"></audio><script defer="defer" src="/js/coin.js"></script><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/498ab7d9.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://tuchuang.voooe.cn/images/2024/06/28/bc09.webp" onerror="onerror=null;src='/assets/r2.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">机器学习</div></div></a></div><div class="next-post pull-right"><a href="/posts/d7fb1ba1.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://tuchuang.voooe.cn/images/2024/06/28/bc16.webp" onerror="onerror=null;src='/assets/r2.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">免费图床综合教程</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><svg class="meta_icon" style="width:22px;height:22px;position:relative;top:5px"><use xlink:href="#icon-mulu1"></use></svg><span style="font-weight:bold">目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">机器学习与大数据赛项</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">模块A：大数据运维与应用(30分)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="toc-text">Hadoop基础环境搭建</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MySQL%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85"><span class="toc-text">MySQL离线安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E5%AE%89%E8%A3%85"><span class="toc-text">Hive安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E4%BD%BF%E7%94%A8"><span class="toc-text">Hive使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sqoop%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8"><span class="toc-text">Sqoop安装与使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark%E5%AE%89%E8%A3%85"><span class="toc-text">Spark安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark%E4%BD%BF%E7%94%A8"><span class="toc-text">Spark使用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9C%81%E8%B5%9B%E6%A0%B7%E5%8D%B7%E4%B8%80"><span class="toc-text">省赛样卷一</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#6-1-%E8%AE%A1%E7%AE%97%E4%B8%8D%E9%87%8D%E5%A4%8D%E7%9A%84%E7%94%B5%E5%BD%B1%E6%95%B0%E9%87%8F"><span class="toc-text">6.1 计算不重复的电影数量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-2-%E8%AE%A1%E7%AE%97%E7%94%B5%E5%BD%B1%E5%B9%B3%E5%9D%87%E8%AF%84%E5%88%86"><span class="toc-text">6.2  计算电影平均评分</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-3-%E8%AE%A1%E7%AE%97%E7%94%A8%E6%88%B7%E5%9C%A8%E5%A4%9C%E6%99%9A%E7%9A%84%E8%AF%84%E5%88%86%E6%80%BB%E8%AE%B0%E5%BD%95%E6%95%B0"><span class="toc-text">6.3  计算用户在夜晚的评分总记录数</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Flume%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8"><span class="toc-text">Flume安装与使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Linux%E6%9D%83%E9%99%90"><span class="toc-text">Linux权限</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link"><span class="toc-text"></span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">模块B：数据分析(30分)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9C%81%E8%B5%9B%E6%A0%B7%E5%8D%B7%E4%B8%80%EF%BC%9A%E6%A8%A1%E5%9D%97B"><span class="toc-text">省赛样卷一：模块B</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A11%EF%BC%9A%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%EF%BC%881%E5%88%86%EF%BC%89"><span class="toc-text">任务1：数据读取（1分）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A12%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%EF%BC%889%E5%88%86%EF%BC%89"><span class="toc-text">任务2：数据处理（9分）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A12-1%EF%BC%881%E5%88%86%EF%BC%89"><span class="toc-text">任务2-1（1分）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A12-2%EF%BC%881%E5%88%86%EF%BC%89"><span class="toc-text">任务2-2（1分）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A12-4%EF%BC%881%E5%88%86%EF%BC%89"><span class="toc-text">任务2-4（1分）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A12-5%EF%BC%882%E5%88%86%EF%BC%89"><span class="toc-text">任务2-5（2分）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A12-6%EF%BC%882%E5%88%86%EF%BC%89"><span class="toc-text">任务2-6（2分）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A13%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%EF%BC%8820%E5%88%86%EF%BC%89"><span class="toc-text">任务3：数据可视化（20分）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A13-1%EF%BC%882%E5%88%86%EF%BC%89"><span class="toc-text">任务3-1（2分）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A13-2%EF%BC%882%E5%88%86%EF%BC%89"><span class="toc-text">任务3-2（2分）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A13-3%EF%BC%882%E5%88%86%EF%BC%89"><span class="toc-text">任务3-3（2分）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A13-4%EF%BC%882%E5%88%86%EF%BC%89"><span class="toc-text">任务3-4（2分）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A13-5%EF%BC%882%E5%88%86%EF%BC%89"><span class="toc-text">任务3-5（2分）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A13-6%EF%BC%882%E5%88%86%EF%BC%89"><span class="toc-text">任务3-6（2分）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A13-7%EF%BC%882%E5%88%86%EF%BC%89"><span class="toc-text">任务3-7（2分）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A13-8%EF%BC%882%E5%88%86%EF%BC%89"><span class="toc-text">任务3-8（2分）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A13-9%EF%BC%884%E5%88%86%EF%BC%89"><span class="toc-text">任务3-9（4分）</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">模块C：机器学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-text">特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-text">特征提取</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E3%80%81%E5%AD%97%E5%85%B8%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-text">1、字典特征提取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E3%80%81%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-text">2、文本特征提取</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4"><span class="toc-text">特征降维</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E3%80%81%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="toc-text">1、特征选择</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E3%80%81%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-PCA"><span class="toc-text">2、主成分分析(PCA)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%83%E4%BC%98"><span class="toc-text">调优</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2%E5%92%8C%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="toc-text">网格搜索和交叉验证</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E3%80%81%E5%9D%87%E5%80%BC%E7%A7%BB%E9%99%A4-%E6%A0%87%E5%87%86%E5%B7%AE%E6%A0%87%E5%87%86%E5%8C%96"><span class="toc-text">1、均值移除 (标准差标准化)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E3%80%81%E8%8C%83%E5%9B%B4%E7%BC%A9%E6%94%BE%EF%BC%88%E7%A6%BB%E5%B7%AE%E6%A0%87%E5%87%86%E5%8C%96%EF%BC%89"><span class="toc-text">2、范围缩放（离差标准化）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%E3%80%81%E5%BC%82%E5%B8%B8%E5%80%BC%E7%BC%A9%E6%94%BE%E6%95%B0%E6%8D%AE"><span class="toc-text">3、异常值缩放数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4%E3%80%81%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-text">4、归一化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5%E3%80%81%E4%BA%8C%E5%80%BC%E5%8C%96"><span class="toc-text">5、二值化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6%E3%80%81%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81%EF%BC%88onehot%EF%BC%89"><span class="toc-text">6、独热编码（onehot）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7%E3%80%81%E6%A0%87%E7%AD%BE%E7%BC%96%E7%A0%81"><span class="toc-text">7、标签编码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8%E3%80%81%E5%B8%B8%E7%94%A8"><span class="toc-text">8、常用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98"><span class="toc-text">回归问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%80%E4%BB%8B"><span class="toc-text">1、线性回归简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-text">2、一元线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BC%98%E5%8C%96%E6%B1%82%E8%A7%A3"><span class="toc-text">线性回归模型的优化求解</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B"><span class="toc-text">正规方程</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%EF%BC%88Gradient-Descent%EF%BC%89"><span class="toc-text">梯度下降（Gradient Descent）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E5%9B%9E%E5%BD%92%E7%9B%B8%E5%85%B3API"><span class="toc-text">3、回归相关API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%E3%80%81%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98%EF%BC%9A%E5%8A%A0%E5%88%A9%E7%A6%8F%E5%B0%BC%E4%BA%9A%E6%88%BF%E5%B1%8B%E4%BB%B7%E6%A0%BC%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90"><span class="toc-text">4、案例实战：加利福尼亚房屋价格回归分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5%E3%80%81%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="toc-text">5、回归模型评价指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6%E3%80%81%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="toc-text">6、过拟合和欠拟合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7%E3%80%81%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-text">7、多元线性回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8%E3%80%81%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92"><span class="toc-text">8、多项式回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B"><span class="toc-text">9、正则化线性模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="toc-text">逻辑回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%8E%9F%E7%90%86"><span class="toc-text">1、逻辑回归原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="toc-text">2、交叉验证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86"><span class="toc-text">3、数据集划分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%E3%80%81%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="toc-text">4、模型搭建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5%E3%80%81%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-text">5、分类问题模型评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6%E3%80%81%E7%BA%A2%E9%85%92%E5%88%86%E7%B1%BB"><span class="toc-text">6、红酒分类</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-text">决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E5%86%B3%E7%AD%96%E6%A0%91%E5%9B%9E%E5%BD%92%E5%99%A8%E6%A8%A1%E5%9E%8B%E7%9B%B8%E5%85%B3API"><span class="toc-text">1、决策树回归器模型相关API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%9B%9E%E5%BD%92%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-text">2、鸢尾花回归决策树</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E5%90%88%E7%AE%97%E6%B3%95"><span class="toc-text">集合算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-text">1、随机森林</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81AdaBoost"><span class="toc-text">2、AdaBoost</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-text">朴素贝叶斯</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM"><span class="toc-text">支持向量机(SVM)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%EF%BC%88SVC%EF%BC%89"><span class="toc-text">分类（SVC）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%EF%BC%88SVR%EF%BC%89"><span class="toc-text">回归（SVR）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B"><span class="toc-text">案例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ROC%E6%9B%B2%E7%BA%BF%E4%B8%8EAUC%E6%8C%87%E6%A0%87"><span class="toc-text">ROC曲线与AUC指标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD"><span class="toc-text">模型保存和加载</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-text">无监督学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K-means%E8%81%9A%E7%B1%BB"><span class="toc-text">K-means聚类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0"><span class="toc-text">评估</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%A1%E7%94%A8%E5%8D%A1%E8%AF%88%E9%AA%97%E6%A3%80%E6%B5%8B"><span class="toc-text">信用卡诈骗检测</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-color: transparent;"><div id="footer-wrap"><div id="ft"><div class="ft-item-1"><div class="t-top"><div class="t-t-l"><p class="ft-t t-l-t">格言🧬</p><div class="bg-ad"><div>再看看那个光点，它就在这里，这是家园，这是我们 —— 你所爱的每一个人，你认识的一个人，你听说过的每一个人，曾经有过的每一个人，都在它上面度过他们的一生✨</div><div class="btn-xz-box"><a class="btn-xz" target="_blank" rel="noopener" href="https://stellarium.org/">点击开启星辰之旅</a></div></div></div><div class="t-t-r"><p class="ft-t t-l-t">猜你想看💡</p><ul class="ft-links"><li><a href="/posts/eec9786.html">魔改指南</a><a href="/box/nav/">网址导航</a></li><li><a href="/social/link/">我的朋友</a><a href="/comments/">留点什么</a></li><li><a href="/personal/about/">关于作者</a><a href="/archives/">文章归档</a></li><li><a href="/categories/">文章分类</a><a href="/tags/">文章标签</a></li><li><a href="/box/gallery/">我的画廊</a><a href="/personal/bb/">我的唠叨</a></li><li><a href="/site/time/">建设进程</a><a href="/site/census/">网站统计</a></li></ul></div></div></div><div class="ft-item-2"><p class="ft-t">推荐友链⌛</p><div class="ft-img-group"><div class="img-group-item"><a href="https://www.beihai.wiki/" title="北海Wiki🌊"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://tuchuang.voooe.cn/images/2024/06/28/ec042e2c1e514fb772b637364b0710a7.gif" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://tuchuang.voooe.cn/images/2024/06/08/hellokittydance.gif" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="" alt=""/></a></div></div></div></div><div class="copyright"><span><b>&copy;2022-2024</b></span><span><b>&nbsp;&nbsp;By 北海🌊</b></span></div><div class="footer_custom_text"><a target="_blank" rel="noopener" href="http://beian.miit.gov.cn/"><img class="icp-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://beian.mps.gov.cn/img/logo01.dd7ff50e.png"><span>备案号：鲁ICP备2024091427号</span></a></div><div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" title="本站采用多线部署，主线路托管于Vercel"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vercel-brightgreen?style=flat&amp;logo=Vercel" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" title="本站项目由Github托管"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" title="本站项目由Github托管"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a></p></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><a class="icon-V hidden" onclick="switchNightMode()" title="浅色和深色模式转换"><svg width="25" height="25" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon"></use></svg></a><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="share" type="button" title="右键模式" onclick="changeMouseMode()"><i class="fas fa-mouse"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog right_side"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button class="share" type="button" title="分享链接" onclick="share()"><i class="fas fa-share-nodes"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i><span id="percent">0<span>%</span></span></button><button id="go-down" type="button" title="直达底部" onclick="btf.scrollToDest(document.body.scrollHeight, 500)"><i class="fas fa-arrow-down"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();"><i class="fa fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();"><i class="fa fa-arrow-right"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();"><i class="fa fa-refresh"></i></a><a class="rightMenu-item" href="javascript:rmf.scrollToTop();"><i class="fa fa-arrow-up"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();"><i class="fa fa-copy"></i><span>复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.baidu.com/s?wd=&quot;+window.getSelection().toString());window.location.reload();"><i class="fa fa-search"></i><span>百度搜索</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-too"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();"><i class="fa fa-link"></i><span>转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:rmf.paste()"><i class="fa fa-copy"></i><span>粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-post"><a class="rightMenu-item" href="#post-comment"><i class="fas fa-comment"></i><span>空降评论</span></a><a class="rightMenu-item" href="javascript:rmf.copyWordsLink()"><i class="fa fa-link"></i><span>复制本文地址</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>新窗口打开</span></a><a class="rightMenu-item" id="menu-too" href="javascript:rmf.open()"><i class="fa fa-link"></i><span>转到链接</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:rmf.saveAs()"><i class="fa fa-download"></i><span>保存图片</span></a><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:switchNightMode();"><i class="fa fa-moon"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="/personal/about/"><i class="fa fa-info-circle"></i><span>关于博客</span></a><a class="rightMenu-item" href="javascript:rmf.fullScreen();"><i class="fas fa-expand"></i><span>切换全屏</span></a><a class="rightMenu-item" href="javascript:window.print();"><i class="fa-solid fa-print"></i><span>打印页面</span></a></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.staticfile.org/fancyapps-ui/4.0.31/fancybox.umd.min.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/instant.page/5.1.0/instantpage.min.js" type="module"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/vanilla-lazyload/17.3.1/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><script async="async">var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())
setTimeout(function(){preloader.endLoading();}, 5000);
document.getElementById('loading-box').addEventListener('click',()=> {preloader.endLoading()})</script><div class="js-pjax"><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: '',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: '',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.staticfile.org/twikoo/1.6.8/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script><script async src="https://cdn1.tianli0.top/npm/vue@2.6.14/dist/vue.min.js"></script><script async src="https://cdn1.tianli0.top/npm/element-ui@2.15.6/lib/index.js"></script><div class="aplayer no-destroy" id="aplayer" data-id="7100534627" data-server="netease" data-type="playlist" data-order="list" data-fixed="true" data-preload="auto" data-autoplay="true" data-mutex="true"></div><script async src="https://cdn.bootcdn.net/ajax/libs/clipboard.js/2.0.11/clipboard.min.js"></script><script defer type="text/javascript" src="https://cdn1.tianli0.top/npm/sweetalert2@8.19.0/dist/sweetalert2.all.js"></script><script async src="//npm.elemecdn.com/pace-js@1.2.4/pace.min.js"></script><script defer src="https://cdn1.tianli0.top/gh/nextapps-de/winbox/dist/winbox.bundle.min.js"></script><script async src="//at.alicdn.com/t/c/font_4051628_e4216kdfc9.js"></script><script async src="//at.alicdn.com/t/c/font_3586335_hsivh70x0fm.js"></script><script async src="//at.alicdn.com/t/c/font_3636804_gr02jmjr3y9.js"></script><script async src="//at.alicdn.com/t/c/font_3612150_kfv55xn3u2g.js"></script><script async src="https://cdn.wpon.cn/2022-sucai/Gold-ingot.js"></script><canvas id="universe"></canvas><canvas id="snow"></canvas><script defer src="/js/fomal.js"></script><script id="click-show-text" src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.3/click-show-text.min.js" data-mobile="false" data-text="I,LOVE,北海,Wiki" data-fontsize="15px" data-random="false" async="async"></script><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.js"></script><script src="https://cdn1.tianli0.top/npm/js-heo@1.0.12/metingjs/Meting.min.js"></script><script src="https://lib.baomitu.com/pjax/0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show","#web_bg",".js-pjax","#bibi","body > title","#app","#tag-echarts","#posts-echart","#categories-echarts"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://www.beihai.wiki/categories/工作室/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎅 北海の大学的工作室 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.beihai.wiki/categories/大数据/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 北海の大数据 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.beihai.wiki/categories/工作室/大数据/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 北海の大数据 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.beihai.wiki/categories/实用小技巧/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 北海の实用小技巧 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="https://www.beihai.wiki/categories/" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(33.333333333333336% - 5px);background: #e9e9e9;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: var(--text-bg-hover)}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/498ab7d9.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://tuchuang.voooe.cn/images/2024/06/28/bc09.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-08-10</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/498ab7d9.html&quot;);" href="javascript:void(0);" alt="">机器学习</a><div class="blog-slider__text">机器学习</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/498ab7d9.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/2013454d.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://tuchuang.voooe.cn/images/2024/06/28/bc09.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-08-09</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/2013454d.html&quot;);" href="javascript:void(0);" alt="">Markdown语法与外挂标签写法汇总</a><div class="blog-slider__text">🥧本文汇总Markdown格式以及外挂标签在网页端的渲染效果，可作为文档进行查询</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/2013454d.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('gitZone');
      var item_html = '<div class="recent-post-item" id="gitcalendarBar" style="width:100%;height:auto;padding:10px;"><style>#git_container{min-height: 320px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></div>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('gitZone') && (location.pathname ==='/site/census/'|| '/site/census/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("/api?null",['#d9e0df', '#c6e0dc', '#a8dcd4', '#9adcd2', '#89ded1', '#77e0d0', '#5fdecb', '#47dcc6', '#39dcc3', '#1fdabe', '#00dab9'],'null')
    }
  </script><!-- hexo injector body_end end --></body></html>